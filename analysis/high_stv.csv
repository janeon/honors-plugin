Post Link,ViewCount,Score,Body,Title,scTovc
16589806,3558,211,"<p>I'm trying to learn JS and got an issue.</p>

<p>I tried many things and googled but all in vain. Following piece of code doesn't work as expected. I should get value of i on click but it always returns 6. I'm pulling my hair out., please help.</p>

<pre><code>for (var i = 1; i &lt; 6; i++) {

    console.log(i);

    $(""#div"" + i).click(
        function() {
            alert(i);
        }
    );
}
</code></pre>

<p><a href=""http://jsfiddle.net/rmXcF/""><strong>jsfiddle</strong></a></p>
",JavaScript click handler not working as expected inside a for loop,0.05930298
2056948,7669,400,"<p>The following code gives different output when running the release inside Visual Studio, and running the release outside Visual Studio. I'm using Visual Studio 2008 and targeting .NET 3.5. I've also tried .NET 3.5 SP1.</p>

<p>When running outside Visual Studio, the JIT should kick in. Either (a) there's something subtle going on with C# that I'm missing or (b) the JIT is actually in error. I'm doubtful that the JIT can go wrong, but I'm running out of other possiblities...</p>

<p>Output when running inside Visual Studio:</p>

<pre><code>    0 0,
    0 1,
    1 0,
    1 1,
</code></pre>

<p>Output when running release outside of Visual Studio:</p>

<pre><code>    0 2,
    0 2,
    1 2,
    1 2,
</code></pre>

<p>What is the reason?</p>

<pre><code>using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;

namespace Test
{
    struct IntVec
    {
        public int x;
        public int y;
    }

    interface IDoSomething
    {
        void Do(IntVec o);
    }

    class DoSomething : IDoSomething
    {
        public void Do(IntVec o)
        {
            Console.WriteLine(o.x.ToString() + "" "" + o.y.ToString()+"","");
        }
    }

    class Program
    {
        static void Test(IDoSomething oDoesSomething)
        {
            IntVec oVec = new IntVec();
            for (oVec.x = 0; oVec.x &lt; 2; oVec.x++)
            {
                for (oVec.y = 0; oVec.y &lt; 2; oVec.y++)
                {
                    oDoesSomething.Do(oVec);
                }
            }
        }

        static void Main(string[] args)
        {
            Test(new DoSomething());
            Console.ReadLine();
        }
    }
}
</code></pre>
",.NET JIT potential error?,0.05215804
9761520,3007,146,"<p>I am trying to login to RDP using AS3 (air). I am doing ok, considering the lack of resources out there to understand the actual process.</p>

<p>I have gotten past the initial sending username, received a response from server, and I am now at initial request connection.</p>

<p>I am sending all my data and when sniffing traffic, I see that netmon is recognizing correctly what kind of packet I am sending (t125). I am <em>not</em> being disconnected by RDP and they send an <code>ack</code> packet - but I don't receive the response that I am expecting.</p>

<p>I have been cross referencing with <code>connectoid</code>, which is an open source RDP client. In the connection code, I am stuck where they write a mixture of little and big-endian integers.</p>

<p>When I look at the limited examples out there (more like packet dumps), I see that connection length for this process is 412, but my <code>bytearray</code> is more like 470.</p>

<p>I have converted <code>connectoid</code> methods to what I believe is correct, but with a mixture of endian type,  I am still unsure.</p>

<p>I am sorry if this is garbled, but I am trying my best to help you to help me. I will attach some code showing what I have tried to do in conversion.</p>

<pre><code>public function sendMcsData(): void {
    trace(""Secure.sendMcsData"");
    var num_channels: int = 2;
    //RdpPacket_Localised dataBuffer = new RdpPacket_Localised(512);
    var hostlen: int = 2 * ""myhostaddress.ath.cx"".length;
    if (hostlen &gt; 30) {
        hostlen = 30;
    }
    var length: int = 158;
    length += 76 + 12 + 4;
    length += num_channels * 12 + 8;
    dataBuffer.writeShort(5); /* unknown */
    dataBuffer.writeShort(0x14);
    dataBuffer.writeByte(0x7c); //set 8 is write byte //write short is setbigendian 16 //
    dataBuffer.writeShort(1);
    dataBuffer.writeShort(length | 0x8000); // remaining length
    dataBuffer.writeShort(8); // length?
    dataBuffer.writeShort(16);
    dataBuffer.writeByte(0);
    var b1: ByteArray = new ByteArray();
    b1.endian = Endian.LITTLE_ENDIAN;
    b1.writeShort(0xc001);
    dataBuffer.writeBytes(b1);
    dataBuffer.writeByte(0);
    var b2: ByteArray = new ByteArray();
    b2.endian = Endian.LITTLE_ENDIAN;
    b2.writeInt(0x61637544);
    dataBuffer.writeBytes(b2);
    //dataBuffer.setLittleEndian32(0x61637544); // ""Duca"" ?!
    dataBuffer.writeShort(length - 14 | 0x8000); // remaining length
    var b3: ByteArray = new ByteArray();
    b3.endian = Endian.LITTLE_ENDIAN;
    // Client information
    b3.writeShort(SEC_TAG_CLI_INFO);
    b3.writeShort(true ? 212 : 136); // length
    b3.writeShort(true ? 4 : 1);
    b3.writeShort(8);
    b3.writeShort(600);
    b3.writeShort(1024);
    b3.writeShort(0xca01);
    b3.writeShort(0xaa03);
    b3.writeInt(0x809); //should be option.keybaortd layout just guessed 1
    b3.writeInt(true ? 2600 : 419); // or 0ece
    dataBuffer.writeBytes(b3);
    // // client
    // build? we
    // are 2600
    // compatible
    // :-)
    /* Unicode name of client, padded to 32 bytes */
    dataBuffer.writeMultiByte(""myhost.ath.cx"".toLocaleUpperCase(), ""ISO"");
    dataBuffer.position = dataBuffer.position + (30 - ""myhost.ath.cx"".toLocaleUpperCase()
        .length);
    var b4: ByteArray = new ByteArray();
    b4.endian = Endian.LITTLE_ENDIAN;
    b4.writeInt(4);
    b4.writeInt(0);
    b4.writeInt(12);
    dataBuffer.writeBytes(b4);
    dataBuffer.position = dataBuffer.position + 64; /* reserved? 4 + 12 doublewords */
    var b5: ByteArray = new ByteArray();
    b5.endian = Endian.LITTLE_ENDIAN;
    b5.writeShort(0xca01); // out_uint16_le(s, 0xca01);
    b5.writeShort(true ? 1 : 0);
    if (true) //Options.use_rdp5)
    {
        b5.writeInt(0); // out_uint32(s, 0);
        b5.writeByte(24); // out_uint8(s, g_server_bpp);
        b5.writeShort(0x0700); // out_uint16_le(s, 0x0700);
        b5.writeByte(0); // out_uint8(s, 0);
        b5.writeInt(1); // out_uint32_le(s, 1);
        b5.position = b5.position + 64;
        b5.writeShort(SEC_TAG_CLI_4); // out_uint16_le(s,
        // SEC_TAG_CLI_4);
        b5.writeShort(12); // out_uint16_le(s, 12);
        b5.writeInt(false ? 0xb : 0xd); // out_uint32_le(s,
        // g_console_session
        // ?
        // 0xb
        // :
        // 9);
        b5.writeInt(0); // out_uint32(s, 0);
    }
    // Client encryption settings //
    b5.writeShort(SEC_TAG_CLI_CRYPT);
    b5.writeShort(true ? 12 : 8); // length
    // if(Options.use_rdp5) dataBuffer.setLittleEndian32(Options.encryption ?
    // 0x1b : 0); // 128-bit encryption supported
    // else
    b5.writeInt(true ? (false ? 0xb : 0x3) : 0);
    if (true) b5.writeInt(0); // unknown
    if (true &amp;&amp; (num_channels &gt; 0)) {
        trace((""num_channels is "" + num_channels));
        b5.writeShort(SEC_TAG_CLI_CHANNELS); // out_uint16_le(s,
        // SEC_TAG_CLI_CHANNELS);
        b5.writeShort(num_channels * 12 + 8); // out_uint16_le(s,
        // g_num_channels
        // * 12
        // + 8);
        // //
        // length
        b5.writeInt(num_channels); // out_uint32_le(s,
        // g_num_channels);
        // // number of
        // virtual
        // channels
        dataBuffer.writeBytes(b5);
        trace(""b5 is bigendin"" + (b5.endian == Endian.BIG_ENDIAN));
        for (var i: int = 0; i &lt; num_channels; i++) {
            dataBuffer.writeMultiByte(""testtes"" + i, ""ascii""); //, 8); // out_uint8a(s,
            // g_channels[i].name,
            // 8);
            dataBuffer.writeInt(0x40000000); // out_uint32_be(s,
            // g_channels[i].flags);
        }
    }
    //socket.
    //buffer.markEnd();
    //return buffer;
}
</code></pre>
",Trying to login to RDP using AS3,0.04855338
17247880,5501,256,"<p>Can Template Haskell find out the names and/or the declarations of the associated type synonyms declared in a type class?  I expected <a href=""http://hackage.haskell.org/packages/archive/template-haskell/latest/doc/html/Language-Haskell-TH.html#v:reify""><code>reify</code></a> would do what I want, but it doesn't seem to provide all the necessary information.  It works for getting function type signatures:</p>

<pre><code>% ghci
GHCi, version 7.8.3: http://www.haskell.org/ghc/  :? for help
...
Prelude&gt; -- I'll be inserting line breaks and whitespace for clarity
Prelude&gt; -- in all GHCi output.
Prelude&gt; :set -XTemplateHaskell 
Prelude&gt; import Language.Haskell.TH
Prelude Language.Haskell.TH&gt; class C a where f :: a -&gt; Int
Prelude Language.Haskell.TH&gt; putStrLn $(stringE . show =&lt;&lt; reify ''C)
ClassI (ClassD [] Ghci1.C [PlainTV a_1627398388] []
               [SigD Ghci1.f
                     (ForallT [PlainTV a_1627398388]
                              [ClassP Ghci1.C [VarT a_1627398388]]
                              (AppT (AppT ArrowT (VarT a_1627398388))
                                    (ConT GHC.Types.Int)))])
       []
</code></pre>

<p>However, adding an associated type synonym to the class causes no change (up to renaming) in the output:</p>

<pre><code>Prelude Language.Haskell.TH&gt; :set -XTypeFamilies 
Prelude Language.Haskell.TH&gt; class C' a where type F a :: * ; f' :: a -&gt; Int
Prelude Language.Haskell.TH&gt; putStrLn $(stringE . show =&lt;&lt; reify ''C')
ClassI (ClassD [] Ghci3.C' [PlainTV a_1627405973] []
               [SigD Ghci3.f'
                     (ForallT [PlainTV a_1627405973]
                              [ClassP Ghci3.C' [VarT a_1627405973]]
                              (AppT (AppT ArrowT (VarT a_1627405973))
                                    (ConT GHC.Types.Int)))])
       []
</code></pre>

<p>If I know the name of <code>F</code>, I can look up information about it:</p>

<pre><code>Prelude Language.Haskell.TH&gt; putStrLn $(stringE . show =&lt;&lt; reify ''F)
FamilyI (FamilyD TypeFam
                 Ghci3.F
                 [PlainTV a_1627405973]
                 (Just StarT))
        []
</code></pre>

<p>But I can't find the name of <code>F</code> in the first place.  Even if I add an instance of the type class, the <code>InstanceD</code> has none of the information about the definition:</p>

<pre><code>Prelude Language.Haskell.TH&gt; instance C' [a] where type F [a] = a ; f' = length
Prelude Language.Haskell.TH&gt; f' ""Haskell""
7
Prelude Language.Haskell.TH&gt; 42 :: F [Integer]
42
Prelude Language.Haskell.TH&gt; putStrLn $(stringE . show =&lt;&lt; reify ''C')
ClassI (ClassD [] Ghci3.C' [PlainTV a_1627405973] []
               [SigD Ghci3.f'
                     (ForallT [PlainTV a_1627405973]
                              [ClassP Ghci3.C' [VarT a_1627405973]]
                              (AppT (AppT ArrowT (VarT a_1627405973))
                                    (ConT GHC.Types.Int)))])
       [InstanceD []
                  (AppT (ConT Ghci3.C')
                        (AppT ListT (VarT a_1627406161)))
                  []]
</code></pre>

<p>If <code>reify</code> won't work, is there a workaround, other than listing the associate type synonyms manually?</p>

<p>This problem is present in GHC 7.8.3 with version 2.9.0.0 of the template-haskell package; it was also present in GHC 7.4.2 with version 2.7.0.0 of the template-haskell package.  (I didn't check on GHC 7.6.*, but I imagine it was present there too.)  I'm interested in solutions for any version of GHC (including ""this was only fixed in GHC version <em>V</em>"").</p>
",Getting associated type synonyms with template Haskell,0.04653699
21872422,3705,168,"<p>I'm using <a href=""https://sourceforge.net/projects/jnca/"" rel=""nofollow noreferrer"">jnca</a> library to collect NetFlow records sent by a router. The version of the NetFlow record sent by the router is version 9. </p>

<p>When the NetFlow packet is observed from the Wireshark the flow sets with the template id 263 contains the data about initiator octets and responder octets which can be used to determine the number of bytes associated with a flow. 
<a href=""https://i.stack.imgur.com/aYwGh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/aYwGh.png"" alt=""wireshark record""></a>
</p>

<p>But the problem is these values cannot be obtained by the jcna. It shows always zero for the octets. </p>

<pre><code>currOffset = t.getTypeOffset(FieldDefinition.InBYTES_32);
currLen = t.getTypeLen(FieldDefinition.InBYTES_32);
if (currOffset &gt;= 0 &amp;&amp; currLen &gt; 0) {
    dOctets = Util.to_number(buf, off + currOffset, currLen) * t.getSamplingRate();
}
</code></pre>

<p>This is the code segment which is used to get the dOctets. This returns zero even for the template ID 263. </p>

<p>But when it's calculated with respect to the NetFlow template id 263 it gives the correct data. (gives the initiator octets and to get responder octet 46 should be replaced with 50 as the length of the particular record is 4 bytes)</p>

<pre><code>dOctets = Util.to_number(buf, off + 46, 4)
</code></pre>

<p>46 is where the Initiator Octets record lies in that particular NetFlow packet.(got using the Wireshark record.)</p>

<p>Is it a problem with jnca? Hopefully, somebody who's familiar with jcna can give me some help on this. </p>
",Netflow record can't get octets (jnca),0.04534413
9202531,5267,238,"<p>This relates to an earlier question from back in June:</p>

<p><a href=""https://stackoverflow.com/questions/6296455/calculating-expectation-for-a-custom-distribution-in-mathematica"">Calculating expectation for a custom distribution in Mathematica</a></p>

<p>I have a custom mixed distribution defined using a second custom distribution following along the lines discussed by <code>@Sasha</code> in a number of answers over the past year.</p>

<p>Code defining the distributions follows:</p>

<pre><code>nDist /: CharacteristicFunction[nDist[a_, b_, m_, s_], 
   t_] := (a b E^(I m t - (s^2 t^2)/2))/((I a + t) (-I b + t));
nDist /: PDF[nDist[a_, b_, m_, s_], x_] := (1/(2*(a + b)))*a* 
   b*(E^(a*(m + (a*s^2)/2 - x))* Erfc[(m + a*s^2 - x)/(Sqrt[2]*s)] + 
     E^(b*(-m + (b*s^2)/2 + x))* 
      Erfc[(-m + b*s^2 + x)/(Sqrt[2]*s)]); 
nDist /: CDF[nDist[a_, b_, m_, s_], 
   x_] := ((1/(2*(a + b)))*((a + b)*E^(a*x)* 
        Erfc[(m - x)/(Sqrt[2]*s)] - 
       b*E^(a*m + (a^2*s^2)/2)*Erfc[(m + a*s^2 - x)/(Sqrt[2]*s)] + 
       a*E^((-b)*m + (b^2*s^2)/2 + a*x + b*x)*
        Erfc[(-m + b*s^2 + x)/(Sqrt[2]*s)]))/ E^(a*x);         

nDist /: Quantile[nDist[a_, b_, m_, s_], p_] :=  
 Module[{x}, 
   x /. FindRoot[CDF[nDist[a, b, m, s], x] == #, {x, m}] &amp; /@ p] /; 
  VectorQ[p, 0 &lt; # &lt; 1 &amp;]
nDist /: Quantile[nDist[a_, b_, m_, s_], p_] := 
 Module[{x}, x /. FindRoot[CDF[nDist[a, b, m, s], x] == p, {x, m}]] /;
   0 &lt; p &lt; 1
nDist /: Quantile[nDist[a_, b_, m_, s_], p_] := -Infinity /; p == 0
nDist /: Quantile[nDist[a_, b_, m_, s_], p_] := Infinity /; p == 1
nDist /: Mean[nDist[a_, b_, m_, s_]] := 1/a - 1/b + m;
nDist /: Variance[nDist[a_, b_, m_, s_]] := 1/a^2 + 1/b^2 + s^2;
nDist /: StandardDeviation[ nDist[a_, b_, m_, s_]] := 
  Sqrt[ 1/a^2 + 1/b^2 + s^2];
nDist /: DistributionDomain[nDist[a_, b_, m_, s_]] := 
 Interval[{0, Infinity}]
nDist /: DistributionParameterQ[nDist[a_, b_, m_, s_]] := ! 
  TrueQ[Not[Element[{a, b, s, m}, Reals] &amp;&amp; a &gt; 0 &amp;&amp; b &gt; 0 &amp;&amp; s &gt; 0]]
nDist /: DistributionParameterAssumptions[nDist[a_, b_, m_, s_]] := 
 Element[{a, b, s, m}, Reals] &amp;&amp; a &gt; 0 &amp;&amp; b &gt; 0 &amp;&amp; s &gt; 0
nDist /: Random`DistributionVector[nDist[a_, b_, m_, s_], n_, prec_] :=

    RandomVariate[ExponentialDistribution[a], n, 
    WorkingPrecision -&gt; prec] - 
   RandomVariate[ExponentialDistribution[b], n, 
    WorkingPrecision -&gt; prec] + 
   RandomVariate[NormalDistribution[m, s], n, 
    WorkingPrecision -&gt; prec];

(* Fitting: This uses Mean, central moments 2 and 3 and 4th cumulant \
but it often does not provide a solution *)

nDistParam[data_] := Module[{mn, vv, m3, k4, al, be, m, si},
      mn = Mean[data];
      vv = CentralMoment[data, 2];
      m3 = CentralMoment[data, 3];
      k4 = Cumulant[data, 4];
      al = 
    ConditionalExpression[
     Root[864 - 864 m3 #1^3 - 216 k4 #1^4 + 648 m3^2 #1^6 + 
        36 k4^2 #1^8 - 216 m3^3 #1^9 + (-2 k4^3 + 27 m3^4) #1^12 &amp;, 
      2], k4 &gt; Root[-27 m3^4 + 4 #1^3 &amp;, 1]];
      be = ConditionalExpression[

     Root[2 Root[
           864 - 864 m3 #1^3 - 216 k4 #1^4 + 648 m3^2 #1^6 + 
             36 k4^2 #1^8 - 
             216 m3^3 #1^9 + (-2 k4^3 + 27 m3^4) #1^12 &amp;, 
           2]^3 + (-2 + 
           m3 Root[
              864 - 864 m3 #1^3 - 216 k4 #1^4 + 648 m3^2 #1^6 + 
                36 k4^2 #1^8 - 
                216 m3^3 #1^9 + (-2 k4^3 + 27 m3^4) #1^12 &amp;, 
              2]^3) #1^3 &amp;, 1], k4 &gt; Root[-27 m3^4 + 4 #1^3 &amp;, 1]];
      m = mn - 1/al + 1/be;
      si = 
    Sqrt[Abs[-al^-2 - be^-2 + vv ]];(*Ensure positive*)
      {al, 
    be, m, si}];

nDistLL = 
  Compile[{a, b, m, s, {x, _Real, 1}}, 
   Total[Log[
     1/(2 (a + 
           b)) a b (E^(a (m + (a s^2)/2 - x)) Erfc[(m + a s^2 - 
             x)/(Sqrt[2] s)] + 
        E^(b (-m + (b s^2)/2 + x)) Erfc[(-m + b s^2 + 
             x)/(Sqrt[2] s)])]](*, CompilationTarget-&gt;""C"", 
   RuntimeAttributes-&gt;{Listable}, Parallelization-&gt;True*)];

nlloglike[data_, a_?NumericQ, b_?NumericQ, m_?NumericQ, s_?NumericQ] := 
  nDistLL[a, b, m, s, data];

nFit[data_] := Module[{a, b, m, s, a0, b0, m0, s0, res},

      (* So far have not found a good way to quickly estimate a and \
b.  Starting assumption is that they both = 2,then m0 ~= 
   Mean and s0 ~= 
   StandardDeviation it seems to work better if a and b are not the \
same at start. *)

   {a0, b0, m0, s0} = nDistParam[data];(*may give Undefined values*)

     If[! (VectorQ[{a0, b0, m0, s0}, NumericQ] &amp;&amp; 
       VectorQ[{a0, b0, s0}, # &gt; 0 &amp;]),
            m0 = Mean[data];
            s0 = StandardDeviation[data];
            a0 = 1;
            b0 = 2;];
   res = {a, b, m, s} /. 
     FindMaximum[
       nlloglike[data, Abs[a], Abs[b], m,  
        Abs[s]], {{a, a0}, {b, b0}, {m, m0}, {s, s0}},
               Method -&gt; ""PrincipalAxis""][[2]];
      {Abs[res[[1]]], Abs[res[[2]]], res[[3]], Abs[res[[4]]]}];

nFit[data_, {a0_, b0_, m0_, s0_}] := Module[{a, b, m, s, res},
      res = {a, b, m, s} /. 
     FindMaximum[
       nlloglike[data, Abs[a], Abs[b], m, 
        Abs[s]], {{a, a0}, {b, b0}, {m, m0}, {s, s0}},
               Method -&gt; ""PrincipalAxis""][[2]];
      {Abs[res[[1]]], Abs[res[[2]]], res[[3]], Abs[res[[4]]]}];

dDist /: PDF[dDist[a_, b_, m_, s_], x_] := 
  PDF[nDist[a, b, m, s], Log[x]]/x;
dDist /: CDF[dDist[a_, b_, m_, s_], x_] := 
  CDF[nDist[a, b, m, s], Log[x]];
dDist /: EstimatedDistribution[data_, dDist[a_, b_, m_, s_]] := 
  dDist[Sequence @@ nFit[Log[data]]];
dDist /: EstimatedDistribution[data_, 
   dDist[a_, b_, m_, 
    s_], {{a_, a0_}, {b_, b0_}, {m_, m0_}, {s_, s0_}}] := 
  dDist[Sequence @@ nFit[Log[data], {a0, b0, m0, s0}]];
dDist /: Quantile[dDist[a_, b_, m_, s_], p_] := 
 Module[{x}, x /. FindRoot[CDF[dDist[a, b, m, s], x] == p, {x, s}]] /;
   0 &lt; p &lt; 1
dDist /: Quantile[dDist[a_, b_, m_, s_], p_] :=  
 Module[{x}, 
   x /. FindRoot[ CDF[dDist[a, b, m, s], x] == #, {x, s}] &amp; /@ p] /; 
  VectorQ[p, 0 &lt; # &lt; 1 &amp;]
dDist /: Quantile[dDist[a_, b_, m_, s_], p_] := -Infinity /; p == 0
dDist /: Quantile[dDist[a_, b_, m_, s_], p_] := Infinity /; p == 1
dDist /: DistributionDomain[dDist[a_, b_, m_, s_]] := 
 Interval[{0, Infinity}]
dDist /: DistributionParameterQ[dDist[a_, b_, m_, s_]] := ! 
  TrueQ[Not[Element[{a, b, s, m}, Reals] &amp;&amp; a &gt; 0 &amp;&amp; b &gt; 0 &amp;&amp; s &gt; 0]]
dDist /: DistributionParameterAssumptions[dDist[a_, b_, m_, s_]] := 
 Element[{a, b, s, m}, Reals] &amp;&amp; a &gt; 0 &amp;&amp; b &gt; 0 &amp;&amp; s &gt; 0
dDist /: Random`DistributionVector[dDist[a_, b_, m_, s_], n_, prec_] :=
   Exp[RandomVariate[ExponentialDistribution[a], n, 
     WorkingPrecision -&gt; prec] - 
       RandomVariate[ExponentialDistribution[b], n, 
     WorkingPrecision -&gt; prec] + 
    RandomVariate[NormalDistribution[m, s], n, 
     WorkingPrecision -&gt; prec]];
</code></pre>

<p>This enables me to fit distribution parameters and generate <strong>PDF's</strong> and <strong>CDF's</strong>.  An example of the plots:</p>

<pre><code>Plot[PDF[dDist[3.77, 1.34, -2.65, 0.40], x], {x, 0, .3}, 
 PlotRange -&gt; All]
Plot[CDF[dDist[3.77, 1.34, -2.65, 0.40], x], {x, 0, .3}, 
 PlotRange -&gt; All]
</code></pre>

<p><img src=""https://i.stack.imgur.com/0ynOS.png"" alt=""enter image description here""></p>

<p>Now I've defined a <code>function</code> to calculate mean residual life (see <a href=""https://math.stackexchange.com/questions/104494/mean-residual-life-clarification-needed"">this question</a> for an explanation).</p>

<pre><code>MeanResidualLife[start_, dist_] := 
 NExpectation[X \[Conditioned] X &gt; start, X \[Distributed] dist] - 
  start
MeanResidualLife[start_, limit_, dist_] := 
 NExpectation[X \[Conditioned] start &lt;= X &lt;= limit, 
   X \[Distributed] dist] - start
</code></pre>

<p>The first of these that doesn't set a limit as in the second takes a long time to calculate, but they both work.</p>

<p>Now I need to find the minimum of the <code>MeanResidualLife</code> function for the same distribution (or some variation of it) or minimize it.</p>

<p>I've tried a number of variations on this:</p>

<pre><code>FindMinimum[MeanResidualLife[x, dDist[3.77, 1.34, -2.65, 0.40]], x]
FindMinimum[MeanResidualLife[x, 1, dDist[3.77, 1.34, -2.65, 0.40]], x]

NMinimize[{MeanResidualLife[x, dDist[3.77, 1.34, -2.65, 0.40]], 
  0 &lt;= x &lt;= 1}, x]
NMinimize[{MeanResidualLife[x, 1, dDist[3.77, 1.34, -2.65, 0.40]], 0 &lt;= x &lt;= 1}, x]
</code></pre>

<p>These either seem to run forever or run into: </p>

<blockquote>
  <p>Power::infy : Infinite expression 1/ 0. encountered. >></p>
</blockquote>

<p>The <code>MeanResidualLife</code> function applied to a simpler but similarly shaped distribution shows that it has a single minimum:</p>

<pre><code>Plot[PDF[LogNormalDistribution[1.75, 0.65], x], {x, 0, 30}, 
 PlotRange -&gt; All]
Plot[MeanResidualLife[x, LogNormalDistribution[1.75, 0.65]], {x, 0, 
  30},
 PlotRange -&gt; {{0, 30}, {4.5, 8}}]
</code></pre>

<p><img src=""https://i.stack.imgur.com/4IpRL.png"" alt=""enter image description here""></p>

<p>Also both:</p>

<pre><code>FindMinimum[MeanResidualLife[x, LogNormalDistribution[1.75, 0.65]], x]
FindMinimum[MeanResidualLife[x, 30, LogNormalDistribution[1.75, 0.65]], x]
</code></pre>

<p>give me answers (if with a bunch of messages first) when used with the <code>LogNormalDistribution</code>.</p>

<p>Any thoughts on how to get this to work for the custom distribution described above?</p>

<p>Do I need to add constraints or options?</p>

<p>Do I need to define something else in the definitions of the custom distributions?</p>

<p>Maybe the <code>FindMinimum</code> or <code>NMinimize</code> just need to run longer (I've run them nearly an hour to no avail).  If so do I just need some way to speed up finding the minimum of the function?  Any suggestions on how?</p>

<p>Does <code>Mathematica</code> have another way to do this?</p>

<p><strong>Added 9 Feb 5:50PM EST:</strong> </p>

<p>Anyone can download <strong>Oleksandr Pavlyk's</strong> presentation about creating distributions in Mathematica from the Wolfram Technology Conference 2011 workshop 'Create Your Own Distribution' <a href=""http://www.wolfram.com/events/technology-conference/2011/mathematics-and-statistics.html"" rel=""nofollow noreferrer"">here</a>.  The downloads include the notebook, <code>'ExampleOfParametricDistribution.nb'</code> that seems to lays out all the pieces required to create a distribution that one can use like the distributions that come with Mathematica.</p>

<p>It may supply some of the answer.</p>
",Minimizing NExpectation for a custom distribution in Mathematica,0.04518701
24200904,5286,228,"<p>I'm currently working on a very performance critical program and one path I decided to explore that may help reduce resource consumption was increasing my worker threads' stack size so I can move most of the data (<code>float[]</code>s)  that I'll be accesing onto the stack (using <a href=""http://msdn.microsoft.com/en-us/library/cx9s2sy4(v=vs.80).aspx"" rel=""noreferrer""><code>stackalloc</code></a>).</p>

<p>I've <a href=""https://stackoverflow.com/a/823729/2246344"">read</a> that the default stack size for a thread is 1 MB, so in order to move all my <code>float[]</code>s I would have to expand the stack by approximately 50 times (to 50 MB~).</p>

<p>I understand this is generally considered ""unsafe"" and isn't recommended, but after benchmarking my current code against this method, I've discovered a <em>530%</em> increase in processing speed! So I can not simply pass by this option without further investigation, which leads me to my question; what are the dangers associated with increasing the stack to such a large size (what could go wrong), and what precautions should I take to minimise such dangers?</p>

<p>My test code,</p>

<pre><code>public static unsafe void TestMethod1()
{
    float* samples = stackalloc float[12500000];

    for (var ii = 0; ii &lt; 12500000; ii++)
    {
        samples[ii] = 32768;
    }
}

public static void TestMethod2()
{
    var samples = new float[12500000];

    for (var i = 0; i &lt; 12500000; i++)
    {
        samples[i] = 32768;
    }
}
</code></pre>
",What are the dangers when creating a thread with a stack size of 50x the default?,0.0431328
21296099,3686,148,"<p>In shapeless, the Nat type represents a way to encode natural numbers at a type level. This is used for example for fixed size lists. You can even do calculations on type level, e.g. append a list of <code>N</code> elements to a list of <code>K</code> elements and get back a list that is known at compile time to have <code>N+K</code> elements.</p>

<p>Is this representation capable of representing large numbers, e.g. <code>1000000</code> or 2<sup>53</sup>, or will this cause the Scala compiler to give up?</p>
",Limits of Nat type in Shapeless,0.04015193
8241821,3591,142,"<p>I'm trying to figure out how to properly use the <a href=""http://hackage.haskell.org/packages/archive/HsOpenSSL/0.10.3.1/doc/html/OpenSSL-Session.html"" rel=""noreferrer"">OpenSSL.Session</a> API in a concurrent context</p>

<p>E.g. assume I want to implement a <code>stunnel-style ssl-wrapper</code>, I'd expect to have the following basic skeleton structure, which implements a naive <code>full-duplex tcp-port-forwarder:</code></p>

<pre><code>runProxy :: PortID -&gt; AddrInfo -&gt; IO ()
runProxy localPort@(PortNumber lpn) serverAddrInfo = do
  listener &lt;- listenOn localPort

  forever $ do
    (sClient, clientAddr) &lt;- accept listener

    let finalize sServer = do
            sClose sServer
            sClose sClient

    forkIO $ do
        tidToServer &lt;- myThreadId
        bracket (connectToServer serverAddrInfo) finalize $ \sServer -&gt; do
            -- execute one 'copySocket' thread for each data direction
            -- and make sure that if one direction dies, the other gets
            -- pulled down as well
            bracket (forkIO (copySocket sServer sClient
                             `finally` killThread tidToServer))
                    (killThread) $ \_ -&gt; do
                copySocket sClient sServer -- ""controlling"" thread

 where
  -- |Copy data from source to dest until EOF occurs on source
  -- Copying may also be aborted due to exceptions
  copySocket :: Socket -&gt; Socket -&gt; IO ()
  copySocket src dst = go
   where
    go = do
        buf &lt;- B.recv src 4096
        unless (B.null buf) $ do
            B.sendAll dst buf
            go

  -- |Create connection to given AddrInfo target and return socket
  connectToServer saddr = do
    sServer &lt;- socket (addrFamily saddr) Stream defaultProtocol
    connect sServer (addrAddress saddr)
    return sServer
</code></pre>

<p>How do I transform the above skeleton into a <code>full-duplex ssl-wrapping tcp-forwarding proxy</code>? Where are the dangers W.R.T to concurrent/parallel execution (in the context of the above use-case) of the function calls provided by the HsOpenSSL API?</p>

<p>PS: I'm still struggling to fully comprehend how to make the code robust w.r.t. to exceptions and resource-leaks. So, albeit not being the primary focus of this question, if you notice something bad in the code above, please leave a comment.</p>
",Proper use of the HsOpenSSL API to implement a TLS Server,0.0395433
31679051,6966,272,"<p>I'm trying to call a <code>Shapeless</code> macro from inside a <code>quasiquote</code> with <code>Scala</code> and I'm not getting what I would like to get. </p>

<p>My macro doesn't return any errors but it doesn't expand <code>Witness(fieldName)</code> into <code>Witness.Lt[String]</code></p>

<pre><code>val implicits = schema.fields.map { field =&gt;
  val fieldName:String = field.name
  val fieldType = TypeName(field.valueType.fullName)
  val in = TermName(""implicitField""+fieldName)
  val tn = TermName(fieldName)
  val cc = TermName(""cc"")
  q""""""implicit val $in = Field.apply[$className,$fieldType](Witness($fieldName), ($cc:   $className) =&gt; $cc.$tn)""""""
}
</code></pre>

<p>Here is my <code>Field</code> definition: </p>

<pre><code>sealed abstract class Field[CC, FieldName] {
  val  fieldName: String
  type fieldType

  // How to extract this field
  def  get(cc : CC) : fieldType
}

object Field {
  // fieldType is existencial in Field but parametric in Fied.Aux
  // used to explict constraints on fieldType
  type Aux[CC, FieldName, fieldType_] = Field[CC, FieldName] {
    type fieldType = fieldType_
  }

  def apply[CC, fieldType_](fieldWitness : Witness.Lt[String], ext : CC =&gt; fieldType_) : Field.Aux[CC, fieldWitness.T, fieldType_] =
    new Field[CC, fieldWitness.T] {
      val fieldName  : String = fieldWitness.value
      type fieldType = fieldType_
      def get(cc : CC) : fieldType = ext(cc)
    }
}
</code></pre>

<p>In this case the implicit I generate looks like:</p>

<pre><code>implicit val implicitFieldname : Field[MyCaseClass, fieldWitness.`type`#T]{
  override type fieldType = java.lang.String
}
</code></pre>

<p>If it had been defined outside a <code>quasiquote</code> it would generate something like: </p>

<pre><code>implicit val implicitFieldname : Field.Aux[MyCaseClass, Witness.Lt[String]#T, String] = ...
</code></pre>

<p>Is there something that can be done?</p>
",How to use Shapeless in a Quasiquote?,0.0390468
42334986,3299,124,"<p>I have a form that has two <code>FieldGroup</code>s, and in one of the <code>FieldGroup</code>s I have a <code>SelectionGroup</code>.</p>

<p>The <code>SelectionGroup_Item</code>s show up in the form <code>FieldGroup</code> but the radio boxes to select one of the options doesn't show. If I remove the <code>FieldGroup</code> it then works again.</p>

<p>I've looked at the framework templates, and if I change the <code>FieldGroup_holder.ss</code> <code>SmallFieldHolder</code> to <code>FieldHolder</code> the radio boxes appear again and work correctly. I've tried following the templates to see which one isn't obeying the <code>SelectionGroup</code> but I keep getting lost. </p>

<p>Here's an example bit of code</p>

<pre><code>$fields = FieldList::create(
    FieldGroup::create(
        TextField::create('Name', 'Name')
    ),
    FieldGroup::create(
        SelectionGroup::create(
            'Test1or2',
            array(
                SelectionGroup_Item::create(
                    'Test1', array(
                        TextField::create('Test1', 'Test1')
                    ),
                    'Test1'
                ),
                SelectionGroup_Item::create(
                    'Test2', array(
                        TextField::create('Test2', 'Test2')
                    ),
                    'Test2'
                )
            )
        )
    )
),
FieldList::create(
    FormAction::create('submit', 'Submit')
)
</code></pre>
","SilverStripe PHP Forms - If I nest a SelectionGroup inside a FieldGroup, one of the related SelectionGroup_Items' Radio Box does not show up. Why?",0.03758715
17699877,4353,161,"<p>How does the following <a href=""http://en.wikipedia.org/wiki/Language_Integrated_Query"" rel=""noreferrer"">LINQ</a> statement work?</p>

<p>Here is my code:</p>

<pre><code>var list = new List&lt;int&gt;{1,2,4,5,6};
var even = list.Where(m =&gt; m%2 == 0);
list.Add(8);
foreach (var i in even)
{
    Console.WriteLine(i);
}
</code></pre>

<p><strong>Output:</strong> <code>2, 4, 6, 8</code></p>

<p>Why not <code>2, 4, 6</code>?</p>
",How does the following LINQ statement work?,0.03698599
38856677,4816,178,"<p>I have set up JavaScript unit testing with JS Test Driver on Netbeans as per <a href=""https://netbeans.org/kb/docs/webclient/html5-js-support.html#jstestdriver"" rel=""noreferrer"">this Link</a>. However, unlike the results in that tutorial, no more tests are executed after an assertion fails. How can I change this behaviour? </p>

<p>For example, given this test file:</p>

<p>The <code>test.js</code> file:</p>

<pre><code>AssertionsTestCase = TestCase(""AssertionsTestCase"");

AssertionsTestCase.prototype.testAlwaysPass = function(){
  assertEquals(1, 1);
  assertEquals(2, 2);
};
AssertionsTestCase.prototype.testAlwaysFail1 = function(){
  assertEquals(1, 2);
};
AssertionsTestCase.prototype.testAlwaysFail2 = function(){
  assertEquals(3, 4);
};
</code></pre>

<p>the progress bar shows 50%, (2 tests), it should say 33%.</p>

<p><a href=""https://i.stack.imgur.com/lBkZq.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/lBkZq.png"" alt=""enter image description here""></a></p>

<p>The <code>jsTestDriver.conf</code> file:</p>

<pre><code>server: http://localhost:42442
load:
  - test/lib/jasmine/jasmine.js
  - test/lib/jasmine-jstd-adapter/JasmineAdapter.js
  - test/unit/*.js
</code></pre>

<hr>

<p>I can have all tests run by command line. (On Windows PowerShell). Running as follows, tests do not stop running after a failure:</p>

<hr>

<blockquote>
  <p>java -jar $env:JSTD\JsTestDriver-1.3.5.jar --tests all --config jsTestDriver.conf</p>
</blockquote>

<p>the <code>jsTestDriver.conf</code> file:</p>

<pre><code>server: http://localhost:4244
load:
  - test/lib/jasmine/jasmine.js
  - test/lib/jasmine-jstd-adapter/JasmineAdapter.js
  - test/unit/*.js
</code></pre>

<p>All three tests are run.</p>
",JsTestDriver on NetBeans stops testing after a failed assertion,0.03696013
11425350,3314,121,"<p>According to the <a href=""http://www.scala-lang.org/docu/files/ScalaReference.pdf#page58"" rel=""noreferrer"">Scala Language Spec</a>:</p>

<blockquote>
  <p>... local type inference is permitted to limit the complexity of inferred
  bounds [of type parameters]. Minimality and maximality of types have to be understood
  relative to the set of types of acceptable complexity.</p>
</blockquote>

<p>In practice what are the limits? </p>

<p>Also, are there different limits that apply to inferred expression types than to parameter type bounds, and what are those limits?</p>
","What limits does scala place on the ""acceptable complexity"" of inferred types?",0.03651177
2356698,4829,175,"<p>If you program for a nontechnical audience, you find yourself at a high risk that users will not read your carefully worded and enlightening error messages, but just click on the first button available with a shrug of frustration.</p>

<p>So, I'm wondering what good practices you can recommend to help users actually read your error message, instead of simply waiving it aside. Ideas I can think of would fall along the lines of:</p>

<ul>
<li>Formatting of course help; maybe a simple, short message, with a ""learn more"" button that leads to the longer, more detailed error message</li>
<li>Have all error messages link to some section of the user guide (somewhat difficult to achieve)</li>
<li>Just don't issue error messages, simply refuse to perform the task (a somewhat ""Apple"" way of handling user input)</li>
</ul>

<p><em>Edit:</em> the audience I have in mind is a rather broad user base that doesn't use the software too often and is not captive (i.e., no in-house software or narrow community). A more generic form of this question was asked on <a href=""http://slashdot.org/"" rel=""noreferrer"">slashdot</a>, so you may want to <a href=""http://ask.slashdot.org/story/10/03/01/132219/How-Do-You-Get-Users-To-Read-Error-Messages"" rel=""noreferrer"">check there</a> for some of the answers.</p>
",How to get users to read error messages?,0.03623939
6937198,3703,134,"<p>Firstly, I apologize for the length of this question. </p>

<p>I am the author of <a href=""http://ironscheme.codeplex.com/"" rel=""nofollow noreferrer"">IronScheme</a>. Recently I have been working hard on emitting decent debug info, so that I can use the 'native' .NET debugger. </p>

<p>While this has been partly successful, I am running into some teething problems.</p>

<p>The first problem is related to stepping.</p>

<p>Due to Scheme being an expression language, everything tends to be wrapped in parenthesis, unlike the major .NET languages which seems to be statement (or line) based.</p>

<p>The original code (Scheme) looks like:</p>

<pre><code>(define (baz x)
  (cond
    [(null? x) 
      x]
    [(pair? x) 
      (car x)]
    [else
      (assertion-violation #f ""nooo"" x)]))
</code></pre>

<p>I have on purpose laid out each expression on a newline.</p>

<p>The emitted code transforms to C# (via ILSpy) looks like:</p>

<pre><code>public static object ::baz(object x)
{
  if (x == null)
  {
    return x;
  }
  if (x is Cons)
  {
    return Builtins.Car(x);
  }
  return #.ironscheme.exceptions::assertion-violation+(
     RuntimeHelpers.False, ""nooo"", Builtins.List(x));
}
</code></pre>

<p>As you can see, pretty simple. </p>

<p>Note: If the code was transformed into a conditional expression (?:) in C#, the whole thing would just be one debug step, keep that in mind.</p>

<p>Here is IL output with source and line numbers:</p>

<pre><code>  .method public static object  '::baz'(object x) cil managed
  {
    // Code size       56 (0x38)
    .maxstack  6
    .line 15,15 : 1,2 ''
//000014: 
//000015: (define (baz x)
    IL_0000:  nop
    .line 17,17 : 6,15 ''
//000016:   (cond
//000017:     [(null? x) 
    IL_0001:  ldarg.0
    IL_0002:  brtrue     IL_0009

    .line 18,18 : 7,8 ''
//000018:       x]
    IL_0007:  ldarg.0
    IL_0008:  ret

    .line 19,19 : 6,15 ''
//000019:     [(pair? x) 
    .line 19,19 : 6,15 ''
    IL_0009:  ldarg.0
    IL_000a:  isinst [IronScheme]IronScheme.Runtime.Cons
    IL_000f:  ldnull
    IL_0010:  cgt.un
    IL_0012:  brfalse    IL_0020

    IL_0017:  ldarg.0
    .line 20,20 : 7,14 ''
//000020:       (car x)]
    IL_0018:  tail.
    IL_001a:  call object [IronScheme]IronScheme.Runtime.Builtins::Car(object)
    IL_001f:  ret

    IL_0020:  ldsfld object 
         [Microsoft.Scripting]Microsoft.Scripting.RuntimeHelpers::False
    IL_0025:  ldstr      ""nooo""
    IL_002a:  ldarg.0
    IL_002b:  call object [IronScheme]IronScheme.Runtime.Builtins::List(object)
    .line 22,22 : 7,40 ''
//000021:     [else
//000022:       (assertion-violation #f ""nooo"" x)]))
    IL_0030:  tail.
    IL_0032:  call object [ironscheme.boot]#::
       'ironscheme.exceptions::assertion-violation+'(object,object,object)
    IL_0037:  ret
  } // end of method 'eval-core(033)'::'::baz'
</code></pre>

<p><em>Note:</em> To prevent the debugger from simply highlighting the entire method, I make the method entry point just 1 column wide.</p>

<p>As you can see, each expression maps correctly to a line.</p>

<p>Now the problem with stepping (tested on VS2010, but same/similar issue on VS2008):</p>

<p>These are with <code>IgnoreSymbolStoreSequencePoints</code> not applied.</p>

<ol>
<li>Call baz with null arg, it works correctly. (null? x) followed by x.</li>
<li>Call baz with Cons arg, it works correctly. (null? x) then (pair? x) then (car x).</li>
<li>Call baz with other arg, it fails. (null? x) then (pair? x) then (car x) then (assertion-violation ...).</li>
</ol>

<p>When applying <code>IgnoreSymbolStoreSequencePoints</code> (as recommended):</p>

<ol>
<li>Call baz with null arg, it works correctly. (null? x) followed by x.</li>
<li>Call baz with Cons arg, it fails. (null? x) then (pair? x).</li>
<li>Call baz with other arg, it fails. (null? x) then (pair? x) then (car x) then (assertion-violation ...).</li>
</ol>

<p>I also find in this mode that some lines (not shown here) are incorrectly highlighted, they are off by 1.</p>

<p>Here are some ideas what could be the causes:</p>

<ul>
<li>Tailcalls confuses the debugger</li>
<li>Overlapping locations (not shown here) confuses the debugger (it does so very well when setting a breakpoint)</li>
<li>????</li>
</ul>

<p>The second, but also serious, issue is the debugger failing to break/hit breakpoints in some cases.</p>

<p>The only place where I can get the debugger to break correctly (and consistantly), is at the method entry point. </p>

<p>The situation gets a bit better when <code>IgnoreSymbolStoreSequencePoints</code> is not applied.</p>

<p><strong>Conclusion</strong></p>

<p>It might be that the VS debugger is just plain buggy  :(</p>

<p><strong>References:</strong></p>

<ol>
<li><a href=""https://stackoverflow.com/questions/4357420/making-a-clr-net-language-debuggable"">Making a CLR/.NET Language Debuggable</a></li>
</ol>

<p><strong>Update 1:</strong></p>

<p>Mdbg does not work for 64-bit assemblies. So that is out. I have no more 32-bit machines to test it on. <em>Update:</em> I am sure this is no big problem, does anyone have a fix? <em>Edit:</em> Yes, silly me, just start mdbg under the x64 command prompt :)</p>

<p><strong>Update 2:</strong></p>

<p>I have created a C# app, and tried to dissect the line info. </p>

<p>My findings:</p>

<ul>
<li>After any <code>brXXX</code> instruction you need to have a sequence point (if not valid aka '#line hidden', emit a <code>nop</code>).</li>
<li>Before any <code>brXXX</code> instruction,  emit a '#line hidden' and a <code>nop</code>.</li>
</ul>

<p>Applying this, does not however fix the issues (alone?). </p>

<p>But adding the following, gives the desired result  :)</p>

<ul>
<li>After <code>ret</code>, emit a '#line hidden' and a <code>nop</code>.</li>
</ul>

<p>This is using the mode where <code>IgnoreSymbolStoreSequencePoints</code> is not applied. When applied, some steps are still skipped :(</p>

<p>Here is the IL output when above has been applied:</p>

<pre><code>  .method public static object  '::baz'(object x) cil managed
  {
    // Code size       63 (0x3f)
    .maxstack  6
    .line 15,15 : 1,2 ''
    IL_0000:  nop
    .line 17,17 : 6,15 ''
    IL_0001:  ldarg.0
    .line 16707566,16707566 : 0,0 ''
    IL_0002:  nop
    IL_0003:  brtrue     IL_000c

    .line 16707566,16707566 : 0,0 ''
    IL_0008:  nop
    .line 18,18 : 7,8 ''
    IL_0009:  ldarg.0
    IL_000a:  ret

    .line 16707566,16707566 : 0,0 ''
    IL_000b:  nop
    .line 19,19 : 6,15 ''
    .line 19,19 : 6,15 ''
    IL_000c:  ldarg.0
    IL_000d:  isinst     [IronScheme]IronScheme.Runtime.Cons
    IL_0012:  ldnull
    IL_0013:  cgt.un
    .line 16707566,16707566 : 0,0 ''
    IL_0015:  nop
    IL_0016:  brfalse    IL_0026

    .line 16707566,16707566 : 0,0 ''
    IL_001b:  nop
    IL_001c:  ldarg.0
    .line 20,20 : 7,14 ''
    IL_001d:  tail.
    IL_001f:  call object [IronScheme]IronScheme.Runtime.Builtins::Car(object)
    IL_0024:  ret

    .line 16707566,16707566 : 0,0 ''
    IL_0025:  nop
    IL_0026:  ldsfld object 
      [Microsoft.Scripting]Microsoft.Scripting.RuntimeHelpers::False
    IL_002b:  ldstr      ""nooo""
    IL_0030:  ldarg.0
    IL_0031:  call object [IronScheme]IronScheme.Runtime.Builtins::List(object)
    .line 22,22 : 7,40 ''
    IL_0036:  tail.
    IL_0038:  call object [ironscheme.boot]#::
      'ironscheme.exceptions::assertion-violation+'(object,object,object)
    IL_003d:  ret

    .line 16707566,16707566 : 0,0 ''
    IL_003e:  nop
  } // end of method 'eval-core(033)'::'::baz'
</code></pre>

<p><strong>Update 3:</strong></p>

<p>Problem with above 'semi-fix'. Peverify reports errors on all methods due to the <code>nop</code> after <code>ret</code>. I dont understand the problem really. How can a <code>nop</code> break verification after a <code>ret</code>. It is like dead code (except that it is NOT even code) ... Oh well, experimentation continues.</p>

<p><strong>Update 4:</strong></p>

<p>Back at home now, removed the 'unverifiable' code, running on VS2008 and things are a lot worse. Perhaps running unverifiable code for the sake of proper debugging might be the answer. In 'release' mode, all output would still be verifiable.</p>

<p><strong>Update 5:</strong></p>

<p>I have now decided my above idea is the only viable option for now. Although the generated code is unverifiable, I have yet to find any <code>VerificationException</code>'s. I dont know what the impact will be on the end user with this scenario. </p>

<p>As a bonus, my second issue has also be solved. :)</p>

<p>Here is a little <a href=""http://www.screencast.com/t/Tjrkjl7By"" rel=""nofollow noreferrer"">screencast</a> of what I ended up with. It hits breakpoints, does proper stepping (in/out/over), etc. All in all, the desired effect.</p>

<p>I, however, am still not accepting this as the way to do it. It feel overly-hacky to me. Having a confirmation on the real issue would be nice.</p>

<p><strong>Update 6:</strong></p>

<p>Just had the change to test the code on VS2010, there seems to be some problems:</p>

<ol>
<li><strike>The first call now does not step correctly. (assertion-violation ...) is hit. Other cases works fine.</strike> Some old code emitted unnecessary positions. Removed the code, works as expected. :)</li>
<li>More seriously, breakpoints fail on the second invocation of the program (using in-memory compilation, dumping assembly to file seems to make breakpoints happy again).</li>
</ol>

<p>Both these cases work correctly under VS2008. The main difference is that under VS2010, the entire application is compiled for .NET 4 and under VS2008, compiles to .NET 2. Both running 64-bit.</p>

<p><strong>Update 7:</strong></p>

<p>Like mentioned, I got mdbg running under 64-bit. Unfortunately, it also have the breakpoint issue where it fails to break if I rerun the program (this implies it gets recompiled, so not using the same assembly, but still using the same source).</p>

<p><strong>Update 8:</strong></p>

<p>I have <a href=""https://connect.microsoft.com/VisualStudio/feedback/details/684089/"" rel=""nofollow noreferrer"">filed a bug</a> at the MS Connect site regarding the breakpoint issue. </p>

<p>Update: Fixed</p>

<p><strong>Update 9:</strong></p>

<p>After some long thinking, the only way to make the debugger happy seems to be doing SSA, so every step can be isolated and sequential. I am yet to prove this notion though. But it seems logical. Obviously, cleaning up temps from SSA will break debugging, but that is easy to toggle, and leaving them does not have much overhead.</p>
",Making your .NET language step correctly in the debugger,0.03618688
20977741,6548,235,"<p>I have found an interesting performance regression in a small C++ snippet, when I enable C++11:</p>

<pre><code>#include &lt;vector&gt;

struct Item
{
  int a;
  int b;
};

int main()
{
  const std::size_t num_items = 10000000;
  std::vector&lt;Item&gt; container;
  container.reserve(num_items);
  for (std::size_t i = 0; i &lt; num_items; ++i) {
    container.push_back(Item());
  }
  return 0;
}
</code></pre>

<p>With g++ (GCC) 4.8.2 20131219 (prerelease) and C++03 I get:</p>

<pre><code>milian:/tmp$ g++ -O3 main.cpp &amp;&amp; perf stat -r 10 ./a.out

Performance counter stats for './a.out' (10 runs):

        35.206824 task-clock                #    0.988 CPUs utilized            ( +-  1.23% )
                4 context-switches          #    0.116 K/sec                    ( +-  4.38% )
                0 cpu-migrations            #    0.006 K/sec                    ( +- 66.67% )
              849 page-faults               #    0.024 M/sec                    ( +-  6.02% )
       95,693,808 cycles                    #    2.718 GHz                      ( +-  1.14% ) [49.72%]
  &lt;not supported&gt; stalled-cycles-frontend 
  &lt;not supported&gt; stalled-cycles-backend  
       95,282,359 instructions              #    1.00  insns per cycle          ( +-  0.65% ) [75.27%]
       30,104,021 branches                  #  855.062 M/sec                    ( +-  0.87% ) [77.46%]
            6,038 branch-misses             #    0.02% of all branches          ( +- 25.73% ) [75.53%]

      0.035648729 seconds time elapsed                                          ( +-  1.22% )
</code></pre>

<p>With C++11 enabled on the other hand, the performance degrades significantly:</p>

<pre><code>milian:/tmp$ g++ -std=c++11 -O3 main.cpp &amp;&amp; perf stat -r 10 ./a.out

Performance counter stats for './a.out' (10 runs):

        86.485313 task-clock                #    0.994 CPUs utilized            ( +-  0.50% )
                9 context-switches          #    0.104 K/sec                    ( +-  1.66% )
                2 cpu-migrations            #    0.017 K/sec                    ( +- 26.76% )
              798 page-faults               #    0.009 M/sec                    ( +-  8.54% )
      237,982,690 cycles                    #    2.752 GHz                      ( +-  0.41% ) [51.32%]
  &lt;not supported&gt; stalled-cycles-frontend 
  &lt;not supported&gt; stalled-cycles-backend  
      135,730,319 instructions              #    0.57  insns per cycle          ( +-  0.32% ) [75.77%]
       30,880,156 branches                  #  357.057 M/sec                    ( +-  0.25% ) [75.76%]
            4,188 branch-misses             #    0.01% of all branches          ( +-  7.59% ) [74.08%]

    0.087016724 seconds time elapsed                                          ( +-  0.50% )
</code></pre>

<p>Can someone explain this? So far my experience was that the STL gets faster by enabling C++11, esp. thanks to move semantics.</p>

<p><strong>EDIT:</strong> As suggested, using <code>container.emplace_back();</code> instead the performance gets on par with the C++03 version. How can the C++03 version achieve the same for <code>push_back</code>?</p>

<pre><code>milian:/tmp$ g++ -std=c++11 -O3 main.cpp &amp;&amp; perf stat -r 10 ./a.out

Performance counter stats for './a.out' (10 runs):

        36.229348 task-clock                #    0.988 CPUs utilized            ( +-  0.81% )
                4 context-switches          #    0.116 K/sec                    ( +-  3.17% )
                1 cpu-migrations            #    0.017 K/sec                    ( +- 36.85% )
              798 page-faults               #    0.022 M/sec                    ( +-  8.54% )
       94,488,818 cycles                    #    2.608 GHz                      ( +-  1.11% ) [50.44%]
  &lt;not supported&gt; stalled-cycles-frontend 
  &lt;not supported&gt; stalled-cycles-backend  
       94,851,411 instructions              #    1.00  insns per cycle          ( +-  0.98% ) [75.22%]
       30,468,562 branches                  #  840.991 M/sec                    ( +-  1.07% ) [76.71%]
            2,723 branch-misses             #    0.01% of all branches          ( +-  9.84% ) [74.81%]

   0.036678068 seconds time elapsed                                          ( +-  0.80% )
</code></pre>
",std::vector performance regression when enabling C++11,0.03588882
8419079,3811,136,"<p>I was answering a <a href=""https://stackoverflow.com/questions/8417470/private-field-captured-in-anonymous-delegate"">question</a> about the possibility of closures (legitimately) extending object-lifetimes when I ran into some <em>extremely</em> curious code-gen on the part of the C# compiler (4.0 if that matters). </p>

<p>The shortest repro I can find is the following:</p>

<ol>
<li>Create a lambda that captures a local while calling a  <em>static</em> method of the containing type.</li>
<li>Assign the generated delegate-reference to an <em>instance</em> field of the containing object.</li>
</ol>

<p>Result: The compiler creates a closure-object that references the object that created the lambda, when it has no reason to - the 'inner' target of the delegate is a <em>static</em> method, and the lambda-creating-object's instance members needn't be (and aren't) touched when the delegate is executed. Effectively, the compiler is acting like the programmer has captured <code>this</code> without reason.</p>

<pre><code>class Foo
{
    private Action _field;

    public void InstanceMethod()
    {
        var capturedVariable = Math.Pow(42, 1);

        _field = () =&gt; StaticMethod(capturedVariable);
    }

    private static void StaticMethod(double arg) { }
}
</code></pre>

<p>The generated code from a release build (decompiled to 'simpler' C#) looks like this:</p>

<pre><code>public void InstanceMethod()
{

    &lt;&gt;c__DisplayClass1 CS$&lt;&gt;8__locals2 = new &lt;&gt;c__DisplayClass1();

    CS$&lt;&gt;8__locals2.&lt;&gt;4__this = this; // What's this doing here?

    CS$&lt;&gt;8__locals2.capturedVariable = Math.Pow(42.0, 1.0);
    this._field = new Action(CS$&lt;&gt;8__locals2.&lt;InstanceMethod&gt;b__0);
}

[CompilerGenerated]
private sealed class &lt;&gt;c__DisplayClass1
{
    // Fields
    public Foo &lt;&gt;4__this; // Never read, only written to.
    public double capturedVariable;

    // Methods
    public void &lt;InstanceMethod&gt;b__0()
    {
        Foo.StaticMethod(this.capturedVariable);
    }
}
</code></pre>

<p>Observe that  <code>&lt;&gt;4__this</code> field of the closure object is populated with an object reference but is never read from (there is no reason).</p>

<p>So what's going on here? Does the language-specification allow for it?  Is this a compiler bug / oddity or is there a good reason (that I'm clearly missing) for the closure to reference the object? This makes me anxious because this looks like a recipe for closure-happy programmers (like me) to unwittingly introduce strange memory-leaks (imagine if the delegate were used as an event-handler) into programs. </p>
",Is this object-lifetime-extending-closure a C# compiler bug?,0.03568617
30434961,4381,155,"<p>Google Chrome does not refresh accessibility elements (<a href=""https://msdn.microsoft.com/library/system.windows.automation.automationelement%28v=vs.110%29.aspx"">AutomationElement</a>) when a user scrolls down in the browser. </p>

<p>To reproduce it: </p>

<ol>
<li>Enable renderer accessibility with :  <code>""chrome --force-render-accessibility""</code> or by setting on Global Accessibility at <code>""chrome://accessibility""</code>.</li>
<li>Go to <a href=""http://en.wikipedia.org/wiki/Google"">http://en.wikipedia.org/wiki/Google</a></li>
<li>Open <a href=""https://msdn.microsoft.com/en-us/library/windows/desktop/dd318521%28v=vs.85%29.aspx"">inspect.exe</a> in UI Automation Mode (from Windows Kits), look for ""Links to related articles"" element. </li>
<li>Come back to Chrome, Scroll down until ""Links to related articles"" at the bottom is visible</li>
<li>""Links to related articles"" element is marked off screen</li>
</ol>

<hr>

<p>I found some manual solutions that can force Chrome to refresh it: </p>

<ol>
<li>Set Zoom to 90% then set it back to 100 % (very very ugly way)</li>
<li>Switch accessibility off then switch on in <code>chrome://accessibility/</code></li>
</ol>

<p><strong>What I'm looking for is the ability to do one of these operations programatically, or any operation that can make Chrome refresh its cache tree.</strong></p>

<hr>

<p>What I've tried:</p>

<ul>
<li>Resize window with <code>PInvoke/MoveWindow</code></li>
<li>Redraw Window with <code>PInvoke/Redrawwindow</code></li>
<li>Build a chrome extension and force zoom to 100% on demand: <code>chrome.tabs.setZoom(null, 0);</code> (working but blink and slow down the window)</li>
</ul>

<p>None of these are working properly.</p>

<p><strong>EDIT</strong>: Tested with Google Chrome 40.XX, 41.XX, 42.XX, 43.XX, 44.XX, 45.XX, 46.XX, 47.XX.Dev, 48.XX.Dev under Windows 7.</p>
",Google Chrome accessible tree cache issue with UI Automation,0.03538005
23684947,6070,212,"<p>I've recently posted a <a href=""https://stackoverflow.com/questions/23448150/techniques-for-tracing-constraints"">question</a> about <a href=""https://github.com/emilaxelsson/syntactic"" rel=""noreferrer"">syntactic-2.0</a> regarding the definition of <code>share</code>. I've had this working in <strong>GHC 7.6</strong>:</p>

<pre><code>{-# LANGUAGE GADTs, TypeOperators, FlexibleContexts #-}

import Data.Syntactic
import Data.Syntactic.Sugar.BindingT

data Let a where
    Let :: Let (a :-&gt; (a -&gt; b) :-&gt; Full b)

share :: (Let :&lt;: sup,
          sup ~ Domain b, sup ~ Domain a,
          Syntactic a, Syntactic b,
          Syntactic (a -&gt; b),
          SyntacticN (a -&gt; (a -&gt; b) -&gt; b) 
                     fi)
           =&gt; a -&gt; (a -&gt; b) -&gt; b
share = sugarSym Let
</code></pre>

<p>However, GHC 7.8 wants <code>-XAllowAmbiguousTypes</code> to compile with that signature. Alternatively, I can replace the <code>fi</code> with </p>

<pre><code>(ASTF sup (Internal a) -&gt; AST sup ((Internal a) :-&gt; Full (Internal b)) -&gt; ASTF sup (Internal b))
</code></pre>

<p>which is the type implied by the fundep on <code>SyntacticN</code>. This allows me to avoid the extension. Of course this is </p>

<ul>
<li>a very long type to add to an already-large signature</li>
<li>tiresome to manually derive</li>
<li>unnecessary due to the fundep</li>
</ul>

<p>My questions are:</p>

<ol>
<li>Is this an acceptable use of <code>-XAllowAmbiguousTypes</code>?</li>
<li>In general, when should this extension be used? An answer <a href=""https://stackoverflow.com/questions/23461560/how-can-i-extract-this-polymorphic-recursion-function/23462397#23462397"">here</a> suggests ""it is almost never a good idea"".</li>
<li><p>Though I've read <a href=""http://www.haskell.org/ghc/docs/7.8.2/html/users_guide/other-type-extensions.html#ambiguity"" rel=""noreferrer"">the docs</a>, I'm still having trouble deciding if a constraint is ambiguous or not. Specifically, consider this function from Data.Syntactic.Sugar:</p>

<pre><code>sugarSym :: (sub :&lt;: AST sup, ApplySym sig fi sup, SyntacticN f fi) 
         =&gt; sub sig -&gt; f
sugarSym = sugarN . appSym
</code></pre>

<p>It appears to me that <code>fi</code> (and possibly <code>sup</code>) should be ambiguous here, but it compiles without the extension. Why is <code>sugarSym</code> unambiguous while <code>share</code> is? Since <code>share</code> is an application of <code>sugarSym</code>, the <code>share</code> constraints all come straight from <code>sugarSym</code>.</p></li>
</ol>
",When is -XAllowAmbiguousTypes appropriate?,0.03492586
18381936,3160,110,"<p>While reading the Java official tutorial about generics, I found that you can restrict the type argument (in this case is <code>T</code>) to extend a class and/or more interfaces with the 'and' operator (<code>&amp;</code>) like this:</p>

<pre><code>&lt;T extends MyClass &amp; Serializable&gt;
</code></pre>

<p>I replaced the <code>&amp;</code> with <code>,</code> (by mistake and still works, with a minor warning).</p>

<p>My question is, is there any difference between these two:</p>

<pre><code>&lt;T extends MyClass &amp; Serializable&gt;
&lt;T extends MyClass , Serializable&gt; // here is with comma
</code></pre>

<p>And the example method:</p>

<pre><code>static &lt;T extends MyClass &amp; Serializable&gt; ArrayList&lt;T&gt; fromArrayToCollection(T[] a) {
    ArrayList&lt;T&gt; arr = new ArrayList&lt;T&gt;();

    for (T o : a) {
        arr.add(o); // Correct
    }
    return arr;
}
</code></pre>
","What is the difference between '&' and ',' in Java generics?",0.03481013
20691482,5269,181,"<p>I have a requirement to <strong>secure a streamed WCF net.tcp service endpoint using WIF</strong>.  It should authenticate incoming calls against our token server.  The service is streamed because it is designed to transfer large amounts of data n stuff.</p>

<p><strong>This appears to be impossible.</strong>  And if I can't get around the catch, my Christmas will be ruined and I'll drink myself to death in a gutter while merry shoppers step over my slowly cooling body.  Totes serious, you guys.</p>

<p>Why is this impossible?  Here's the Catch-22.</p>

<p>On the client, I need to create a channel with the <a href=""http://msdn.microsoft.com/en-us/library/system.identitymodel.tokens.genericxmlsecuritytoken%28v=vs.110%29.aspx"" rel=""noreferrer"">GenericXmlSecurityToken</a> I get from our token server.  No problemo.</p>

<pre><code>// people around here hate the Framework Design Guidelines.
var token = Authentication.Current._Token;
var service = base.ChannelFactory.CreateChannelWithIssuedToken(token);
return service.Derp();
</code></pre>

<p>Did I say ""no problemo""?  Problemo.  In fact, <code>NullReferenceException</code> style problemo.  </p>

<p>""Bro, "" I asked the Framework, ""do you even null check?""  The Framework was silent, so I disassembled and found that </p>

<pre><code>((IChannel)(object)tChannel).
    GetProperty&lt;ChannelParameterCollection&gt;().
    Add(federatedClientCredentialsParameter);
</code></pre>

<p>was the source of the exception, and that the <code>GetProperty</code> call was returning <code>null</code>.  So, WTF?  Turns out that if I turn on Message security and set the client credential type to <code>IssuedToken</code> then this property now exists in the <code>ClientFactory</code> (protip:  There is no ""SetProperty"" equivalent in IChannel, the bastard).</p>

<pre class=""lang-xml prettyprint-override""><code>&lt;binding name=""OMGWTFLOL22"" transferMode=""Streamed"" &gt;
    &lt;security mode=""Message""&gt;
        &lt;message clientCredentialType=""IssuedToken""/&gt;
    &lt;/security&gt;
&lt;/binding&gt;
</code></pre>

<p>Sweet. No more NREs.  However, now my client is <em>faulted at birth</em> (still love him, tho).  Digging through WCF diagnostics (protip:  make your worst enemies do this after crushing them and driving them before you but right before enjoying the lamentations of their women and children), I see it's because of a security mismatch between the server and client.</p>

<blockquote>
  <p>The requested upgrade is not supported by 'net.tcp://localhost:49627/MyService'. This could be due to mismatched bindings (for example security enabled on the client and not on the server).</p>
</blockquote>

<p>Checking the host's diags (again: crush, drive, read logs, enjoy lamentations), I see this is true</p>

<blockquote>
  <p>Protocol Type application/ssl-tls was sent to a service that does not support that type of upgrade.</p>
</blockquote>

<p>""Well, self,"" I says, ""I'll just turn on Message security on the host!""  And I do.  <sup><sub>If you want to know what it looks like, it's an exact copy of the client config.  Look up.</sub></sup></p>

<p>Result:  <strong>Kaboom.</strong></p>

<blockquote>
  <p>The binding ('NetTcpBinding','<a href=""http://tempuri.org/"" rel=""noreferrer"">http://tempuri.org/</a>') supports streaming which cannot be configured together with message level security.  Consider choosing a different transfer mode or choosing the transport level security.</p>
</blockquote>

<p>So, <strong>my host cannot be both streamed and secured via tokens</strong>.  Catch-22.</p>

<p><strong>tl;dr:  How can I secure a streamed net.tcp WCF endpoint using WIF???</strong></p>
","Catch-22 prevents streamed TCP WCF service securable by WIF; ruining my Christmas, mental health",0.03435187
10548988,3005,103,"<p>Isn't <code>var</code> a keyword in C#? But why can I do this:</p>

<pre><code>public class var { }

public class main
{
    public static void main(string[] args)
    {
        var testVar = new var();
    }
}
</code></pre>

<p>The <code>var</code> that is used in the code is the <code>var</code> class that is declared before the <code>main</code> class. And the compiler doesn't even complain.</p>

<p>While when I do this:</p>

<pre><code>public class int { }
</code></pre>

<p>or this:</p>

<pre><code>public class true { }
</code></pre>

<p>The compiler said that <code>int</code> or <code>true</code> is a keyword and cannot be used like that. Why is it not the same with <code>var</code>?</p>
","Why can I create a class named ""var""?",0.03427621
20115672,3246,109,"<p>Here is my code: </p>

<pre><code>class A {
    static A obj = new A();
    static int num1;
    static int num2=0;

    private A() {
        num1++;
        num2++;
    }
    public static A getInstance() {
        return obj;
    }
}

public class Main{
    public static void main(String[] arg) {
        A obj = A.getInstance();
        System.out.println(obj.num1);
        System.out.println(obj.num2);
    }
}
</code></pre>

<p>The output is <code>1 0</code>, but I can't understand.</p>

<p>Can somebody explain it to me?</p>
",How does the static modifier affect this code?,0.03357979
34987370,6332,210,"<p>In CSS, <code>*</code> will match any element.</p>

<p>Frequently, <code>*|*</code> is used instead of <code>*</code> to match all elements. This is generally used for testing purposes.</p>

<p>What is the difference between <code>*</code> and <code>*|*</code> in CSS?</p>
",What is the difference between * and *|* in CSS?,0.03316488
28277982,4084,135,"<p>In the process of answering <a href=""https://stackoverflow.com/q/28266382/3959454"">another question</a> I stumbled upon slightly different wordings for <code>std::vector::erase()</code> and <code>std::deque::erase()</code>. </p>

<p>This is what C++14 says about <code>std::deque::erase</code> (<code>[deque.modifiers]/4-6</code>, emphasis mine):</p>

<blockquote>
  <p><em>Effects:</em> ...</p>
  
  <p><em>Complexity:</em> The number of calls to the destructor is the same as the number of elements erased, but
  The number of calls to the <strong>assignment operator</strong> is no more than the lesser of the number of elements
  Before the erased elements and the number of elements after the erased elements.</p>
  
  <p><em>Throws:</em> Nothing unless an exception is thrown by the copy constructor, move constructor, assignment operator, or move assignment operator of <code>T</code>.</p>
</blockquote>

<p>And here is what it says about <code>std::vector::erase</code> (<code>[vector.modifiers]/3-5</code>):</p>

<blockquote>
  <p><em>Effects:</em> ...</p>
  
  <p><em>Complexity:</em> The destructor of <code>T</code> is called the number of times equal to the number of the elements erased, but the <strong>move assignment operator</strong> of <code>T</code> is called the number of times equal to the number of elements in the vector after the erased elements.</p>
  
  <p><em>Throws:</em> Nothing unless an exception is thrown by the copy constructor, move constructor, assignment operator, or move assignment operator of <code>T</code>.</p>
</blockquote>

<p>As you can see, the exception specifications for both of them are the same, but for <code>std::vector</code> it's explicitly mentioned that move assignment operator is called.</p>

<p>There's also requirement for <code>T</code> to be <code>MoveAssignable</code> for <code>erase()</code> to work with both <code>std::vector</code> and <code>std::deque</code> (Table 100), but this doesn't imply the presence of the move assignment operator: one can define a copy assignment operator, and not define move assignment operator, and this class will be <code>MoveAssignable</code>.</p>

<p>Just in case, I checked with GCC and Clang, and indeed <code>std::vector::erase()</code> calls copy assignment operator if there's no move assignment operator, and <code>std::deque::erase()</code> does the same (<a href=""http://coliru.stacked-crooked.com/a/c9377a2ee408fa16"" rel=""nofollow noreferrer"">DEMO</a>).</p>

<p>So the question is: did I miss something, or this is an (editorial) issue in the standard?</p>

<p><strong>Update:</strong>
I've submitted an <a href=""http://www.open-std.org/jtc1/sc22/wg21/docs/lwg-active.html#2477"" rel=""nofollow noreferrer"">LWG issue #2477</a>.</p>
",Copy/move assignment in std::vector::erase() and std::deque::erase(),0.03305583
16349925,3209,106,"<p>I am new to competitive programming, and I noticed frequently, many of the great coders have these four lines in their code (particularly in those involving arrays):</p>

<pre><code>int di[] = { 1, -1, 0, 0, 1, -1, 1, -1 };
int dj[] = { 0, 0, 1, -1, 1, -1, -1, 1 };
int diK[] = { -2, -2, -1, 1, 2, 2, 1, -1 };
int djK[] = { -1, 1, 2, 2, 1, -1, -2, -2 };
</code></pre>

<p>What does this really signify and what is technique used for?</p>
",What is the significance of initializing direction arrays below with given values when developing chess program?,0.0330321
27606179,3057,100,"<p>I inherited a website, and just came across this curiosity:</p>

<pre><code>&lt;a href=""/delete""  onClick=""jamoscript:return confirm('Do you really want to do that?');""&gt;Delete all&lt;/a&gt;
</code></pre>

<p>I can display the page containing it and click the link to get the confirmation dialog box exactly the same as I do when I change ""<code>jamoscript</code>"" to ""<code>javascript</code>"". No diagnostics are displayed in the Firebug console, either when the page is loaded or when the link is clicked. What the hey? Googling for jamoscript doesn't turn up anything interesting.</p>

<p>Can anybody explain this behavior?</p>
",Why don't browsers throw an error when any other word is used in place of 'javascript' in the value of onclick?,0.03271181
10905350,3641,118,"<p>Boot up your interpreter/console and try the comparison</p>

<pre><code>&gt; "",,,"" == Array(4)
True
</code></pre>

<p>Why?  At first I thought maybe since you could think of "",,,"" as an array of four characters with a '\0' terminating slice, that might be why, but</p>

<pre><code>&gt; ""..."" == Array(4)
</code></pre>

<p>Returns ""False"".  So... why?  I know it's some idiosyncratic bit of duck typing in Javascript, but just curious what underlines this behavior.  Gleaned this from Zed Shaw's excellent <a href=""http://vimeo.com/43380467"" rel=""nofollow noreferrer"">presentation here btw</a>.</p>
","Why does "",,,"" == Array(4) in Javascript?",0.03240868
2186101,7302,235,"<p>I noticed in <code>System.Threading.TimerBase.Dipose()</code> the method has a <code>try{} finally{}</code> block but the <code>try{}</code> is empty.</p>

<p>Is there any value in using <code>try{} finally{}</code> with an empty try?</p>

<p><a href=""http://labs.developerfusion.co.uk/SourceViewer/browse.aspx?assembly=SSCLI&amp;namespace=System.Threading&amp;type=TimerBase"" rel=""noreferrer"">http://labs.developerfusion.co.uk/SourceViewer/browse.aspx?assembly=SSCLI&amp;namespace=System.Threading&amp;type=TimerBase</a></p>

<pre><code>[ReliabilityContract(Consistency.WillNotCorruptState, Cer.MayFail)]
internal bool Dispose(WaitHandle notifyObject)
{
    bool status = false;
    bool bLockTaken = false;
    RuntimeHelpers.PrepareConstrainedRegions();
    try {
    }
    finally {
        do {
            if (Interlocked.CompareExchange(ref m_lock, 1, 0) == 0) {
                bLockTaken = true;
                try {
                    status = DeleteTimerNative(notifyObject.SafeWaitHandle);
                }
                finally {
                    m_lock = 0;
                }
            }
            Thread.SpinWait(1);
            // yield to processor
        }
        while (!bLockTaken);
        GC.SuppressFinalize(this);
    }

    return status;
}
</code></pre>
",Why use try {} finally {} with an empty try block?,0.03218296
9284350,4630,149,"<p>When I was looking at answers to <a href=""https://stackoverflow.com/questions/9201445/python-best-way-to-keep-track-of-results-from-loop"">this question</a>, I found I didn't understand my own answer.</p>

<p>I don't really understand how this is being parsed. Why does the second example return False?</p>

<pre><code>&gt;&gt;&gt; 1 in [1,0]             # This is expected
True
&gt;&gt;&gt; 1 in [1,0] == True     # This is strange
False
&gt;&gt;&gt; (1 in [1,0]) == True   # This is what I wanted it to be
True
&gt;&gt;&gt; 1 in ([1,0] == True)   # But it's not just a precedence issue!
                           # It did not raise an exception on the second example.

Traceback (most recent call last):
  File ""&lt;pyshell#4&gt;"", line 1, in &lt;module&gt;
    1 in ([1,0] == True)
TypeError: argument of type 'bool' is not iterable
</code></pre>

<p>Thanks for any help. I think I must be missing something really obvious.</p>

<hr>

<p>I think this is subtly different to the linked duplicate:</p>

<p><a href=""https://stackoverflow.com/questions/6074018/why-does-the-expression-0-0-0-return-false-in-python"">Why does the expression 0 &lt; 0 == 0 return False in Python?</a>.</p>

<p>Both questions are to do with human comprehension of the expression. There seemed to be two ways (to my mind) of evaluating the expression. Of course neither were correct, but in my example, the last interpretation is impossible.</p>

<p>Looking at <code>0 &lt; 0 == 0</code> you could imagine each half being evaluated and making sense as an expression:</p>

<pre><code>&gt;&gt;&gt; (0 &lt; 0) == 0
True
&gt;&gt;&gt; 0 &lt; (0 == 0)
True
</code></pre>

<p>So the link answers why this evaluates <code>False</code>:</p>

<pre><code>&gt;&gt;&gt; 0 &lt; 0 == 0
False
</code></pre>

<p>But with my example <code>1 in ([1,0] == True)</code> doesn't make sense as an expression, so instead of there being two (admittedly wrong) possible interpretations, only one seems possible:</p>

<pre><code>&gt;&gt;&gt; (1 in [1,0]) == True
</code></pre>
","Why does (1 in [1,0] == True) evaluate to False?",0.03218143
13532784,4172,134,"<p>I was somehow surprised that the following code compiles and runs (vc2012 &amp; gcc4.7.2)</p>

<pre><code>class Foo {
    struct Bar { int i; };
public:
    Bar Baz() { return Bar(); }
};

int main() {
    Foo f;
    // Foo::Bar b = f.Baz();  // error
    auto b = f.Baz();         // ok
    std::cout &lt;&lt; b.i;
}
</code></pre>

<p>Is it correct that this code compiles fine? And why is it correct? Why can I use <code>auto</code> on a private type, while I can't use its name (as expected)?</p>
",Why can I use auto on a private type?,0.03211889
19956665,3394,108,"<p>All port operations in Rebol 3 are asynchronous.  The only way I can find to do synchronous communication is calling <code>wait</code>.</p>

<p>But the problem with calling wait in this case is that it will check events for all open ports (even if they are not in the port block passed to wait).  Then they call their responding event handlers, but a read/write could be done in one of those event handlers.  That could result in recursive calls to ""wait"".</p>

<p>How do I get around this?</p>
",Avoiding recursion when reading/writing a port synchronously?,0.03182086
15607873,3057,97,"<p>Recently I came across <code>* *</code> in <a href=""http://en.wikipedia.org/wiki/Cascading_Style_Sheets"" rel=""noreferrer"">CSS</a>.</p>

<p>Site reference - <a href=""http://semlabs.co.uk/journal/how-to-stop-your-wordpress-blog-getting-hacked"" rel=""noreferrer"">Site Link</a>.</p>

<p>For a single <code>*</code> usage in CSS style sheet, Internet and Stack Overflow is flooded with examples, but I am not sure about using two <code>* *</code> symbol in CSS.</p>

<p>I googled it, but unable to find any relevant information about this, as a single <code>*</code> selects all elements, but I am not sure why the site used it twice. What is the missing part for this, and why is this hack used (if it is a hack)?</p>
",What does the * * CSS selector do?,0.03173045
26914692,14029,445,"<p>If I have an <code>EnumeratorT</code> and a corresponding <code>IterateeT</code> I can run them together:</p>

<pre><code>val en: EnumeratorT[String, Task] = EnumeratorT.enumList(List(""a"", ""b"", ""c""))
val it: IterateeT[String, Task, Int] = IterateeT.length

(it &amp;= en).run : Task[Int]
</code></pre>

<p>If the enumerator monad is ""bigger"" than the iteratee monad, I can use <code>up</code> or, more generally, <code>Hoist</code> to ""lift"" the iteratee to match:</p>

<pre><code>val en: EnumeratorT[String, Task] = ...
val it: IterateeT[String, Id, Int] = ...

val liftedIt = IterateeT.IterateeTMonadTrans[String].hoist(
  implicitly[Task |&gt;=| Id]).apply(it)
(liftedIt &amp;= en).run: Task[Int]
</code></pre>

<p>But what do I do when the iteratee monad is ""bigger"" than the enumerator monad?</p>

<pre><code>val en: EnumeratorT[String, Id] = ...
val it: IterateeT[String, Task, Int] = ...

it &amp;= ???
</code></pre>

<p>There doesn't seem to be a <code>Hoist</code> instance for <code>EnumeratorT</code>, nor any obvious ""lift"" method.</p>
","Scalaz iteratees: ""Lifting"" `EnumeratorT` to match `IterateeT` for a ""bigger"" monad",0.03172001
52146115,4070,129,"<p>I saw <a href=""https://en.cppreference.com/w/cpp/types/numeric_limits"" rel=""noreferrer"">this example in cppreference's documentation for <code>std::numeric_limits</code></a></p>

<pre><code>#include &lt;limits&gt;
#include &lt;iostream&gt;

int main() 
{
    std::cout &lt;&lt; ""type\tlowest()\tmin()\t\tmax()\n\n"";

    std::cout &lt;&lt; ""uchar\t""
              &lt;&lt; +std::numeric_limits&lt;unsigned char&gt;::lowest() &lt;&lt; '\t' &lt;&lt; '\t'
              &lt;&lt; +std::numeric_limits&lt;unsigned char&gt;::min() &lt;&lt; '\t' &lt;&lt; '\t'
              &lt;&lt; +std::numeric_limits&lt;unsigned char&gt;::max() &lt;&lt; '\n';
    std::cout &lt;&lt; ""int\t""
              &lt;&lt; std::numeric_limits&lt;int&gt;::lowest() &lt;&lt; '\t'
              &lt;&lt; std::numeric_limits&lt;int&gt;::min() &lt;&lt; '\t'
              &lt;&lt; std::numeric_limits&lt;int&gt;::max() &lt;&lt; '\n';
    std::cout &lt;&lt; ""float\t""
              &lt;&lt; std::numeric_limits&lt;float&gt;::lowest() &lt;&lt; '\t'
              &lt;&lt; std::numeric_limits&lt;float&gt;::min() &lt;&lt; '\t'
              &lt;&lt; std::numeric_limits&lt;float&gt;::max() &lt;&lt; '\n';
    std::cout &lt;&lt; ""double\t""
              &lt;&lt; std::numeric_limits&lt;double&gt;::lowest() &lt;&lt; '\t'
              &lt;&lt; std::numeric_limits&lt;double&gt;::min() &lt;&lt; '\t'
              &lt;&lt; std::numeric_limits&lt;double&gt;::max() &lt;&lt; '\n';
}
</code></pre>

<p>I don't understand the ""+"" operator in </p>

<pre><code>&lt;&lt; +std::numeric_limits&lt;unsigned char&gt;::lowest()
</code></pre>

<p>I have tested it, replaced it with ""-"", and that also worked.
What is the use of such a ""+"" operator?</p>
","What is the purpose of a unary ""+"" before a call to std::numeric_limits<unsigned char> members?",0.03169533
23796515,3005,95,"<p>I'm having an issue where the sourcemaps generated by Webpack using the <code>inline-source-map</code> configuration setting are off by one line when I use the Chrome devtools debugger.
Webpack is set up inside a Ruby on Rails application to generate a concatenated, unminified JavaScript file composed of a couple dozen modules.  Most of those modules are ReactJS components, and are parsed by the <code>jsx</code> loader.  The output from Webpack is then included in the <code>application.js</code> file along with some other JavaScript libraries generated by gems.</p>

<p>When I use <code>eval-source-map</code>, there is no problem.  Something about the use of <code>inline-source-map</code> causes the line numbers to be thrown off by one.</p>

<p>Inspecting JavaScript that is not a React component still has this issue, so I don't think it's related to the use of jsx.</p>
","Sourcemaps off by one line in Chrome, with Ruby on Rails, Webpack, and React JS",0.03161398
19128856,3354,106,"<p><strong>Background</strong></p>

<p>As noted in <a href=""https://stackoverflow.com/questions/19059831/asynchronous-iteratee-processing-in-scalaz"">this question</a>, I'm using Scalaz 7 iteratees to process a large (i.e., unbounded) stream of data in constant heap space.</p>

<p>My code looks like this:</p>

<pre><code>type ErrorOrT[M[+_], A] = EitherT[M, Throwable, A]
type ErrorOr[A] = ErrorOrT[IO, A]

def processChunk(c: Chunk, idx: Long): Result

def process(data: EnumeratorT[Chunk, ErrorOr]): IterateeT[Vector[(Chunk, Long)], ErrorOr, Vector[Result]] =
  Iteratee.fold[Vector[(Chunk, Long)], ErrorOr, Vector[Result]](Nil) { (rs, vs) =&gt;
    rs ++ vs map { 
      case (c, i) =&gt; processChunk(c, i) 
    }
  } &amp;= (data.zipWithIndex mapE Iteratee.group(P))
</code></pre>

<p><strong>The Problem</strong> </p>

<p>I seem to have run into a memory leak, but I'm not familiar enough with Scalaz/FP to know whether the bug is in Scalaz or in my code. Intuitively, I expect this code to require only (on the order of) <em>P</em> times the <code>Chunk</code>-size space.</p>

<p>Note: I found <a href=""https://stackoverflow.com/questions/16228154/scalaz-7-iteratee-to-process-large-zip-file-outofmemoryerror"">a similar question</a> in which an <code>OutOfMemoryError</code> was encountered, but my code is not using <code>consume</code>.</p>

<p><strong>Testing</strong></p>

<p>I ran some tests to try and isolate the problem. To summarize, the leak only appears to arise when both <code>zipWithIndex</code> and <code>group</code> are used.</p>

<pre><code>// no zipping/grouping
scala&gt; (i1 &amp;= enumArrs(1 &lt;&lt; 25, 128)).run.unsafePerformIO
res47: Long = 4294967296

// grouping only
scala&gt; (i2 &amp;= (enumArrs(1 &lt;&lt; 25, 128) mapE Iteratee.group(4))).run.unsafePerformIO
res49: Long = 4294967296

// zipping and grouping
scala&gt; (i3 &amp;= (enumArrs(1 &lt;&lt; 25, 128).zipWithIndex mapE Iteratee.group(4))).run.unsafePerformIO
java.lang.OutOfMemoryError: Java heap space

// zipping only
scala&gt; (i4 &amp;= (enumArrs(1 &lt;&lt; 25, 128).zipWithIndex)).run.unsafePerformIO
res51: Long = 4294967296

// no zipping/grouping, larger arrays
scala&gt; (i1 &amp;= enumArrs(1 &lt;&lt; 27, 128)).run.unsafePerformIO
res53: Long = 17179869184

// zipping only, larger arrays
scala&gt; (i4 &amp;= (enumArrs(1 &lt;&lt; 27, 128).zipWithIndex)).run.unsafePerformIO
res54: Long = 17179869184
</code></pre>

<p>Code for the tests:</p>

<pre><code>import scalaz.iteratee._, scalaz.effect.IO, scalaz.std.vector._

// define an enumerator that produces a stream of new, zero-filled arrays
def enumArrs(sz: Int, n: Int) = 
  Iteratee.enumIterator[Array[Int], IO](
    Iterator.continually(Array.fill(sz)(0)).take(n))

// define an iteratee that consumes a stream of arrays 
// and computes its length
val i1 = Iteratee.fold[Array[Int], IO, Long](0) { 
  (c, a) =&gt; c + a.length 
}

// define an iteratee that consumes a grouped stream of arrays 
// and computes its length
val i2 = Iteratee.fold[Vector[Array[Int]], IO, Long](0) { 
  (c, as) =&gt; c + as.map(_.length).sum 
}

// define an iteratee that consumes a grouped/zipped stream of arrays
// and computes its length
val i3 = Iteratee.fold[Vector[(Array[Int], Long)], IO, Long](0) {
  (c, vs) =&gt; c + vs.map(_._1.length).sum
}

// define an iteratee that consumes a zipped stream of arrays
// and computes its length
val i4 = Iteratee.fold[(Array[Int], Long), IO, Long](0) {
  (c, v) =&gt; c + v._1.length
}
</code></pre>

<p><strong>Questions</strong></p>

<ul>
<li>Is the bug in my code?</li>
<li>How can I make this work in constant heap space?</li>
</ul>
",Avoiding memory leaks with Scalaz 7 zipWithIndex/group enumeratees,0.03160405
23448150,10176,321,"<p>Here's the scenario: I've written some code with a type signature and GHC complains could not deduce x ~ y for some <code>x</code> and <code>y</code>. You can usually throw GHC a bone and simply add the isomorphism to the function constraints, but this is a bad idea for several reasons:</p>

<ol>
<li>It does not emphasize understanding the code.</li>
<li>You can end up with 5 constraints where one would have sufficed (for example, if the 5 are implied by one more specific constraint)</li>
<li>You can end up with bogus constraints if you've done something wrong or if GHC is being unhelpful</li>
</ol>

<p>I just spent several hours battling case 3. I'm playing with <a href=""https://hackage.haskell.org/package/syntactic-2.0"" rel=""noreferrer""><code>syntactic-2.0</code></a>, and I was trying to define a domain-independent version of <code>share</code>, similar to the version defined in <a href=""https://github.com/emilaxelsson/syntactic/blob/2.0/examples/NanoFeldspar.hs"" rel=""noreferrer""><code>NanoFeldspar.hs</code></a>.</p>

<p>I had this:</p>

<pre><code>{-# LANGUAGE GADTs, FlexibleContexts, TypeOperators #-}
import Data.Syntactic

-- Based on NanoFeldspar.hs
data Let a where
    Let :: Let (a :-&gt; (a -&gt; b) :-&gt; Full b)

share :: (Let :&lt;: sup,
          Domain a ~ sup,
          Domain b ~ sup,
          SyntacticN (a -&gt; (a -&gt; b) -&gt; b) fi) 
      =&gt; a -&gt; (a -&gt; b) -&gt; a
share = sugarSym Let
</code></pre>

<p>and GHC <code>could not deduce (Internal a) ~ (Internal b)</code>, which is certainly not what I was going for. So either I had written some code I didn't intend to (which required the constraint), or GHC wanted that constraint due to some other constraints I had written.</p>

<p>It turns out I needed to add <code>(Syntactic a, Syntactic b, Syntactic (a-&gt;b))</code> to the constraint list, none of which imply <code>(Internal a) ~ (Internal b)</code>. I basically stumbled upon the correct constraints; I still don't have a systematic way to find them.</p>

<p>My questions are:</p>

<ol>
<li>Why did GHC propose that constraint? Nowhere in syntactic is there a constraint <code>Internal a ~ Internal b</code>, so where did GHC pull that from?</li>
<li>In general, what techniques can be used to trace the origin of a constraint which GHC believes it needs? Even for constraints that I <em>can</em> discover myself, my approach is essentially brute forcing the offending path by physically writing down recursive constraints. This approach is basically going down an infinite rabbit hole of constraints and is about the least efficient method I can imagine.</li>
</ol>
",Techniques for Tracing Constraints,0.03154481
34950111,3926,123,"<p>I'm getting this note in the build whenever I do an inject into a kotlin class (btw, I have a mixed android project with both kotlin and java).</p>

<p>For example, after this gradle task: <code>compileStagingDebugJavaWithJavac</code> (StagingDebug is my build variant), I get this message:</p>

<blockquote>
  <p>""Note: Generating a MembersInjector or Factory for com.packageNameXXX.CourseDiscoveryMapFragment. Prefer to run the dagger processor over that class instead.""</p>
</blockquote>

<p>My <strong>CourseDiscoveryMapFragment</strong> code can be seen here:</p>

<pre><code>class CourseDiscoveryMapFragment : Fragment(){

    @Inject
    lateinit var presenter: CourseDiscoveryMapPresenter

    lateinit var mapView: MapView

    override fun onCreateView(inflater: LayoutInflater, container: ViewGroup?, savedInstanceState: Bundle?): View? {

        val view = inflater.inflate(R.layout.fragment_discovery_map, container, false)

        MapsInitializer.initialize(activity)

        mapView = view.mapView
        mapView.onCreate(savedInstanceState?.getBundle(BUNDLE_KEY_MAP_STATE))

        (activity as BaseActivity)
                .activityComponent.inject(this)
}
</code></pre>

<p>And my <strong>ActivityComponent</strong> is :</p>

<pre><code>@ActivityScope
@Subcomponent(modules = ActivityModule.class)
public interface ActivityComponent {

    void inject(BaseActivity baseActivity);

    void inject(CourseDiscoveryMapFragment fragment);

    //Exposed to sub-graphs.
    Activity activity();
}
</code></pre>

<p>So, I'm having dagger component and modules written in Java, while having dagger injections in Kotlin.</p>

<p>Is this anything that I should be worried about?</p>

<p>Thank you. </p>
","""Prefer to run the dagger processor over that class instead"" in Kotlin",0.0313296
53984116,4652,145,"<p>If you execute the following statement in Python 3.7, it will (from my testing) print <code>b</code>:</p>

<pre><code>if None.__eq__(""a""):
    print(""b"")
</code></pre>

<p>However, <code>None.__eq__(""a"")</code> evaluates to <code>NotImplemented</code>.</p>

<p>Naturally, <code>""a"".__eq__(""a"")</code> evaluates to <code>True</code>, and <code>""b"".__eq__(""a"")</code> evaluates to <code>False</code>.</p>

<p>I initially discovered this when testing the return value of a function, but didn't return anything in the second case -- so, the function returned <code>None</code>.</p>

<p>What's going on here?</p>
","Why does `if None.__eq__(""a"")` seem to evaluate to True (but not quite)?",0.03116939
30453656,9538,297,"<p>I would like to store the motion capture data from Kinect 2 as a BVH file. I found code which does so for Kinect 1 which can be found <a href=""https://bitbucket.org/nguyenivan/kinect2bvh.v2/src/d19ccd4e76318e86241351adada6b7752aa9e1b5?at=master"" rel=""noreferrer"">here</a>. I went through the code and found several things that I was not able to understand.
For example, in the mentioned code I've tried to understand what exactly the Skeleton <strong><code>skel</code></strong> object, found in several places in the code, actually is. If not, are there any known application available to accomplish the intended?</p>

<p>EDIT: I tried to change Skeleton skel to Body skel which I think is the correspondant object for kinect SDK 2.0. However I've got an error when I try to get the position of the body:</p>

<pre><code>tempMotionVektor[0] = -Math.Round( skel.Position.X * 100,2);
tempMotionVektor[1] = Math.Round( skel.Position.Y * 100,2) + 120;
tempMotionVektor[2] = 300 - Math.Round( skel.Position.Z * 100,2);
</code></pre>

<p>I've gotten errors when calling the function Position for the Body skel. How can I retrieve the X, Y, Z of the skeleton in sdk 2.0?? I tried to change the above three lines to:</p>

<pre><code>tempMotionVektor[0] = -Math.Round(skel.Joints[0].Position.X * 100, 2);
tempMotionVektor[1] = Math.Round(skel.Joints[0].Position.Y * 100, 2) + 120;
tempMotionVektor[2] = 300 - Math.Round(skel.Joints[0].Position.Z * 100, 2);
</code></pre>

<p>EDIT: Basically I managed to store the a bvh file after combining bodyBasicsWPF and kinect2bvh. However, it seems that the skeleton I am storing is not efficient. There are strange movements in the elbows. I am trying to understand if I have to change something in the file <a href=""https://bitbucket.org/nguyenivan/kinect2bvh.v2/src/d19ccd4e76318e86241351adada6b7752aa9e1b5/erstesKinectProjekt/KinectSkeletonBVH.cs?at=master"" rel=""noreferrer"">kinectSkeletonBVH.cp</a>. More specifically, what are the changes in the joint axis orientation for the kinect 2 version. How can I change the following line: <code>skel.BoneOrientations[JointType.ShoulderCenter].AbsoluteRotation.Quaternion;</code>  I tried to change that line with <code>skel.JointOrientations[JointType.ShoulderCenter].Orientation</code>. Am I right? I am using the following code to add the joint to BVHBone objects:</p>

<pre><code>BVHBone hipCenter = new BVHBone(null, JointType.SpineBase.ToString(), 6, TransAxis.None, true);
BVHBone hipCenter2 = new BVHBone(hipCenter, ""HipCenter2"", 3, TransAxis.Y, false);
BVHBone spine = new BVHBone(hipCenter2, JointType.SpineMid.ToString(), 3, TransAxis.Y, true);
BVHBone shoulderCenter = new BVHBone(spine, JointType.SpineShoulder.ToString(), 3, TransAxis.Y, true);

BVHBone collarLeft = new BVHBone(shoulderCenter, ""CollarLeft"", 3, TransAxis.X, false);
BVHBone shoulderLeft = new BVHBone(collarLeft, JointType.ShoulderLeft.ToString(), 3, TransAxis.X, true);
BVHBone elbowLeft = new BVHBone(shoulderLeft, JointType.ElbowLeft.ToString(), 3, TransAxis.X, true);
BVHBone wristLeft = new BVHBone(elbowLeft, JointType.WristLeft.ToString(), 3, TransAxis.X, true);
BVHBone handLeft = new BVHBone(wristLeft, JointType.HandLeft.ToString(), 0, TransAxis.X, true);

BVHBone neck = new BVHBone(shoulderCenter, ""Neck"", 3, TransAxis.Y, false);
BVHBone head = new BVHBone(neck, JointType.Head.ToString(), 3, TransAxis.Y, true);
BVHBone headtop = new BVHBone(head, ""Headtop"", 0, TransAxis.None, false);
</code></pre>

<p>I can't understand where inside the code <code>the axis for every Joint</code> is calculated.</p>
",Store Kinect's v2.0 Motion to BVH File,0.0311386
46050134,3791,118,"<p>I recently came across this app <a href=""https://play.google.com/store/apps/details?id=com.azefsw.purchasedapps"" rel=""noreferrer"">Purchase Apps</a>, which is somehow able to retrieve apps I've paid for in google play after I signed in using my google account. </p>

<p>I'm trying to find out how it is being done as I want to build a similar app, but for the free apps which were downloaded. </p>

<p>However, I can't find which OAuth API Scope was used for retrieving that information, even after going through <a href=""https://developers.google.com/identity/protocols/googlescopes"" rel=""noreferrer"">the entire list of APIs</a>.</p>

<p><a href=""https://i.stack.imgur.com/cc8qKl.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/cc8qKl.jpg"" alt=""Google Sign in asking for access to androidmarket""></a></p>

<hr>

<p>EDIT:
I'm putting a new bounty on this question, as suggested by a similar question I've asked about <a href=""https://stackoverflow.com/q/49620194/878126""><strong>here</strong></a>, and because here and there I don't see a real answer about how to do it, and what can be done with it.</p>

<p>I'd like to refine the questions into multiple pieces:</p>

<ol>
<li><p>What is the API that can be used to get information of purchased apps? Where can I read about it? Please show a full, working example of how to do it.</p></li>
<li><p>Can it do more ? Maybe perform search? Maybe show free apps that were installed? Maybe the time they were installed and uninstalled? And the categories of those apps?</p></li>
<li><p>Are there any special requirements for using this API ?</p></li>
</ol>

<hr>

<p>EDIT: I'm putting a max bounty on this, because no matter how much I've read and tried, I still failed to make a POC that can query the apps from the Play Store that the user has ever downloaded (name, package name, date installed and/or removed, icon URL, price...), including both paid and free apps.</p>

<p>If anyone finds a working sample, show how it's done, and also show how you've found about it (documentation or anything that has led you to the solution). I can't find it anywhere, and the current solutions here are too vague for me to start from.</p>
",How to get list of downloaded apps (paid/free) by a user from Google Play?,0.03112635
33439897,4628,144,"<p>In C++ it's actually possible to throw an exception by value without allocating memory on a heap, so this situation makes sense. But in .NET framework <code>OutOfMemoryException</code> is a reference type, therefore it is allocated on a heap. 
How does .NET framework allocates memory for <code>OutOfMemoryException</code> when there is not enough memory to create a new object?</p>
",How does .NET framework allocate memory for OutOfMemoryException?,0.03111495
71332,6809,211,"<p>I'm making a method combining Scrum with the OpenUP lifecycle and deliverables. I also want to keep the OpenUP disciplines apart from ""Project Management"".  I can ""hide"" it so that it's not immediately obvious in my generated method site. But when you then navigate to the ""Risk List"" artefact for example the PM is still seen as contributing, and if you click on the link, you get taken to the PM Discipline page.</p>

<p>How can I remove it completely from my method without deleting it from the OpenUP library which I'm consuming?</p>
",How do I delete a Discipline in EPF Composer 1.5?,0.0309884
11066050,6574,203,"<p>Pardon the funny title. I've created a little graphic demo of 200 balls bouncing and colliding, both against the walls and each other. You can see what I have currently here: <a href=""http://www.exeneva.com/html5/multipleBallsBouncingAndColliding/"" rel=""noreferrer"">http://www.exeneva.com/html5/multipleBallsBouncingAndColliding/</a></p>

<p>The problem is that whenever they collide with each other, they disappear. I'm not sure why. Can someone take a look and help me out?</p>

<p>UPDATE: Apparently the balls array has balls with coordinates of NaN. Below is the code where I push balls to the array. I'm not entirely sure how the coordinates are getting NaN.</p>

<pre><code>// Variables
var numBalls = 200;  // number of balls
var maxSize = 15;
var minSize = 5;
var maxSpeed = maxSize + 5;
var balls = new Array();
var tempBall;
var tempX;
var tempY;
var tempSpeed;
var tempAngle;
var tempRadius;
var tempRadians;
var tempVelocityX;
var tempVelocityY;

// Find spots to place each ball so none start on top of each other
for (var i = 0; i &lt; numBalls; i += 1) {
  tempRadius = 5;
  var placeOK = false;
  while (!placeOK) {
    tempX = tempRadius * 3 + (Math.floor(Math.random() * theCanvas.width) - tempRadius * 3);
    tempY = tempRadius * 3 + (Math.floor(Math.random() * theCanvas.height) - tempRadius * 3);
    tempSpeed = 4;
    tempAngle = Math.floor(Math.random() * 360);
    tempRadians = tempAngle * Math.PI/180;
    tempVelocityX = Math.cos(tempRadians) * tempSpeed;
    tempVelocityY = Math.sin(tempRadians) * tempSpeed;

    tempBall = {
      x: tempX, 
      y: tempY, 
      nextX: tempX, 
      nextY: tempY, 
      radius: tempRadius, 
      speed: tempSpeed,
      angle: tempAngle,
      velocityX: tempVelocityX,
      velocityY: tempVelocityY,
      mass: tempRadius
    };
    placeOK = canStartHere(tempBall);
  }
  balls.push(tempBall);
}
</code></pre>
",Why are my balls disappearing?,0.03087922
2481543,7117,217,"<p>I have recently noticed that a lot of JavaScript files on the Web start with a <code>;</code> immediately following the comment section.</p>

<p>For example, <a href=""http://plugins.jquery.com/project/ScrollTo"" rel=""noreferrer"">this jQuery plugin's</a> code starts with:</p>

<pre><code>/**
 * jQuery.ScrollTo
 * Copyright (c) 2007-2008 Ariel Flesler - aflesler(at)gmail(dot)com | http://flesler.blogspot.com
 * Dual licensed under MIT and GPL.
 * Date: 9/11/2008                                      
 .... skipping several lines for brevity...
 *
 * @desc Scroll on both axes, to different values
 * @example $('div').scrollTo( { top: 300, left:'+=200' }, { axis:'xy', offset:-20 } );
 */
;(function( $ ){
</code></pre>

<p>Why does the file need to start with a <code>;</code>? I see this convention in server-side JavaScript files as well.</p>

<p>What are the advantages and disadvantages of doing this?</p>
","Why does the JavaScript need to start with "";""?",0.03049038
4089284,11408,345,"<p>I was playing around in jsfiddle.net and I'm curious as to why this returns true?</p>

<pre><code>if(0 &lt; 5 &lt; 3) {
    alert(""True"");
}
</code></pre>

<p>So does this:</p>

<pre><code>if(0 &lt; 5 &lt; 2) {
    alert(""True"");
}
</code></pre>

<p>But this doesn't:</p>

<pre><code>if(0 &lt; 5 &lt; 1) {
    alert(""True"");
}
</code></pre>

<p>Is this quirk ever useful?</p>
",Why does (0 < 5 < 3) return true?,0.03024194
37012586,3253,98,"<p>I'm not sure what's causing this issue, but in a project, I'm building, the compiler is taking hours just to compile a module. The total size of my codebase is 352KB, but none of the modules are over 10KB large. I am using a Native port, but it's very trivial; I'm just fetching <code>Date.now()</code> with it.</p>

<p>Is there anything well-known that would cause the elm compiler to take forever to compile? I don't have many dependencies, but I'm using Html a lot. I would really appreciate any hints as to what would cause this.</p>

<h1>Edit</h1>

<p>So it turns out <strong>large case expressions</strong> will cause the optimizer to take a long time, as of 0.16. Here's the <a href=""https://groups.google.com/forum/#!topic/elm-discuss/2ySK77lKYss"" rel=""noreferrer"">discussion on Elm-Discuss</a> bringing up the issue, and a <a href=""https://gist.github.com/athanclark/0e29485cb245ff07a97730cfef365d10"" rel=""noreferrer"">gist of the nasty case match</a>.</p>

<p>I guess to be verbose and to keep a carrot out there, why would elm's compiler take this route for case-matching? What's the underlying machinery going on here? Why would the compiler take longer than an hour for optimizing 60+ pattern matches on a case statement?</p>
","Elm Compiler running forever, computer just getting hot",0.03012604
35296734,3570,107,"<p>I just had a rather unpleasant experience in our production environment, causing <code>OutOfMemoryErrors: heapspace..</code></p>

<p>I traced the issue to my use of <code>ArrayList::new</code> in a function.</p>

<p>To verify that this is actually performing worse than normal creation via a declared constructor (<code>t -&gt; new ArrayList&lt;&gt;()</code>), I wrote the following small method:</p>

<pre><code>public class TestMain {
  public static void main(String[] args) {
    boolean newMethod = false;
    Map&lt;Integer,List&lt;Integer&gt;&gt; map = new HashMap&lt;&gt;();
    int index = 0;

    while(true){
      if (newMethod) {
        map.computeIfAbsent(index, ArrayList::new).add(index);
     } else {
        map.computeIfAbsent(index, i-&gt;new ArrayList&lt;&gt;()).add(index);
      }
      if (index++ % 100 == 0) {
        System.out.println(""Reached index ""+index);
      }
    }
  }
}
</code></pre>

<p>Running the method with <code>newMethod=true;</code> will cause the method to fail with <code>OutOfMemoryError</code> just after index hits 30k. With <code>newMethod=false;</code> the program does not fail, but keeps pounding away until killed (index easily reaches 1.5 milion).</p>

<p>Why does <code>ArrayList::new</code> create so many <code>Object[]</code> elements on the heap that it causes <code>OutOfMemoryError</code> so fast?</p>

<p>(By the way - it also happens when the collection type is <code>HashSet</code>.)</p>
",Horrendous performance & large heap footprint of Java 8 constructor reference?,0.02997199
28885876,3486,103,"<p>I was testing some code on <a href=""http://coliru.stacked-crooked.com/"" rel=""nofollow noreferrer"">Coliru</a>, and I got a strange output. I went down the code and could reproduce it with this simple <a href=""http://coliru.stacked-crooked.com/a/66324d1cbd4985bf"" rel=""nofollow noreferrer"">piece of code</a>:</p>

<pre><code>int main()
{
    &amp;pi;
}
</code></pre>

<p>The output on g++:</p>

<p><img src=""https://i.stack.imgur.com/JlROt.png"" alt=""output on g++""></p>

<p>clang:</p>

<p><img src=""https://i.stack.imgur.com/BbE1J.png"" alt=""output on clang""></p>

<p>For instance, using just <code>pi</code> (without the address-of) shows the expected result:</p>

<pre><code>main.cpp:3:5: error: 'pi' was not declared in this scope
    pi;
    ^
</code></pre>

<p>I tried to reproduce this on my machine, using g++ 4.9.2 and on others sites but I could not.</p>

<p>Is this some bug on this site, some config of these compilers ?</p>

<p>And why only using the address-of operator (<code>&amp;</code>) shows this symbol ?</p>
",Compiler showing 'pi' symbol on error,0.02954676
4470131,3134,92,"<p>The company I work for uses C++ Builder 6.  We've been developing native code since conception. Our flagship product is written completely in native code.  </p>

<p>Enters the .NET Framework with its bells and whistles.  I fall, hook, line and sinker.  I convince management that .NET should absolutely be our new framework for all new software development and that we should start migrating our existing codeline ASAP.  With all the benefits it doesn't take much convincing.  They accept my proposal as usual.  </p>

<p>At this point I start developing my very first .NET application.  It's all going as planned.  The project is only one component of our product.  And so I get to the point of creating an installer for this new component.  As a company we pride ourselves in making things for the user as easy as possible.  Even Microsoft with thousands of developers don't create installers like we do.  When you install Microsoft CRM for instance, you will only get a list of failures and prerequisites that needs installing before you can continue.  Not us.  Never.  If you need something, we will install it for you.</p>

<p>This makes our installations feel so easy.  .NET Framework not installed?  No problem!  We'll do it for you.  Need SQL Native client?  Fine!</p>

<p>The issue is this, now that one single component of our solution is written in .NET, it complicates the installation process incredibly.  Before I can even get to installing our product, I need to do the following:</p>

<ul>
<li><p>Detect whether the prerequisite is installed</p></li>
<li><p>Install it if it isn't</p></li>
<li><p>Verify that it was installed successfully</p></li>
<li><p>Next prerequisite</p></li>
</ul>

<p>To install .NET Framework, I need the Windows Installer 4.5 first.  But there are different versions for the different OSes, so I add OS detection and launch the correct EXE.  Oh, .NET framework is already packaged with 2k8 and the installer exe cannot run on it, you have to run OCSetup.exe with parameters to install it.</p>

<p>And so it carries on.  Then SQL Express 2005 needs to be installed.  The dependencies increase once again.</p>

<p>I argue with management that even Microsoft don't make it this easy for the user.  Their response is that there is no reason for us to not be better than them in this way.  I can't argue with that except that I feel that there are very good reasons they've gone with their approach.</p>

<p>Suddenly, our installer is massive.  All the prerequisites for .NET, not even talking about 64 bit support which has a whole separate range of EXEs to install.  So now it gets to the point where we want users to be able to download a ""quick"" evaluation.  What a joke.  You need to download 500MB to get a 30MB application running.  The majority of the installation package is prerequisites.</p>

<p>Management feels that we have too many dependencies/prerequisites.  I understand completely.  They suggest we move away from the .NET framework, back into native land where things were still ""easy"" in terms of installation.  This is where the one part of me wants to stand up for .NET explaining the benefits in the big picture, the improved development experience, easier maintenance and overall code quality.  The other part of me agrees with them wholeheartedly!  Developing in .NET simply requires you to install too many other prerequisites which complicates the installation.</p>

<p>Yes, some of the .NET advocates will claim that everything should be installed on a patched and updated operating system.  This is true, but not all customers have this, and simply saying ""I'm sorry, update first"" just won't cut it.  Remember, we pride ourselves in the overall user experience.</p>

<p>We are now considering writing native code again and I know we're losing in terms of development speed and all the goodies of .NET.  But we are gaining in this area, be it small if you look at the big picture or not.  As we have native code development skills and .NET is actually new ground for us, it even makes sense to move back.</p>

<p>My question is this: what is your company's view on this issue if it even is an issue at all and what will the business case look like that I propose to management assuming I want to continue migrating all our products to .NET?</p>
",The case for or against .NET (the beast),0.02935546
12438786,11293,329,"<p>Take a look at the following two methods:</p>

<pre><code>public static void foo() {
    try {
        foo();
    } finally {
        foo();
    }
}

public static void bar() {
    bar();
}
</code></pre>

<hr>

<p>Running <code>bar()</code> clearly results in a <code>StackOverflowError</code>, but running <code>foo()</code> does not (the program just seems to run indefinitely). <em>Why is that?</em></p>
",Try-finally block prevents StackOverflowError,0.02913309
10133448,3247,94,"<p>I had made a daemon that used a very primitive form of <code>ipc</code> (telnet and send a String that had certain words in a certain order). I snapped out of it and am now using <code>JSON</code> to pass messages to a <code>Yesod</code> server. However, there were some things I really liked about my design, and I'm not sure what my choices are now.</p>

<p>Here's what I was doing:</p>

<pre><code>buildManager :: Phase -&gt; IO ()
buildManager phase = do
  let buildSeq = findSeq phase
      jid = JobID $ pack ""8""
      config = MkConfig $ Just jid
  flip C.catch exceptionHandler $ 
  runReaderT (sequence_ $ buildSeq &lt;*&gt; stages) config
  -- ^^ I would really like to keep the above line of code, or something like it.
  return ()
</code></pre>

<p>each function in buildSeq looked like this</p>

<pre><code>foo :: Stage -&gt; ReaderT Config IO ()

data Config = MkConfig (Either JobID Product) BaseDir JobMap
</code></pre>

<p><code>JobMap</code> is a <code>TMVar Map</code> that tracks information about current jobs.</p>

<p>so now, what I have are Handlers, that all look like this</p>

<pre><code>foo :: Handler RepJson
</code></pre>

<p><code>foo</code> represents a command for my daemon, each handler may have to process a different JSON object.</p>

<p>What I would like to do is send one <code>JSON</code> object that represents success, and another JSON object that espresses information about some exception.</p>

<p>I would like <code>foo</code>s helper function to be able to return an <code>Either</code>, but I'm not sure how I get that, plus the ability to terminate evaluation of my list of actions, <code>buildSeq</code>.</p>

<p>Here's the only choice I see</p>

<p>1) make sure <code>exceptionHandler</code> is in Handler. Put <code>JobMap</code> in the <code>App</code> record. Using <code>getYesod</code> alter the appropriate value in <code>JobMap</code> indicating details about the exception,
which can then be accessed by <code>foo</code></p>

<p>Is there a better way?</p>

<p>What are my other choices?</p>

<p>Edit: For clarity, I will explain the role of<code>Handler RepJson</code>. The server needs some way to accept commands such as <code>build</code> <code>stop</code> <code>report</code>. The client needs some way of knowing the results of these commands. I have chosen JSON as the medium with which the server and client communicate with each other. I'm using the Handler type just to manage the JSON in/out and nothing more.</p>
",Exceptions in Yesod,0.0289498
22273777,3115,90,"<p>I was attempting to do a Windows command prompt re-code in C#. I was wondering how the command prompt knows when to wait for the process started to exit, and when not to wait for the called process to exit.</p>

<p>For example, if you type in the command prompt ""notepad"", <a href=""http://en.wikipedia.org/wiki/Notepad_%28software%29"" rel=""noreferrer"">Notepad</a> will launch, but you can still execute other commands. However, if you open a utility such as more.com, ping.exe, or another utility, it will wait for the executing program to finish before letting you execute another command.</p>

<p>How does the command prompt know when to wait for exit, and how can this behavior be emulated in C#?</p>
",How does the command prompt know when to wait for exit?,0.02889246
47086406,3298,95,"<p>I was snooping through my MSP430 microcontroller's header files, and I ran into this in <code>&lt;setjmp.h&gt;</code>:</p>

<pre><code>/* r3 does not have to be saved */
typedef struct
{
    uint32_t __j_pc; /* return address */
    uint32_t __j_sp; /* r1 stack pointer */
    uint32_t __j_sr; /* r2 status register */
    uint32_t __j_r4;
    uint32_t __j_r5;
    uint32_t __j_r6;
    uint32_t __j_r7;
    uint32_t __j_r8;
    uint32_t __j_r9;
    uint32_t __j_r10;
    uint32_t __j_r11;
} jmp_buf[1]; /* size = 20 bytes */
</code></pre>

<p>I understand that it declares an anonymous struct and typedef's it to <code>jmp_buf</code>, but I can't figure out what the <code>[1]</code> is for. I know it declares <code>jmp_buf</code> to be an array with one member (of this anonymous struct), but I can't imagine what it's used for. Any ideas?</p>
",What's the purpose of this [1] at the end of struct declaration?,0.02880534
2710537,4351,125,"<p>Before you jump to conclusions, yes, this is programming related. It covers a situation that comes under the heading of, ""There, but for the grace of God, go you or I."" This is brand new territory for me so I'm asking for some serious help here.</p>

<p>A young man, <a href=""http://www.pressdemocrat.com/article/20100418/articles/100419536"" rel=""noreferrer"">Honza Ripa</a>, in a nearby town did the classic Dumb Thing two weeks after graduating from High School -- he dove into shallow water in the Russian River and had a <a href=""http://en.wikipedia.org/wiki/Spinal_cord_injury#Cervical_injuries"" rel=""noreferrer"">C-4/C-5 break</a>, sometimes called a Swimming Pool break. In a matter of seconds he went from an exceptional golfer and wrestler to a quadriplegic. (Read the story ... all of us should have been so lucky as to have a girlfriend like Brianna.) That was 10 months ago and he has regained only tiny amounts of control of his right index finger and a couple of other hand/foot motions, none of them fine-grained.</p>

<p>His total control of his computer (currently running Win7, but we can change that as needed) is via voice command. Honza's not dumb. He had a 3.7 GPA with AP math and physics.</p>

<p><strong>The Problems:</strong></p>

<ol>
<li><p>Since all of his input is via voice command, he is concerned that the predominance of special characters in programming will require vast amount of verbose commands. Does anyone know of any <em>well done</em> voice input system specifically designed for programmers? I'm thinking about something that might be modal--e.g. you say ""Python input"" and it goes into a macro mode for doing class definitions, etc. Given all of the RSI in programmer-land there's got to be <em>something</em> out there. What OS(es) does it run on?</p></li>
<li><p>I am planning on teaching him Python, which is my preferred language for programming and teaching. Are there any applications / whatevers that are written in Python and would be a particularly good match for engaging him mentally while supporting his disability? One of his expressed interests is in stock investing, but that not might be a good starting point for a brand-new programmer.</p></li>
<li><p>There are a <em>lot</em> of environments (Flash, JavaScript, etc) that are not particularly friendly to people with accessibility challenges. I vaguely remember (but cannot find) a research project that basically created an overlay system on top of a screen environment and then allowed macro command construction on top of the screen image. If we can get/train this system, we may be able to remove many hurdles to using the net.</p></li>
<li><p>I am particularly interested in finding open source Python-based robotics and robotic prostheses projects so that he can simultaneously learn advanced programming concepts while learning to solve some of his own immediate problems.</p></li>
</ol>

<p>I've done a ton of googling on this, but I <em>know</em> there are things I'm missing. I'm asking the SO community to step up to the plate here. I <em>know</em> this group has the answers, so let me hear them! <em>Overwhelm</em> me with the opportunities that any of us might have/need to still program after such a life-changing event.</p>

<p><strong>Update:</strong> I just registered computingforquads.org and I'll be creating pages for all sorts of solutions to all sorts of problems. Thanks for you help so far and keep those answers coming!</p>
",Best programming aids for a quadriplegic programmer,0.02872903
17268468,4700,135,"<p>While <code>[] + []</code> is an empty string, <code>[] + {}</code> is <code>""[object Object]""</code>, and <code>{} + []</code> is <code>0</code>. Why is <code>{} + {}</code> NaN?</p>

<pre><code>&gt; {} + {}
  NaN
</code></pre>

<p>My question isn't why <code>({} + {}).toString()</code> is <code>""[object Object][object Object]""</code> while <code>NaN.toString()</code> is <code>""NaN""</code>, <a href=""https://stackoverflow.com/a/9033306/1348195"">this part has an answer here already</a>.</p>

<p>My question is why does this happen only on the client side? On the server side (<a href=""http://en.wikipedia.org/wiki/Node.js"" rel=""noreferrer"">Node.js</a>) <code>{} + {}</code> is <code>""[object Object][object Object]""</code>.</p>

<pre><code>&gt; {} + {}
'[object Object][object Object]'
</code></pre>

<hr>

<p><strong>Summarizing</strong>:</p>

<p>On the client side:</p>

<pre><code> [] + []              // Returns """"
 [] + {}              // Returns ""[object Object]""
 {} + []              // Returns 0
 {} + {}              // Returns NaN

 NaN.toString()       // Returns ""NaN""
 ({} + {}).toString() // Returns ""[object Object][object Object]""
 var a = {} + {};     // 'a' will be ""[object Object][object Object]""
</code></pre>

<p>In Node.js:</p>

<pre><code> [] + []   // Returns """" (like on the client)
 [] + {}   // Returns ""[object Object]"" (like on the client)
 {} + []   // Returns ""[object Object]"" (not like on the client)
 {} + {}   // Returns ""[object Object][object Object]"" (not like on the client)
</code></pre>
",Why {} + {} is NaN only on the client side? Why not in Node.js?,0.0287234
30387471,3153,90,"<p>I have 2 classes:</p>

<pre><code>class base {
    virtual void foo() {};
};

class derived : public base {
    void foo() { base::foo(); }
};
</code></pre>

<p>I made a mistake and wrote <code>base:foo();</code> instead of <code>base::foo();</code>. The code was compiled and run, but segfaulted.</p>

<p>I don't know how I can Google it and don't know what it is, but I'm very interested: what does that mean?</p>

<pre><code>base:foo();
</code></pre>

<p>If it is important:</p>

<pre><code>class base : public QAbstractGraphicsShapeItem
</code></pre>
",What does : mean?,0.02854424
19234310,6220,177,"<p>I'm trying to create a script in <code>ExtendScript</code> for Premiere Pro that will load-in specified video files, clip them at specified start and stop times, place them into a sequence and then export the resulting movie.</p>

<p>I understand that Adobe doesn't have an official documentation about scripting for Premiere Pro, so I've been working from the data browser (in the <code>ExtendScript Toolkit</code>, or <code>ESTK</code>) and a collection of handy class references I've found <strong><a href=""http://cssdk.s3-website-us-east-1.amazonaws.com/sdk/2.1/docs/WebHelp/references/csawlib/com/adobe/premiere/package-detail.html"">here</a></strong>. </p>

<p>I have successfully loaded in the CSV file that specifies the needed info and also know how to import the video files and create a new sequence (as explained <strong><a href=""http://forums.adobe.com/thread/1177191"">here</a></strong>). The trouble I'm having now is getting the imported files clipped correctly and placed into the sequence. I see that the activeSequence has methods like setInPoint and setOutPoint, but that doesn't seem to result in the correct trimming upon export.</p>

<p>Here is my code with comments to show flow of overall script:</p>

<pre><code>#target premierepro

var myDir = ""G:\\directoryWithVideoFiles\\"";
// defined ""indexOf"" subfunction here
// ***** begin main body of script *****
// (dataRuns has fields runName, startVideo, startTime, stopVideo, stopTime)
// Import video files listed in dataRuns
var vidFiles = new Array;
for (i=0; i&lt;dataRuns.length; i++) {
    if (indexOf.call(vidFiles,myDir + dataRuns[i].startVideo + '.MPG') == -1) {
        vidFiles.push(myDir + dataRuns[i].startVideo + '.MPG');
        }
    if (indexOf.call(vidFiles,myDir + dataRuns[i].stopVideo + '.MPG') == -1) {
        vidFiles.push(myDir + dataRuns[i].stopVideo + '.MPG');
        }
    app.project.createNewSequence(dataRuns[i].runName,'');
    }
app.project.importFiles(vidFiles);
// at this point, for each run (called runName) I need to:
// - take a clip of the startVideo from the startTime to the end of the video
// - take a clip of the stopVideo from the start of the video to the stopTime
// - put clip 1 at the beginning of the associated sequence, &amp; clip 2 right after
// - export the sequence as a new video file
</code></pre>
",Add imported files into sequences using Premiere Pro's ExtendScript connection,0.02845659
23207168,3044,86,"<p>More than any other language I know, I've ""learned"" Bash by Googling every time I need some little thing. Consequently, I can patchwork together little scripts that appear to work. However, I don't <em>really</em> know what's going on, and I was hoping for a more formal introduction to Bash as a programming language. For example: What is the evaluation order? what are the scoping rules? What is the typing discipline, e.g. is everything a string? What is the state of the program -- is it a key-value assignment of strings to variable names; is there more than that, e.g. the stack? Is there a heap? And so on.</p>

<p>I thought to consult the GNU Bash manual for this kind of insight, but it doesn't seem to be what I want; it's more of a laundry list of syntactic sugar rather than an explanation of the core semantic model. The million-and-one ""bash tutorials"" online are only worse. Perhaps I should first study <code>sh</code>, and understand Bash as a syntactic sugar on top of this? I don't know if this is an accurate model, though.</p>

<p>Any suggestions?</p>

<p><strong>EDIT:</strong> I've been asked to provide examples of what ideally I'm looking for. A rather extreme example of what I would consider a ""formal semantics"" is <a href=""http://cs.brown.edu/~sk/Publications/Papers/Published/gsk-essence-javascript/paper.pdf"" rel=""noreferrer"">this paper on ""the essence of JavaScript""</a>. Perhaps a slightly less formal example is the <a href=""http://www.haskell.org/definition/haskell2010.pdf"" rel=""noreferrer"">Haskell 2010 report</a>.</p>
",A semantics for Bash scripts?,0.0282523
6916884,12074,341,"<p>The C# compiler requires that whenever a custom type defines operator <code>==</code>, it must also define <code>!=</code> (see <a href=""http://msdn.microsoft.com/en-us/library/ms173147%28v=vs.80%29.aspx"" rel=""noreferrer"">here</a>).</p>

<p>Why?</p>

<p>I'm curious to know why the designers thought it necessary and why can't the compiler default to a reasonable implementation for either of the operators when only the other is present. For example, Lua lets you define only the equality operator and you get the other for free. C# could do the same by asking you to define either == or both == and != and then automatically compile the missing != operator as <code>!(left == right)</code>.</p>

<p>I understand that there are weird corner cases where some entities may neither be equal nor unequal, (like IEEE-754 NaN's), but those seem like the exception, not the rule. So this doesn't explain why the C# compiler designers made the exception the rule.</p>

<p>I've seen cases of poor workmanship where the equality operator is defined, then the inequality operator is a copy-paste with each and every comparison reversed and every &amp;&amp; switched to a || (you get the point... basically !(a==b) expanded through De Morgan's rules). That's poor practice that the compiler could eliminate by design, as is the case with Lua.</p>

<p>Note:
The same holds for operators &lt; > &lt;= >=. I can't imagine cases where you'll need to define these in unnatural ways. Lua lets you define only &lt; and &lt;= and defines >= and > naturally through the formers' negation. Why doesn't C# do the same (at least 'by default')?</p>

<p><strong>EDIT</strong></p>

<p>Apparently there are valid reasons to allow the programmer to implement checks for equality and inequality however they like. Some of the answers point to cases where that may be nice.</p>

<p>The kernel of my question, however, is why this is forcibly required in C# when <em>usually</em> it's not <em>logically</em> necessary?</p>

<p>It is also in striking contrast to design choices for .NET interfaces like <code>Object.Equals</code>, <code>IEquatable.Equals</code> <code>IEqualityComparer.Equals</code> where the lack of a <code>NotEquals</code> counterpart shows that the framework considers <code>!Equals()</code> objects as unequal and that's that. Furthermore, classes like <code>Dictionary</code> and methods like <code>.Contains()</code> depend exclusively on the aforementioned interfaces and do not use the operators directly even if they are defined. In fact, when ReSharper generates equality members, it defines both <code>==</code> and <code>!=</code> in terms of <code>Equals()</code> and even then only if the user chooses to generate operators at all. The equality operators aren't needed by the framework to understand object equality.</p>

<p>Basically, the .NET framework doesn't care about these operators, it only cares about a few <code>Equals</code> methods. The decision to require both == and != operators to be defined in tandem by the user is related purely to the language design and not object semantics as far as .NET is concerned.</p>
",Why must we define both == and != in C#?,0.0282425
18331774,5151,145,"<p>I have a class, like this:</p>

<pre><code>public class MyClass
{
    public int Value { get; set; }
    public bool IsValid { get; set; }
}
</code></pre>

<p><sub>In actual fact it's much larger, but this recreates the problem (weirdness).</sub></p>

<p>I want to get the sum of the <code>Value</code>, where the instance is valid. So far, I've found two solutions to this.</p>

<h2>The first one is this:</h2>

<pre><code>int result = myCollection.Where(mc =&gt; mc.IsValid).Select(mc =&gt; mc.Value).Sum();
</code></pre>

<h2>The second one, however, is this:</h2>

<pre><code>int result = myCollection.Select(mc =&gt; mc.IsValid ? mc.Value : 0).Sum();
</code></pre>

<p>I want to get the most efficient method. I, at first, thought that the second one would be more efficient. Then the theoretical part of me started going ""Well, one is O(n + m + m), the other one is O(n + n). The first one should perform better with more invalids, while the second one should perform better with less"". I thought that they would perform equally.
EDIT: And then @Martin pointed out that the Where and the Select were combined, so it should actually be O(m + n). However, if you look below, it seems like this is not related.</p>

<hr>

<h1><a href=""https://gist.github.com/anonymous/68fc3b49478ee2848a27"" rel=""noreferrer"">So I put it to the test.</a></h1>

<p><sub>(It's 100+ lines, so I thought it was better to post it as a Gist.)</sub><br>
The results were... interesting.</p>

<h2><sub>With 0% tie tolerance:</sub></h2>

<p>The scales are in the favour of <code>Select</code> and <code>Where</code>, by about ~30 points.</p>

<p><code>
How much do you want to be the disambiguation percentage?<br>
0<br>
Starting benchmarking.<br>
Ties: 0<br>
Where + Select: 65<br>
Select: 36<br>
</code></p>

<h2><sub>With 2% tie tolerance:</sub></h2>

<p>It's the same, except that for some they were within 2%. I'd say that's a minimum margin of error. <code>Select</code> and <code>Where</code> now have just a ~20 point lead.</p>

<p><code>
How much do you want to be the disambiguation percentage?<br>
2<br>
Starting benchmarking.<br>
Ties: 6<br>
Where + Select: 58<br>
Select: 37<br>
</code></p>

<h2><sub>With 5% tie tolerance:</sub></h2>

<p>This is what I'd say to be my maximum margin of error. It makes it a bit better for the <code>Select</code>, but not much.</p>

<p><code>
How much do you want to be the disambiguation percentage?<br>
5<br>
Starting benchmarking.<br>
Ties: 17<br>
Where + Select: 53<br>
Select: 31<br>
</code></p>

<h2><sub>With 10% tie tolerance:</sub></h2>

<p>This is way out of my margin of error, but I'm still interested in the result. Because it gives the <code>Select</code> and <code>Where</code> the twenty point lead it's had for a while now.</p>

<p><code>
How much do you want to be the disambiguation percentage?<br>
10<br>
Starting benchmarking.<br>
Ties: 36<br>
Where + Select: 44<br>
Select: 21<br>
</code></p>

<h2><sub>With 25% tie tolerance:</sub></h2>

<p>This is way, <strong>way</strong> out of my margin of error, but I'm still interested in the result, because the <code>Select</code> and <code>Where</code> <strong>still</strong> (nearly) keep their 20 point lead. It seems like it's outclassing it in a distinct few, and that's what giving it the lead.</p>

<p><code>
How much do you want to be the disambiguation percentage?<br>
25<br>
Starting benchmarking.<br>
Ties: 85<br>
Where + Select: 16<br>
Select: 0<br>
</code></p>

<hr>

<p>Now, I'm guessing that the 20 point lead came from the middle, where they're both bound to get <strong>around</strong> the same performance. I could try and log it, but it would be a whole load of information to take in. A graph would be better, I guess. </p>

<p>So that's what I did.</p>

<p><img src=""https://i.stack.imgur.com/zQhQS.png"" alt=""Select vs Select and Where.""></p>

<p>It shows that the <code>Select</code> line keeps steady (expected) and that the <code>Select + Where</code> line climbs up (expected). However, what puzzles me is why it doesn't meet with the <code>Select</code> at 50 or earlier: in fact I was expecting earlier than 50, as an extra enumerator had to be created for the <code>Select</code> and <code>Where</code>. I mean, this shows the 20-point lead, but it doesn't explain why. This, I guess, is the main point of my question.</p>

<h1>Why does it behave like this? Should I trust it? If not, should I use the other one or this one?</h1>

<hr>

<p>As @KingKong mentioned in the comments, you can also use <code>Sum</code>'s overload that takes a lambda. So my two options are now changed to this:</p>

<h2>First:</h2>

<pre><code>int result = myCollection.Where(mc =&gt; mc.IsValid).Sum(mc =&gt; mc.Value);
</code></pre>

<h2>Second:</h2>

<pre><code>int result = myCollection.Sum(mc =&gt; mc.IsValid ? mc.Value : 0);
</code></pre>

<p>I'm going to make it a bit shorter, but:</p>

<p><code>
How much do you want to be the disambiguation percentage?<br>
0<br>
Starting benchmarking.<br>
Ties: 0<br>
Where: 60<br>
Sum: 41<br>
How much do you want to be the disambiguation percentage?<br>
2<br>
Starting benchmarking.<br>
Ties: 8<br>
Where: 55<br>
Sum: 38<br>
How much do you want to be the disambiguation percentage?<br>
5<br>
Starting benchmarking.<br>
Ties: 21<br>
Where: 49<br>
Sum: 31<br>
How much do you want to be the disambiguation percentage?<br>
10<br>
Starting benchmarking.<br>
Ties: 39<br>
Where: 41<br>
Sum: 21<br>
How much do you want to be the disambiguation percentage?<br>
25<br>
Starting benchmarking.<br>
Ties: 85<br>
Where: 16<br>
Sum: 0<br>
</code></p>

<p>The twenty-point lead is still there, meaning it doesn't have to do with the <code>Where</code> and <code>Select</code> combination pointed out by @Marcin in the comments.</p>

<p><sub>Thanks for reading through my wall of text! Also, if you're interested, <a href=""https://gist.github.com/anonymous/0adf47e3c6592f592a2c"" rel=""noreferrer"">here's</a> the modified version that logs the CSV that Excel takes in.</sub></p>
",Why are Where and Select outperforming just Select?,0.02814987
16787719,3353,94,"<p>Based on the following question asked a few days ago in SO: <a href=""https://stackoverflow.com/questions/16679239/gettype-and-polymorphism"">GetType() and polymorphism</a> and reading <a href=""https://stackoverflow.com/questions/16679239/gettype-and-polymorphism/16681120"">Eric Lippert's</a> answer, I started thinking if making <code>GetType()</code> not be virtual really ensured that an object could not lie about its <code>Type</code>.</p>

<p>Specifically, Eric's answer states the following:</p>

<blockquote>
  <p>The framework designers are not going to add an incredibly dangerous feature such as allowing an object to lie about its type merely to make it consistent with three other methods on the same type.</p>
</blockquote>

<p>Now the question is: can I make an object that <em>does</em> lie about its type without it being immediately obvious? I may be profoundly wrong here and I'd love clarification if that is the case, but consider the following code:</p>

<pre><code>public interface IFoo
{
    Type GetType();
}
</code></pre>

<p>And the following two implementations of said interface:</p>

<pre><code>public class BadFoo : IFoo
{
    Type IFoo.GetType()
    {
        return typeof(int);
    }
}

public class NiceFoo : IFoo
{
}
</code></pre>

<p>Then if you run the following simple program:</p>

<pre><code>static void Main(string[] args)
{
    IFoo badFoo = new BadFoo();
    IFoo niceFoo = new NiceFoo();
    Console.WriteLine(""BadFoo says he's a '{0}'"", badFoo.GetType().ToString());
    Console.WriteLine(""NiceFoo says he's a '{0}'"", niceFoo.GetType().ToString());
    Console.ReadLine();
}
</code></pre>

<p>Sure enough <code>badFoo</code> outputs an erroneous <code>Type</code>.</p>

<p>Now I don't know if this has any serious implications based on Eric describing this behavior as an ""<em>incredibly dangerous feature</em>"", but could this pattern pose a credible threat?</p>
",GetType() can lie?,0.0280346
42088015,4467,124,"<pre><code>auto foo = ""You're using g++!"";
auto compiler_detector = [foo](auto foo) { std::puts(foo); };
compiler_detector(""You're using clang++!"");
</code></pre>

<ul>
<li><p><strong>clang++ 3.6.0</strong> and newer print out <em>""You're using clang++!""</em> and warn about the <strong>capture</strong> <code>foo</code> being unused.</p></li>
<li><p><strong>g++ 4.9.0</strong> and newer print out <em>""You're using g++!""</em> and warn about the <strong>parameter</strong> <code>foo</code> being unused.</p></li>
</ul>

<p>What compiler is more accurately following the C++ Standard here?</p>

<p><a href=""http://melpon.org/wandbox/permlink/FFngRM4CwRdtcCBl""><strong>wandbox example</strong></a></p>
",Lambda capture and parameter with same name - who shadows the other? (clang vs gcc),0.02775912
9894821,4011,111,"<p>I see a lot of people in blog posts and here on SO either avoiding or advising against the usage of the <code>Thread</code> class in recent versions of C# (and I mean of course 4.0+, with the addition of <code>Task</code> &amp; friends). Even before, there were debates about the fact that a plain old thread's functionality can be replaced in many cases by the <code>ThreadPool</code> class.</p>

<p>Also, other specialized mechanisms are further rendering the <code>Thread</code> class less appealing, such as <code>Timer</code>s replacing the ugly <code>Thread</code> + <code>Sleep</code> combo, while for GUIs we have <code>BackgroundWorker</code>, etc.</p>

<p>Still, the <code>Thread</code> seems to remain a very familiar concept for some people (myself included), people that, when confronted with a task that involves some kind of parallel execution, jump directly to using the good old <code>Thread</code> class. I've been wondering lately if it's time to amend my ways. </p>

<p>So my question is, are there any cases when it's necessary or useful to use a plain old <code>Thread</code> object instead of one of the above constructs?</p>
",Are there any cases when it's preferable to use a plain old Thread object instead of one of the newer constructs?,0.0276739
11070690,3110,86,"<p>In GHCi:</p>

<pre><code>Prelude&gt; error (error """")
*** Exception: 
Prelude&gt; (error . error) """"
*** Exception: *** Exception: 
</code></pre>

<p>Why isn't the first one a nested exception?</p>
",How do exceptions in Haskell work?,0.02765273
58031966,3381,93,"<pre class=""lang-py prettyprint-override""><code>&gt;&gt;&gt; (float('inf')+0j)*1
(inf+nanj)
</code></pre>

<p>Why? This caused a nasty bug in my code.</p>

<p>Why isn't <code>1</code> the multiplicative identity, giving <code>(inf + 0j)</code>?</p>
",Why does (inf + 0j)*1 evaluate to inf + nanj?,0.02750665
26788397,3167,87,"<p>I'm maintaining some legacy code and I've noticed that the following pattern for defining objects is used:</p>

<pre><code>var MyObject = {};

(function (root) {

    root.myFunction = function (foo) {
        //do something
    };

})(MyObject);
</code></pre>

<p>Is there any purpose to this? Is it equivalent to just doing the following?</p>

<pre><code>var MyObject = {

    myFunction : function (foo) {
        //do something
    };

};
</code></pre>

<p>I'm not about to embark in a holy quest to refactor the whole codebase to my likings, but I'd really like to understand the reason behind that roundabout way of defining objects.</p>

<p>Thanks!</p>
",Does this way of defining JS objects have any purpose?,0.02747079
26770247,3569,98,"<p>While trying to debug an issue in my program (2 circles with an equal radius are being drawn to different sizes using Gloss<code>*</code>), I stumbled across a strange situation. In my file that handles objects, I have the following definition for a <code>Player</code>:</p>

<pre><code>type Coord = (Float,Float)
data Obj =  Player  { oPos :: Coord, oDims :: Coord }
</code></pre>

<p>and in my main file, which imports Objects.hs, I have the following definition:</p>

<pre><code>startPlayer :: Obj
startPlayer = Player (0,0) 10
</code></pre>

<p>This happened due to me adding and changing fields for player, and forgetting to update <code>startPlayer</code> after (its dimensions were determined by a single number to represent a radius, but I changed it to a <code>Coord</code> to represent (width,height); in case I ever make the player object a non-circle).</p>

<p>The amazing thing is, the above code compiles, and runs, despite the second field being of the wrong type.</p>

<p>I first thought that maybe I had different versions of the files open, but any changes to any files were reflected in the compiled program.</p>

<p>Next I thought that maybe <code>startPlayer</code> wasn't being used for some reason. Commenting out <code>startPlayer</code> yields a compiler error though, and even stranger, changing the <code>10</code> in <code>startPlayer</code> causes an appropriate response (changes the starting size of the <code>Player</code>); again, despite it being of the wrong type. To make sure that it's reading the data definition correctly, I inserted a typo into the file, and it gave me an error; so I am looking at the correct file.</p>

<p>I tried pasting the 2 snippets above into their own file, and it spat out the expected error that the second field of <code>Player</code> in <code>startPlayer</code> is incorrect.</p>

<p>What could possibly allow this to happen? You'd think that this is the very thing that Haskell's type checker should prevent.</p>

<hr>

<p><code>*</code> The answer to my original problem, two circles of supposedly equal radius being drawn to different sizes, was that one of the radii was actually negative.</p>
","The type checker is allowing a very wrong type replacement, and the program still compiles",0.02745867
23492381,4737,130,"<p>If <code>cee157</code> can refer to 2 different commit IDs, such as </p>

<p><code>cee157eb799af829a9a0c42c0915f55cd29818d4</code> and <code>cee1577fecf6fc5369a80bd6e926ac5f864a754b</code></p>

<p>will Git warn me if I type in <code>git log cee157</code>?  (or Git 1.8.5.2 (Apple Git-48) allows me to type in <code>git log cee1</code>).</p>

<p>I think it should, although I can't find any authoritative source that says it would.</p>
",Does Git warn me if a shorthand commit ID can refer to 2 different commits?,0.02744353
28781839,5384,147,"<p>I have by pure chance discovered that the C# compiler turns this method:</p>

<pre><code>static bool IsNotNull(object obj)
{
    return obj != null;
}
</code></pre>

<p>…into this <a href=""http://en.wikipedia.org/wiki/Common_Intermediate_Language"">CIL</a>:</p>

<pre><code>.method private hidebysig static bool IsNotNull(object obj) cil managed
{
    ldarg.0   // obj
    ldnull
    cgt.un
    ret
}
</code></pre>

<p>…or, if you prefer looking at decompiled C# code:</p>

<pre><code>static bool IsNotNull(object obj)
{
    return obj &gt; null;   // (note: this is not a valid C# expression)
}
</code></pre>

<p>How come that the <code>!=</code> gets translated as a ""<code>&gt;</code>""?</p>
",Why does the C# compiler translate this != comparison as if it were a > comparison?,0.02730312
18092160,4032,110,"<p>Why were <code>181783497276652981</code> and <code>8682522807148012</code> chosen in <code>Random.java</code>?</p>

<p>Here's the relevant source code from Java SE JDK 1.7:</p>

<pre class=""lang-java prettyprint-override""><code>/**
 * Creates a new random number generator. This constructor sets
 * the seed of the random number generator to a value very likely
 * to be distinct from any other invocation of this constructor.
 */
public Random() {
    this(seedUniquifier() ^ System.nanoTime());
}

private static long seedUniquifier() {
    // L'Ecuyer, ""Tables of Linear Congruential Generators of
    // Different Sizes and Good Lattice Structure"", 1999
    for (;;) {
        long current = seedUniquifier.get();
        long next = current * 181783497276652981L;
        if (seedUniquifier.compareAndSet(current, next))
            return next;
    }
}

private static final AtomicLong seedUniquifier
    = new AtomicLong(8682522807148012L);
</code></pre>

<p>So, invoking <code>new Random()</code> without any seed parameter takes the current ""seed uniquifier"" and XORs it with <code>System.nanoTime()</code>.  Then it uses <code>181783497276652981</code> to create another seed uniquifier to be stored for the next time <code>new Random()</code> is called.</p>

<p>The literals <code>181783497276652981L</code> and <code>8682522807148012L</code> are not placed in constants, but they don't appear anywhere else.</p>

<p>At first the comment gives me an easy lead.  Searching online for that article yields <a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.99.6553&amp;rep=rep1&amp;type=pdf"">the actual article</a>.  <code>8682522807148012</code> doesn't appear in the paper, but <code>181783497276652981</code> does appear -- as a substring of another number, <code>1181783497276652981</code>, which is <code>181783497276652981</code> with a <code>1</code> prepended.</p>

<p>The paper claims that <code>1181783497276652981</code> is a number that yields good ""merit"" for a linear congruential generator.  Was this number simply mis-copied into Java?  Does <code>181783497276652981</code> have an acceptable merit?</p>

<p>And why was <code>8682522807148012</code> chosen?</p>

<p>Searching online for either number yields no explanation, only <a href=""http://www.java-forums.org/advanced-java/72124-random-seed.html"">this page</a> that also notices the dropped <code>1</code> in front of <code>181783497276652981</code>.</p>

<p>Could other numbers have been chosen that would have worked as well as these two numbers?  Why or why not?</p>
",What's with 181783497276652981 and 8682522807148012 in Random (Java 7)?,0.02728175
15724676,3671,100,"<p>In Java, I have just found out that the following code is legal:</p>

<pre><code>KnockKnockServer newServer = new KnockKnockServer();                    
KnockKnockServer.receiver receive = newServer.new receiver(clientSocket);
</code></pre>

<p>FYI, receiver is just a helper class with the following signature:</p>

<pre><code>public class receiver extends Thread {  /* code_inside */  }
</code></pre>

<p>I've never seen the <code>XYZ.new</code> notation before. How does that work?  Is there any way to code that more conventionally?</p>
",What does `someObject.new` do in Java?,0.02724053
30147165,4043,110,"<p>In python 3.4, I am typing</p>

<pre><code>[] = """" 
</code></pre>

<p>and it works fine, no Exception is raised. Though of course <code>[]</code> is not equal to <code>""""</code> afterwards.</p>

<pre><code>[] = ()
</code></pre>

<p>also works fine. </p>

<pre><code>"""" = []
</code></pre>

<p>raises an exception as expected though, </p>

<pre><code>() = """"
</code></pre>

<p>raises an exception as expected though. So, what's going on? </p>
","Why isn't assigning to an empty list (e.g. [] = """") an error?",0.02720752
57003891,3236,88,"<p>I tried to check out where <code>float</code> loses the ability to exactly represent large integer numbers. So I wrote this little snippet:</p>

<pre><code>int main() {
    for (int i=0; ; i++) {
        if ((float)i!=i) {
            return i;
        }
    }
}
</code></pre>

<p>This code seems to work with all compilers, except clang. Clang generates a simple infinite loop. <a href=""https://godbolt.org/z/ck_uVe"" rel=""noreferrer"">Godbolt</a>.</p>

<p>Is this allowed? If yes, is it a QoI issue?</p>
",Is this floating-point optimization allowed?,0.02719407
27506735,4011,109,"<p>I have found the following CSS selector in the Google Chrome user agent stylesheet:</p>

<pre><code>[type=""checkbox"" i]
</code></pre>

<p>What does the <code>i</code> mean?</p>

<p><img src=""https://i.stack.imgur.com/8D94p.png"" alt=""""></p>
","What does ""i"" mean in a CSS attribute selector?",0.02717527
33871181,3170,86,"<p>Let’s consider this very simple async method:</p>

<pre><code>static async Task myMethodAsync() 
{
    await Task.Delay(500);
}
</code></pre>

<p>When I compile this with VS2013 (pre Roslyn compiler) the generated state-machine is a struct. </p>

<pre><code>private struct &lt;myMethodAsync&gt;d__0 : IAsyncStateMachine
{  
    ...
    void IAsyncStateMachine.MoveNext()
    {
        ...
    }
}
</code></pre>

<p>When I compile it with VS2015  (Roslyn) the generated code is this:</p>

<pre><code>private sealed class &lt;myMethodAsync&gt;d__1 : IAsyncStateMachine
{
    ...
    void IAsyncStateMachine.MoveNext()
    {
        ...
    }
}
</code></pre>

<p>As you can see Roslyn generates a class (and not a struct). If I remember correctly the first implementations of the async/await support in the old compiler (CTP2012 i guess) also generated classes and then it was changed to struct from performance reasons. (in some cases you can completely avoid boxing and heap allocation…) (See <a href=""https://stackoverflow.com/questions/23609110/why-are-awaiters-async-await-structs-and-not-classes-can-classes-be-used"">this</a>)</p>

<p>Does anyone know why this was changed again in Roslyn? (I don’t have any problem regarding this, I know that this change is transparent and does not change the behavior of any code, I’m just curious) </p>

<p><strong>Edit:</strong></p>

<p>The answer from @Damien_The_Unbeliever (and the source code :) ) imho explains everything. The described behaviour of Roslyn only applies for debug build (and that's needed because of the CLR limitation mentioned in the comment). In Release it also generates a struct (with all the benefits of that..). So this seems to be a very clever solution to support both Edit and Continue and better performance in production. Interesting stuff, thanks for everyone who participated! </p>
",Why are async state machines classes (and not structs) in Roslyn?,0.02712934
51365138,3762,102,"<p>In the <a href=""https://github.com/git/git/blob/master/date.c#L958"" rel=""noreferrer"">date.c</a> file in Git's source code, I note the following structure of special time names:</p>

<pre><code>static const struct special {
    const char *name;
    void (*fn)(struct tm *, struct tm *, int *);
} special[] = {
    { ""yesterday"", date_yesterday },
    { ""noon"", date_noon },
    { ""midnight"", date_midnight },
    { ""tea"", date_tea },
    { ""PM"", date_pm },
    { ""AM"", date_am },
    { ""never"", date_never },
    { ""now"", date_now },
    { NULL }
};
</code></pre>

<p>I understand the utility (somewhat) of most of these, but why have a ""tea"" time (it evaluates to 17:00 hours)? Is this just an <a href=""https://en.wiktionary.org/wiki/Easter_egg#Noun"" rel=""noreferrer"">Easter egg</a> of sorts?</p>
",Why does Git have a tea time?,0.02711324
27409167,5867,158,"<p>While examining the <code>String ==</code> operator, I noticed that it calls <code>String.Equals(string a, string b)</code>, meaning it's just a pass-through. </p>

<p>Examining the <code>String.Equals(string a, string b)</code> method, I see that it does an equality check using the <code>==</code> operator. How is this actually working and not causing a <code>StackOverflowException</code> when doing something like <code>""x"" == ""x""</code> or <code>""x"" == ""y""</code>?</p>

<p><strong>Update</strong>: I let JetBrains know and they made it a critical priority for dotPeek. <a href=""https://youtrack.jetbrains.com/issue/DOTP-6789"" rel=""noreferrer"">https://youtrack.jetbrains.com/issue/DOTP-6789</a></p>

<p>I also added an issue on ILSpy's GitHub repo.</p>

<p><img src=""https://i.stack.imgur.com/LEXLE.png"" alt=""String Equality""></p>
","How does String.Equals(a,b) not produce a StackOverflowException?",0.02693029
17652412,3566,96,"<p>In C++11 there are variadic templates like this one:</p>

<pre><code>template&lt; class T, class... Args &gt;
unique_ptr&lt;T&gt; make_unique( Args&amp;&amp;... args )
{
    return unique_ptr&lt;T&gt;(new T(std::forward&lt;Args&gt;(args)...));
}
</code></pre>

<p>There are some curiosities about this: The expression <code>std::forward&lt;Args&gt;(args)...</code> uses both <code>Args</code> and <code>args</code> but only one <code>...</code> token. Furthermore <code>std::forward</code> is a non-variadic template function taking only one template parameter and one argument. What are the syntax rules for that (roughly)? How can it be generalized? </p>

<p>Also: In the function implementation the ellipsis (<code>...</code>) is at the end of the expression of interest. Is there a reason that in the template argument list and the parameter list the ellipsis is in the middle?</p>
","What are the rules for the ""..."" token in the context of variadic templates?",0.02692092
18934805,6148,165,"<p>I have this practice project that allows the user to draw on the screen as they touch with their fingers. Very simple App I did as exercise way back.
My little cousin took the liberty of drawing things with his finger with my iPad on this App (Kids drawings: circle, lines, etc, whatever came to his mind).
Then he started to draw circles and then he asked me to make it ""good circle"" (from my understanding: make the drawn circle perfectly round, as we know 
no matter how stable we try to draw something with our finger on the screen, a circle is never really as rounded like a circle should be). </p>

<p>So my question here is that, is there any way in code where we can first detect a line drawn by the user that forms a circle and generate approximately the same size of the circle by making it perfectly round on the screen. Making a not so straight line straight is something I would know how to do, but as for circle, I don't quite know how to go about doing it with Quartz or other methods. </p>

<p>My reasoning is that, the start and the end point of the line must touch or cross each other after the user lifts his finger to justify the fact that he was trying to actually draw a circle.</p>
",Draw a perfect circle from user's touch,0.026838
17781150,3749,100,"<p>I have the following <code>if</code> condition.</p>

<pre><code>if (i == -i &amp;&amp; i != 0)
</code></pre>

<p>What value of <code>i</code> will return <code>true</code> for this condition in Java?</p>

<p>I am unable to think of any such value of <code>i</code> considering <a href=""http://en.wikipedia.org/wiki/Two%27s_complement"" rel=""noreferrer"">two's complement</a> notation in Java.</p>

<p>I would also love to have algebraic proof of whatever answer this condition has (in context with Java)?</p>
",Value of i for (i == -i && i != 0) to return true in Java,0.02667378
17450732,3399,90,"<p>I am receiving R12 Exit Timeout errors for a Heroku app running unicorn and sidekiq. These errors occur 1-2 times a day and whenever I deploy. I understand that I need to convert the shutdown signals from Heroku for unicorn to respond correctly, but thought that I had done so in the below unicorn config:</p>

<pre><code>worker_processes 3
timeout 30
preload_app true

before_fork do |server, worker|
  Signal.trap 'TERM' do
    puts ""Unicorn master intercepting TERM and sending myself QUIT instead. My PID is #{Process.pid}""
    Process.kill 'QUIT', Process.pid
  end

  if defined?(ActiveRecord::Base)
    ActiveRecord::Base.connection.disconnect!
    Rails.logger.info('Disconnected from ActiveRecord')
  end
end

after_fork do |server, worker|
  Signal.trap 'TERM' do
    puts ""Unicorn worker intercepting TERM and doing nothing. Wait for master to sent QUIT. My PID is #{Process.pid}""
  end

  if defined?(ActiveRecord::Base)
    ActiveRecord::Base.establish_connection
    Rails.logger.info('Connected to ActiveRecord')
  end

  Sidekiq.configure_client do |config|
    config.redis = { :size =&gt; 1 }
  end
end
</code></pre>

<p>My logs surrounding the error look like this:</p>

<pre><code>Stopping all processes with SIGTERM
Unicorn worker intercepting TERM and doing nothing. Wait for master to sent QUIT. My PID is 7
Unicorn worker intercepting TERM and doing nothing. Wait for master to sent QUIT. My PID is 11
Unicorn worker intercepting TERM and doing nothing. Wait for master to sent QUIT. My PID is 15
Unicorn master intercepting TERM and sending myself QUIT instead. My PID is 2
Started GET ""/manage""
reaped #&lt;Process::Status: pid 11 exit 0&gt; worker=1
reaped #&lt;Process::Status: pid 7 exit 0&gt; worker=0
reaped #&lt;Process::Status: pid 15 exit 0&gt; worker=2
master complete
Error R12 (Exit timeout) -&gt; At least one process failed to exit within 10 seconds of SIGTERM
Stopping remaining processes with SIGKILL
Process exited with status 137
</code></pre>

<p>It appears that all of the child processes were successfully reaped before the timeout. Is it possible master is still alive? Also, should the router still be sending web requests to the dyno during shut down, as shown in the logs?</p>

<p>FWIW, I'm using Heroku's zero downtime deployment plugin (<a href=""https://devcenter.heroku.com/articles/labs-preboot/"">https://devcenter.heroku.com/articles/labs-preboot/</a>).</p>
",Unicorn exit timeout on Heroku after trapping TERM and sending QUIT,0.02647838
14837209,5751,152,"<p>I have two objects in C# and don't know if it's Boolean or any other type.
However when I try to compare those C# fails to give the right answer.
I have tried the same code with VB.NET and that did it !</p>

<p>Can anyone tell me how to fix this if there is a solution ?</p>

<p>C#:</p>

<pre><code>object a = true;
object b = true;
object c = false;
if (a == b) c = true;
MessageBox.Show(c.ToString()); //Outputs False !!
</code></pre>

<p>VB.NET:</p>

<pre><code>Dim a As Object = True
Dim b As Object = True
Dim c As Object = False
If (a = b) Then c = True
MessageBox.Show(c.ToString()) '// Outputs True
</code></pre>
",Why C# fails to compare two object types with each other but VB doesn't?,0.02643019
23153445,3338,88,"<p>Consider the following statement:</p>

<pre><code>*((char*)NULL) = 0; //undefined behavior
</code></pre>

<p>It clearly invokes undefined behavior. Does the existence of such a statement in a given program mean that the whole program is undefined or that behavior only becomes undefined once control flow hits this statement?</p>

<p>Would the following program be well-defined in case the user never enters the number <code>3</code>?</p>

<pre><code>while (true) {
 int num = ReadNumberFromConsole();
 if (num == 3)
  *((char*)NULL) = 0; //undefined behavior
}
</code></pre>

<p>Or is it entirely undefined behavior no matter what the user enters?</p>

<p>Also, can the compiler assume that undefined behavior will never be executed at runtime? That would allow for reasoning backwards in time:</p>

<pre><code>int num = ReadNumberFromConsole();

if (num == 3) {
 PrintToConsole(num);
 *((char*)NULL) = 0; //undefined behavior
}
</code></pre>

<p>Here, the compiler could reason that in case <code>num == 3</code> we will always invoke undefined behavior. Therefore, this case must be impossible and the number does not need to be printed. The entire <code>if</code> statement could be optimized out. Is this kind of backwards reasoning allowed according to the standard?</p>
",Can branches with undefined behavior be assumed unreachable and optimized as dead code?,0.02636309
11476190,4897,129,"<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""https://stackoverflow.com/questions/306313/python-is-operator-behaves-unexpectedly-with-integers"">Python &ldquo;is&rdquo; operator behaves unexpectedly with integers</a>  </p>
</blockquote>



<p>Today I tried to debug my project and after a few hours of analysing I'd got this:</p>

<pre><code>&gt;&gt;&gt; (0-6) is -6
False
</code></pre>

<p>but,</p>

<pre><code>&gt;&gt;&gt; (0-5) is -5
True
</code></pre>

<p>Could you explain to me, why?
Maybe this is some kind of bug or very strange behavior.</p>

<pre><code>&gt; Python 2.7.3 (default, Apr 24 2012, 00:00:54) [GCC 4.7.0 20120414 (prerelease)] on linux2
&gt;&gt;&gt; type(0-6) 
&lt;type 'int'&gt;
&gt;&gt;&gt; type(-6) 
&lt;type 'int'&gt;
&gt;&gt;&gt; type((0-6) is -6)
&lt;type 'bool'&gt;
&gt;&gt;&gt; 
</code></pre>
",Why (0-6) is -6 = False?,0.02634266
31707614,4951,130,"<p>Church numbers are an encoding of natural numbers as functions.</p>

<pre><code>(\ f x → (f x))             -- church number 1
(\ f x → (f (f (f x))))     -- church number 3
(\ f x → (f (f (f (f x))))) -- church number 4
</code></pre>

<p>Neatly, you can exponentiate 2 church numbers by just applying them. That is, if you apply 4 to 2, you get the church number <code>16</code>, or <code>2^4</code>. Obviously,  that is utterly unpractical. Church numbers need a linear amount of memory and are really, really slow. Computing something like <code>10^10</code> - which GHCI quickly answers correctly - would take ages and couldn't fit the memory on your computer anyway. </p>

<p>I've been experimenting with optimal λ evaluators lately. On my tests, I accidentally typed the following on my optimal λ-calculator:</p>

<pre><code>10 ^ 10 % 13
</code></pre>

<p>It was supposed to be multiplication, not exponentiation. Before I could move my fingers to abort the forever-running program in despair, it answered my request:</p>

<pre><code>3
{ iterations: 11523, applications: 5748, used_memory: 27729 }

real    0m0.104s
user    0m0.086s
sys     0m0.019s
</code></pre>

<p>With my ""bug alert"" flashing, I went to Google and verified, <code>10^10%13 == 3</code> indeed. <strong>But the λ-calculator wasn't supposed to find that result, it can barely store 10^10.</strong> I started stressing it, for science. It instantly answered me <code>20^20%13 == 3</code>, <code>50^50%13 == 4</code>, <code>60^60%3 == 0</code>. I had to use <a href=""https://www.mtholyoke.edu/courses/quenell/s2003/ma139/js/powermod.html"" rel=""noreferrer"">external tools</a> to verify those results, since <s>Haskell itself wasn't able to compute it (due to integer overflow)</s> (it is if you use Integers not Ints, of course!). Pushing it to its limits, this was the answer to <code>200^200%31</code>:</p>

<pre><code>5
{ iterations: 10351327, applications: 5175644, used_memory: 23754870 }

real    0m4.025s
user    0m3.686s
sys 0m0.341s
</code></pre>

<p>If we had one copy of the universe for each atom on the universe, and we had a computer for each atom we had in total, we couldn't store the church number <code>200^200</code>. This prompted me to question if my mac was really that powerful. Maybe the optimal evaluator was able to skip the unnecessary branches and arrive right at the answer in the same fashion Haskell does with lazy evaluation. To test this, I compiled the λ program to Haskell:</p>

<pre><code>data Term = F !(Term -&gt; Term) | N !Double
instance Show Term where {
    show (N x) = ""(N ""++(if fromIntegral (floor x) == x then show (floor x) else show x)++"")"";
    show (F _) = ""(λ...)""}
infixl 0 #
(F f) # x = f x
churchNum = F(\(N n)-&gt;F(\f-&gt;F(\x-&gt;if n&lt;=0 then x else (f#(churchNum#(N(n-1))#f#x)))))
expMod    = (F(\v0-&gt;(F(\v1-&gt;(F(\v2-&gt;((((((churchNum # v2) # (F(\v3-&gt;(F(\v4-&gt;(v3 # (F(\v5-&gt;((v4 # (F(\v6-&gt;(F(\v7-&gt;(v6 # ((v5 # v6) # v7))))))) # v5))))))))) # (F(\v3-&gt;(v3 # (F(\v4-&gt;(F(\v5-&gt;v5)))))))) # (F(\v3-&gt;((((churchNum # v1) # (churchNum # v0)) # ((((churchNum # v2) # (F(\v4-&gt;(F(\v5-&gt;(F(\v6-&gt;(v4 # (F(\v7-&gt;((v5 # v7) # v6))))))))))) # (F(\v4-&gt;v4))) # (F(\v4-&gt;(F(\v5-&gt;(v5 # v4))))))) # ((((churchNum # v2) # (F(\v4-&gt;(F(\v5-&gt;v4))))) # (F(\v4-&gt;v4))) # (F(\v4-&gt;v4))))))) # (F(\v3-&gt;(((F(\(N x)-&gt;F(\(N y)-&gt;N(x+y)))) # v3) # (N 1))))) # (N 0))))))))
main = print $ (expMod # N 5 # N 5 # N 4)
</code></pre>

<p>This correctly outputs <code>1</code> (<code>5 ^ 5 % 4</code>) - but throw anything above <code>10^10</code> and it will be stuck, eliminating the hypothesis. </p>

<p>The <a href=""https://github.com/SrVictorMaia/optlam"" rel=""noreferrer"">optimal evaluator I used</a> is a 160-lines long, unoptimized JavaScript program that didn't include any sort of exponential modulus math - and the lambda-calculus modulus function I used was equally simple:</p>

<pre><code>(λab.(b(λcd.(c(λe.(d(λfg.(f(efg)))e))))(λc.(c(λde.e)))(λc.(a(b(λdef.(d(λg.(egf))))(λd.d)(λde.(ed)))(b(λde.d)(λd.d)(λd.d))))))
</code></pre>

<p>I used no specific modular arithmetic algorithm or formula. <strong>So, how is the optimal evaluator able to arrive at the right answers?</strong></p>
",Why are λ-calculus optimal evaluators able to compute big modular exponentiations without formulas?,0.02625732
1413602,8342,219,"<p>I'm making a website now and I am trying to decide if I should make it fluid or not. Fixed width websites are much easier to make and also much easier to make them appear consistent.</p>

<p>To be honest though, I personally prefer looking at fluid websites that stretch to the full width of my monitor. My question comes from the fact that in most modern browsers you can hold control and scroll your mouse wheel to basically resize any website.</p>

<p>So is creating a fluid website worth the trouble?</p>
",Are fluid websites worth making anymore?,0.0262527
13159739,4076,107,"<p>For a class Foo, is there a way to disallow constructing it without giving it a name?</p>

<p>For example:</p>

<pre><code>Foo(""hi"");
</code></pre>

<p>And only allow it if you give it a name, like the following?</p>

<pre><code>Foo my_foo(""hi"");
</code></pre>

<p>The lifetime of the first one is just the statement, and the second one is the enclosing block.  In my use case, <code>Foo</code> is measuring the time between constructor and destructor. Since I never refer to the local variable, I often forget to put it in, and accidentally change the lifetime.  I'd like to get a compile time error instead.</p>
",How to disallow temporaries,0.02625123
23559866,7368,193,"<p>I'm trying to integrate <strong><a href=""http://projects.spring.io/spring-security-saml/"" rel=""nofollow noreferrer"">Spring Security SAML Extension</a></strong> with <strong><a href=""https://spring.io/blog/2013/08/06/spring-boot-simplifying-spring-for-everyone/"" rel=""nofollow noreferrer"">Spring Boot</a></strong>.</p>

<p>About the matter, I did develop a complete sample application. Its source code is available on GitHub: </p>

<ul>
<li><strong><a href=""https://github.com/vdenotaris/spring-boot-security-saml-sample"" rel=""nofollow noreferrer"">spring-boot-saml-integration on GitHub</a></strong></li>
</ul>

<p>By running it as Spring Boot application (running against the SDK built-in Application Server), the WebApp works fine.</p>

<p>Unfortunately, the same AuthN process doesn't work at all on <strong>Undertow/WildFly</strong>.</p>

<p>According to the logs, the IdP actually performs the <strong>AuthN</strong> process: the instructions of my custom <code>UserDetails</code> implementation are correctly executed. Despite the execution flow, Spring doesn't set up and persist the privileges for the current user.</p>

<pre><code>@Component
public class SAMLUserDetailsServiceImpl implements SAMLUserDetailsService {

    // Logger
    private static final Logger LOG = LoggerFactory.getLogger(SAMLUserDetailsServiceImpl.class);

    @Override
    public Object loadUserBySAML(SAMLCredential credential)
            throws UsernameNotFoundException, SSOUserAccountNotExistsException {
        String userID = credential.getNameID().getValue();
        if (userID.compareTo(""jdoe@samplemail.com"") != 0) {     // We're simulating the data access.
            LOG.warn(""SSO User Account not found into the system"");
            throw new SSOUserAccountNotExistsException(""SSO User Account not found into the system"", userID);
        }
        LOG.info(userID + "" is logged in"");
        List&lt;GrantedAuthority&gt; authorities = new ArrayList&lt;GrantedAuthority&gt;();
        GrantedAuthority authority = new SimpleGrantedAuthority(""ROLE_USER"");
        authorities.add(authority);
        ExtUser userDetails = new ExtUser(userID, ""password"", true, true, true,
                true, authorities, ""John"", ""Doe"");
        return userDetails;
    }
}
</code></pre>

<p>While debugging, I found out the problem relies on the <code>FilterChainProxy</code> class. At runtime, the attribute <code>FILTER_APPLIED</code> of <code>ServletRequest</code> has a <em>null</em> value, thus Spring clears the <code>SecurityContextHolder</code>. </p>

<pre><code>private final static String FILTER_APPLIED = FilterChainProxy.class.getName().concat("".APPLIED"");

public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)
        throws IOException, ServletException {
    boolean clearContext = request.getAttribute(FILTER_APPLIED) == null;
    if (clearContext) {
        try {
            request.setAttribute(FILTER_APPLIED, Boolean.TRUE);
            doFilterInternal(request, response, chain);
        } finally {
            SecurityContextHolder.clearContext();
            request.removeAttribute(FILTER_APPLIED);
        }
    } else {
        doFilterInternal(request, response, chain);
    }
}
</code></pre>

<p>On <strong>VMware vFabric tc Sever</strong> and <strong>Tomcat</strong>, everything works totally fine. Do you have any idea about solving this issue?</p>
",Spring Security on Wildfly: error while executing the filter chain,0.02619435
51414717,3058,80,"<p>I came across an intriguing C code that prints <code>A + B</code>, but I have trouble understanding it.</p>

<h2>Input Format:</h2>

<pre><code>A B
</code></pre>

<p>where <code>A</code>, <code>B</code> are integers between <code>0</code> and <code>10</code> separated by a single space.</p>

<h2>Code:</h2>

<pre><code>main( n )
{
    gets( &amp;n );
    printf(""%d"", n % 85 - 43);
}
</code></pre>

<p>This was intended for short coding, please don't mind the warnings.</p>

<h2>What I understand so far:</h2>

<p><code>gets( &amp;n )</code> stores the ASCII values of A, space, and B in the lower three bytes of <code>n</code>. For example, <code>A = 3</code> and <code>B = 8</code> would yield <code>n = 0x00382033</code>. Given conditions prevent <code>n</code> from overflowing. But I do not understand how <code>n % 85 - 43</code> yields <code>A + B</code>.</p>

<p>How do you come up with these numbers?</p>
",C addition using modulus,0.02616089
8677672,4446,116,"<p>I was just reading </p>

<p><strong>ISO/IEC 9899:201x  Committee Draft — April 12, 2011</strong></p>

<p>in which i found  under 5.1.2.2.3 Program termination</p>

<pre><code>..reaching the } that terminates the main function returns a value of 0. 
</code></pre>

<p>it means if you don't specify any return statement in <code>main()</code>, and if the program runs successfully, then at the closing brace } of main will return 0.</p>

<p>But in the following code i don't specify any return statement, yet it does not return 0 </p>

<pre><code>#include&lt;stdio.h&gt;
int sum(int a,int b)
{
return (a + b);
}

int main()
{
    int a=10;
    int b=5;
    int ans;    
    ans=sum(a,b);
    printf(""sum is %d"",ans);
}
</code></pre>

<p>compile </p>

<pre><code>gcc test.c  
./a.out
sum is 15
echo $?
9          // here it should be 0 but it shows 9 why?
</code></pre>
",Why main does not return 0 here?,0.02609087
27946387,10084,263,"<p><em>Update 2017-05-17. I no longer work for the company where this question originated, and do not have access to Delphi XEx. While I was there, the problem was solved by migrating to mixed FPC+GCC (Pascal+C), with NEON intrinsics for some routines where it made a difference. (FPC+GCC is highly recommended also because it enables using standard tools, particularly Valgrind.) If someone can demonstrate, with credible examples, how they are actually able to produce optimized ARM code from Delphi XEx, I'm happy to accept the answer.</em></p>

<hr>

<p>Embarcadero's Delphi compilers use an LLVM backend to produce native ARM code for Android devices. I have large amounts of Pascal code that I need to compile into Android applications and I would like to know how to make Delphi generate more efficient code. Right now, I'm not even talking about advanced features like automatic SIMD optimizations, just about producing reasonable code. Surely there must be a way to pass parameters to the LLVM side, or somehow affect the result? Usually, any compiler will have many options to affect code compilation and optimization, but Delphi's ARM targets seem to be just ""optimization on/off"" and that's it.</p>

<p>LLVM is supposed to be capable of producing reasonably tight and sensible code, but it seems that Delphi is using its facilities in a weird way. Delphi wants to use the stack very heavily, and it generally only utilizes the processor's registers r0-r3 as temporary variables. Perhaps the craziest of all, it seems to be loading normal 32 bit integers as four 1-byte load operations. How to make Delphi produce better ARM code, and without the byte-by-byte hassle it is making for Android? </p>

<p>At first I thought the byte-by-byte loading was for swapping byte order from big-endian, but that was not the case, it is really just loading a 32 bit number with 4 single-byte loads.*  It might be to load the full 32 bits without doing an unaligned word-sized memory load. (whether it SHOULD avoid that is another thing, which would hint to the whole thing being a compiler bug)*</p>

<p>Let's look at this simple function:</p>

<pre class=""lang-pascal prettyprint-override""><code>function ReadInteger(APInteger : PInteger) : Integer;
begin
  Result := APInteger^;
end;
</code></pre>

<p>Even with optimizations switched on, Delphi XE7 with update pack 1, as well as XE6, produce the following ARM assembly code for that function:</p>

<pre class=""lang-asm prettyprint-override""><code>Disassembly of section .text._ZN16Uarmcodetestform11ReadIntegerEPi:

00000000 &lt;_ZN16Uarmcodetestform11ReadIntegerEPi&gt;:
   0:   b580        push    {r7, lr}
   2:   466f        mov r7, sp
   4:   b083        sub sp, #12
   6:   9002        str r0, [sp, #8]
   8:   78c1        ldrb    r1, [r0, #3]
   a:   7882        ldrb    r2, [r0, #2]
   c:   ea42 2101   orr.w   r1, r2, r1, lsl #8
  10:   7842        ldrb    r2, [r0, #1]
  12:   7803        ldrb    r3, [r0, #0]
  14:   ea43 2202   orr.w   r2, r3, r2, lsl #8
  18:   ea42 4101   orr.w   r1, r2, r1, lsl #16
  1c:   9101        str r1, [sp, #4]
  1e:   9000        str r0, [sp, #0]
  20:   4608        mov r0, r1
  22:   b003        add sp, #12
  24:   bd80        pop {r7, pc}
</code></pre>

<p>Just count the number of instructions and memory accesses Delphi needs for that. And constructing a 32 bit integer from 4 single-byte loads... If I change the function a little bit and use a var parameter instead of a pointer, it is slightly less convoluted:</p>

<pre class=""lang-asm prettyprint-override""><code>Disassembly of section .text._ZN16Uarmcodetestform14ReadIntegerVarERi:

00000000 &lt;_ZN16Uarmcodetestform14ReadIntegerVarERi&gt;:
   0:   b580        push    {r7, lr}
   2:   466f        mov r7, sp
   4:   b083        sub sp, #12
   6:   9002        str r0, [sp, #8]
   8:   6801        ldr r1, [r0, #0]
   a:   9101        str r1, [sp, #4]
   c:   9000        str r0, [sp, #0]
   e:   4608        mov r0, r1
  10:   b003        add sp, #12
  12:   bd80        pop {r7, pc}
</code></pre>

<p>I won't include the disassembly here, but for iOS, Delphi produces identical code for the pointer and var parameter versions, and they are almost but not exactly the same as the Android var parameter version. 
<em>Edit: to clarify, the byte-by-byte loading is only on Android. And only on Android, the pointer and var parameter versions differ from each other. On iOS both versions generate exactly the same code.</em></p>

<p>For comparison, here's what FPC 2.7.1 (SVN trunk version from March 2014) thinks of the function with optimization level -O2. The pointer and var parameter versions are exactly the same.</p>

<pre class=""lang-asm prettyprint-override""><code>Disassembly of section .text.n_p$armcodetest_$$_readinteger$pinteger$$longint:

00000000 &lt;P$ARMCODETEST_$$_READINTEGER$PINTEGER$$LONGINT&gt;:

   0:   6800        ldr r0, [r0, #0]
   2:   46f7        mov pc, lr
</code></pre>

<p>I also tested an equivalent C function with the C compiler that comes with the Android NDK.</p>

<pre class=""lang-c prettyprint-override""><code>int ReadInteger(int *APInteger)
{
    return *APInteger;
}
</code></pre>

<p>And this compiles into essentially the same thing FPC made:</p>

<pre class=""lang-asm prettyprint-override""><code>Disassembly of section .text._Z11ReadIntegerPi:

00000000 &lt;_Z11ReadIntegerPi&gt;:
   0:   6800        ldr r0, [r0, #0]
   2:   4770        bx  lr
</code></pre>
",How to affect Delphi XEx code generation for Android/ARM targets?,0.02608092
12660870,4115,107,"<p>I'm making a Python parser, and this is <em>really</em> confusing me:</p>

<pre><code>&gt;&gt;&gt;  1 in  []  in 'a'
False

&gt;&gt;&gt; (1 in  []) in 'a'
TypeError: 'in &lt;string&gt;' requires string as left operand, not bool

&gt;&gt;&gt;  1 in ([] in 'a')
TypeError: 'in &lt;string&gt;' requires string as left operand, not list
</code></pre>

<p>How exactly does ""in"" work in Python, with regards to associativity, etc.?  </p>

<p>Why do no two of these expressions behave the same way?</p>
","Associativity of ""in"" in Python?",0.02600243
5142251,4558,118,"<p>I'm writing C code for a system where address 0x0000 is valid and contains port I/O. Therefore, any possible bugs that access a NULL pointer will remain undetected and at the same time cause dangerous behaviour.</p>

<p>For this reason I wish to redefine NULL to be another address, to for example an address that isn't valid. If I accidentally access such an address I will get a hardware interrupt where I can handle the error. I happen to have access to stddef.h for this compiler, so I can actually alter the standard header and redefine NULL.</p>

<p>My question is: will this conflict with the C standard? As far as I can tell from 7.17 in the standard, the macro is implementation-defined. Is there anything elsewhere in the standard stating that NULL <em>must</em> be 0?</p>

<p>Another issue is that plenty of compilers perform static initialization by setting everything to zero, no matter the data type. Even though the standard says that the compiler should set integers to zero and pointers to NULL. If I would redefine NULL for my compiler, then I know that such static initialization will fail. Could I regard that as incorrect compiler behaviour even though I boldly altered compiler headers manually? Because I know for certain that this particular compiler does not access the NULL macro when doing static initialization.</p>
",Redefining NULL,0.02588855
21071706,5993,155,"<p>I'm having problems getting GHC to specialize a function with a class constraint. I have a minimal example of my problem here: <a href=""http://lpaste.net/98464"" rel=""nofollow noreferrer"">Foo.hs</a> and  <a href=""http://lpaste.net/98342"" rel=""nofollow noreferrer"">Main.hs</a>. The two files compile (GHC 7.6.2, <code>ghc -O3 Main</code>) and run.</p>

<p><strong>NOTE:</strong>
<code>Foo.hs</code> is really stripped down. If you want to see why the constraint is needed, you can see a little more code <a href=""http://lpaste.net/98840"" rel=""nofollow noreferrer"">here</a>. If I put the code in a single file or make many other minor changes, GHC simply inlines the call to <code>plusFastCyc</code>. This will not happen in the real code because <code>plusFastCyc</code> is too large for GHC to inline, even when marked <code>INLINE</code>. The point is to <em>specialize</em> the call to <code>plusFastCyc</code>, not inline it. <code>plusFastCyc</code> is called in many places in the real code, so duplicating such a large function would not be desirable even if I could force GHC to do it.</p>

<p>The code of interest is the <code>plusFastCyc</code> in <code>Foo.hs</code>, reproduced here:</p>

<pre><code>{-# INLINEABLE plusFastCyc #-}
{-# SPECIALIZE plusFastCyc :: 
         forall m . (Factored m Int) =&gt; 
              (FastCyc (VT U.Vector m) Int) -&gt; 
                   (FastCyc (VT U.Vector m) Int) -&gt; 
                        (FastCyc (VT U.Vector m) Int) #-}

-- Although the next specialization makes `fcTest` fast,
-- it isn't useful to me in my real program because the phantom type M is reified
-- {-# SPECIALIZE plusFastCyc :: 
--          FastCyc (VT U.Vector M) Int -&gt; 
--               FastCyc (VT U.Vector M) Int -&gt; 
--                    FastCyc (VT U.Vector M) Int #-}

plusFastCyc :: (Num (t r)) =&gt; (FastCyc t r) -&gt; (FastCyc t r) -&gt; (FastCyc t r)
plusFastCyc (PowBasis v1) (PowBasis v2) = PowBasis $ v1 + v2
</code></pre>

<p>The <code>Main.hs</code> file has two drivers: <code>vtTest</code>, which runs in ~3 seconds, and <code>fcTest</code>, which runs in ~83 seconds when compiled with -O3 using the <code>forall</code>'d specialization.</p>

<p>The <a href=""http://lpaste.net/98593"" rel=""nofollow noreferrer"">core shows</a> that for the <code>vtTest</code> test, the addition code is being specialized to <code>Unboxed</code> vectors over <code>Int</code>s, etc, while generic vector code is used for <code>fcTest</code>.
On line 10, you can see that GHC does write a specialized version of <code>plusFastCyc</code>, compared to the generic version on line 167.
The rule for the specialization is on line 225. I believe this rule should fire on line 270. (<code>main6</code> calls <code>iterate main8 y</code>, so <code>main8</code> is where <code>plusFastCyc</code> should be specialized.)</p>

<p>My goal is to make <code>fcTest</code> as fast as <code>vtTest</code> by specializing <code>plusFastCyc</code>. I've found two ways to do this:</p>

<ol>
<li>Explicity call <code>inline</code> from <code>GHC.Exts</code> in <code>fcTest</code>.</li>
<li>Remove the <code>Factored m Int</code> constraint on <code>plusFastCyc</code>.</li>
</ol>

<p>Option 1 is unsatisfactory because in the actual code base <code>plusFastCyc</code> is a frequently used operation and a <em>very</em> large function, so it should not be inlined at every use. Rather, GHC should call a specialized version of <code>plusFastCyc</code>. Option 2 is not really an option because I need the constraint in the real code.</p>

<p>I've tried a variety of options using (and not using) <code>INLINE</code>, <code>INLINABLE</code>, and <code>SPECIALIZE</code>, but nothing seems to work. (<strong>EDIT</strong>: I may have stripped out too much of <code>plusFastCyc</code> to make my example small, so <code>INLINE</code> might cause the function to be inlined. This doesn't happen in my real code because <code>plusFastCyc</code> is so large.) In this particular example, I'm not getting any <a href=""http://web.archiveorange.com/archive/v/2B0uXzyXUnvOzzIApVfp"" rel=""nofollow noreferrer""><code>match_co: needs more cases</code></a> or <a href=""https://stackoverflow.com/questions/18792388/haskell-ghc-specialize-causes-rule-left-hand-side-too-complicated-to""><code>RULE: LHS too complicated to desugar</code></a> (and <a href=""https://ghc.haskell.org/trac/ghc/ticket/5821"" rel=""nofollow noreferrer"">here</a>) warnings, though I was getting many <code>match_co</code> warnings before minimizing the example. Presumably, the ""problem"" is the <code>Factored m Int</code> constraint in the rule; if I make changes to that constraint, <code>fcTest</code> runs as fast as <code>vtTest</code>.</p>

<p>Am I doing something GHC just doesn't like? Why won't GHC specialize the <code>plusFastCyc</code>, and how can I make it?</p>

<p><strong>UPDATE</strong></p>

<p>The problem persists in GHC 7.8.2, so this question is still relevant.</p>
",Specialization with Constraints,0.02586351
15485473,3447,89,"<h2>Background</h2>

<p>This picture illustrates the problem:
<img src=""https://i.stack.imgur.com/dNVaO.png"" alt=""square_grid_with_arrows_giving_directions""></p>

<p>I can control the red circle.  The targets are the blue triangles.  The black arrows indicate the direction that the targets will move.</p>

<p>I want to collect all targets in the minimum number of steps.</p>

<p>Each turn I must move 1 step either left/right/up or down.</p>

<p>Each turn the targets will also move 1 step according to the directions shown on the board.</p>

<h2>Demo</h2>

<p>I've put up a playable demo of the problem <a href=""http://penguinspuzzle.appspot.com/a_fishy_problem.html"" rel=""nofollow noreferrer"">here on Google appengine</a>.</p>

<p>I would be very interested if anyone can beat the target score as this would show that my current algorithm is suboptimal.  (A congratulations message should be printed if you manage this!)</p>

<h2>Problem</h2>

<p>My current algorithm scales really badly with the number of targets.  The time goes up exponentially and for 16 fish it is already several seconds. </p>

<p>I would like to compute the answer for board sizes of 32*32 and with 100 moving targets.</p>

<h2>Question</h2>

<p>What is an efficient algorithm (ideally in Javascript) for computing the minimum number of steps to collect all targets?</p>

<h2>What I've tried</h2>

<p>My current approach is based on memoisation but it is very slow and I don't know whether it will always generate the best solution.</p>

<p>I solve the subproblem of ""what is the minimum number of steps to collect a given set of targets and end up at a particular target?"".</p>

<p>The subproblem is solved recursively by examining each choice for the previous target to have visited.
I assume that it is always optimal to collect the previous subset of targets as quickly as possible and then move from the position you ended up to the current target as quickly as possible (although I don't know whether this is a valid assumption).</p>

<p>This results in n*2^n states to be computed which grows very rapidly.</p>

<p>The current code is shown below:</p>

<pre><code>var DX=[1,0,-1,0];
var DY=[0,1,0,-1]; 

// Return the location of the given fish at time t
function getPt(fish,t) {
  var i;
  var x=pts[fish][0];
  var y=pts[fish][1];
  for(i=0;i&lt;t;i++) {
    var b=board[x][y];
    x+=DX[b];
    y+=DY[b];
  }
  return [x,y];
}

// Return the number of steps to track down the given fish
// Work by iterating and selecting first time when Manhattan distance matches time
function fastest_route(peng,dest) {
  var myx=peng[0];
  var myy=peng[1];
  var x=dest[0];
  var y=dest[1];
  var t=0;
  while ((Math.abs(x-myx)+Math.abs(y-myy))!=t) {
    var b=board[x][y];
    x+=DX[b];
    y+=DY[b];
    t+=1;
  }
  return t;
}

// Try to compute the shortest path to reach each fish and a certain subset of the others
// key is current fish followed by N bits of bitmask
// value is shortest time
function computeTarget(start_x,start_y) {
  cache={};
  // Compute the shortest steps to have visited all fish in bitmask
  // and with the last visit being to the fish with index equal to last
  function go(bitmask,last) {
    var i;
    var best=100000000;
    var key=(last&lt;&lt;num_fish)+bitmask;
    if (key in cache) {
      return cache[key];
    }
    // Consider all previous positions
    bitmask -= 1&lt;&lt;last;
    if (bitmask==0) {
      best = fastest_route([start_x,start_y],pts[last]);
    } else {
      for(i=0;i&lt;pts.length;i++) {
        var bit = 1&lt;&lt;i;
        if (bitmask&amp;bit) {
          var s = go(bitmask,i);   // least cost if our previous fish was i
          s+=fastest_route(getPt(i,s),getPt(last,s));
          if (s&lt;best) best=s;
        }
      }
    }
    cache[key]=best;
    return best;
  }
  var t = 100000000;
  for(var i=0;i&lt;pts.length;i++) {
    t = Math.min(t,go((1&lt;&lt;pts.length)-1,i));
  }
  return t;
}
</code></pre>

<h2>What I've considered</h2>

<p>Some options that I've wondered about are:</p>

<ol>
<li><p>Caching of intermediate results.  The distance calculation repeats a lot of simulation and intermediate results could be cached.<br>
However, I don't think this would stop it having exponential complexity.</p></li>
<li><p>An A* search algorithm although it is not clear to me what an appropriate admissible heuristic would be and how effective this would be in practice.</p></li>
<li><p>Investigating good algorithms for the travelling salesman problem and see if they apply to this problem.</p></li>
<li><p>Trying to prove that the problem is NP-hard and hence unreasonable to be seeking an optimal answer for it.</p></li>
</ol>
",How can I find the shortest path between 100 moving targets? (Live demo included.),0.02581955
13603795,3061,79,"<p>In C# language and .NET framework, could you help me with understanding delegates?
I was trying to check some code, and found that the results I received were unexpected for me. Here it is:</p>

<pre><code>class Program
{
    public static int I = 0;

    static Func&lt;string&gt; del = new Func&lt;string&gt;(I.ToString);

    static void Main(string[] args)
    {
        I = 10;
        Console.WriteLine(""{0}"", del());
    }
}
</code></pre>

<p>The answer was 0, but not 10. Why? </p>
",Using delegates in C#,0.02580856
17828584,4310,111,"<p>I was wondering what happens when you try to catch an StackOverflowError and came up with the following method:</p>

<pre><code>class RandomNumberGenerator {

    static int cnt = 0;

    public static void main(String[] args) {
        try {
            main(args);
        } catch (StackOverflowError ignore) {
            System.out.println(cnt++);
        }
    }
}
</code></pre>

<p>Now my question:</p>

<p>Why does this method print '4'?</p>

<p>I thought maybe it was because <code>System.out.println()</code> needs 3 segments on the call stack, but I don't know where the number 3 comes from. When you look at the source code (and bytecode) of <code>System.out.println()</code>, it normally would lead to far more method invocations than 3 (so 3 segments on the call stack would not be sufficient). If it's because of optimizations the Hotspot VM applies (method inlining), I wonder if the result would be different on another VM.</p>

<p><b>Edit</b>:</p>

<p>As the output seems to be highly JVM specific, I get the result 4 using<br>
Java(TM) SE Runtime Environment (build 1.6.0_41-b02)<br>
Java HotSpot(TM) 64-Bit Server VM (build 20.14-b01, mixed mode)</p>

<p><br></p>

<p><b> Explanation why I think this question is different from <a href=""https://stackoverflow.com/questions/15083318/understanding-java-stack"">Understanding the Java stack</a>: </b></p>

<p>My question is not about why there is a cnt > 0 (obviously because <code>System.out.println()</code> requires stack size and throws another <code>StackOverflowError</code> before something gets printed), but why it has the particular value of 4, respectively 0,3,8,55 or something else on other systems.</p>
",Why does this method print 4?,0.02575406
10790737,3076,79,"<p>The title of the question might be a bit strange, but the thing is that, as far as I know, there is nothing that speaks against tail call optimization at all. However, while browsing open source projects, I already came across a few functions that actively try to stop the compiler from doing a tail call optimization, for example the implementation of <a href=""http://opensource.apple.com/source/CF/CF-635.21/CFRunLoop.c"" rel=""noreferrer"">CFRunLoopRef</a> which is full of such <em>hacks</em>. For example:</p>

<pre><code>static void __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__() __attribute__((noinline));
static void __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__(CFRunLoopObserverCallBack func, CFRunLoopObserverRef observer, CFRunLoopActivity activity, void *info) {
    if (func) {
        func(observer, activity, info);
    }
    getpid(); // thwart tail-call optimization
}
</code></pre>

<p>I would love to know why this is seemingly so important, and are there any cases were I as a <em>normal</em> developer should keep this is mind too? Eg. are there common pitfalls with tail call optimization?</p>
",Why would code actively try to prevent tail-call optimization?,0.0256827
30049962,6279,161,"<p>In a custom library I saw an implementation:</p>

<pre><code>inline int is_upper_alpha(char chValue)
{
    if (((chValue &gt;= 'A') &amp;&amp; (chValue &lt;= 'I')) ||
        ((chValue &gt;= 'J') &amp;&amp; (chValue &lt;= 'R')) ||
        ((chValue &gt;= 'S') &amp;&amp; (chValue &lt;= 'Z')))
        return 1;
    return 0;
}
</code></pre>

<p>Is that an <a href=""https://en.wikipedia.org/wiki/Easter_egg_%28media%29"">Easter egg</a> or what are the advantages vs standard C/C++ method?</p>

<pre><code>inline int is_upper_alpha(char chValue)
{
    return ((chValue &gt;= 'A') &amp;&amp; (chValue &lt;= 'Z'));
}
</code></pre>
",Why is the alphabet split into multiple ranges in this C code?,0.02564103
35133777,4904,125,"<p>For some reason I was sneaking into the .NET Framework source for the class <a href=""http://referencesource.microsoft.com/#mscorlib/system/double.cs,159"" rel=""noreferrer""><code>Double</code></a> and found out that the declaration of <code>==</code> is:</p>

<pre><code>public static bool operator ==(Double left, Double right) {
    return left == right;
}
</code></pre>

<p>The same logic applies for <strong>every</strong> operator.</p>

<hr>

<ul>
<li>What's the point of such a definition? </li>
<li>How does it work?</li>
<li>Why doesn't it create an infinite recursion?</li>
</ul>
","Definition of ""=="" operator for Double",0.0254894
44579839,3414,87,"<p>I'm trying to estimate my device position related to a QR code in space. I'm using ARKit and the Vision framework, both introduced in iOS11, but the answer to this question probably doesn't depend on them.</p>

<p>With the Vision framework, I'm able to get the rectangle that bounds a QR code in the camera frame. I'd like to match this rectangle to the device translation and rotation necessary to transform the QR code from a standard position.</p>

<p>For instance if I observe the frame:</p>

<pre><code>*            *

    B
          C
  A
       D


*            *
</code></pre>

<p>while if I was 1m away from the QR code, centered on it, and assuming the QR code has a side of 10cm I'd see:</p>

<pre><code>*            *


    A0  B0

    D0  C0


*            *
</code></pre>

<p>what has been my device transformation between those two frames? I understand that an exact result might not be possible, because maybe the observed QR code is slightly non planar and we're trying to estimate an affine transform on something that is not one perfectly.</p>

<p>I guess the <code>sceneView.pointOfView?.camera?.projectionTransform</code> is more helpful than the <code>sceneView.pointOfView?.camera?.projectionTransform?.camera.projectionMatrix</code> since the later already takes into account transform inferred from the ARKit that I'm not interested into for this problem.</p>

<p>How would I fill</p>

<pre><code>func get transform(
  qrCodeRectangle: VNBarcodeObservation,
  cameraTransform: SCNMatrix4) {
  // qrCodeRectangle.topLeft etc is the position in [0, 1] * [0, 1] of A0

  // expected real world position of the QR code in a referential coordinate system
  let a0 = SCNVector3(x: -0.05, y: 0.05, z: 1)
  let b0 = SCNVector3(x: 0.05, y: 0.05, z: 1)
  let c0 = SCNVector3(x: 0.05, y: -0.05, z: 1)
  let d0 = SCNVector3(x: -0.05, y: -0.05, z: 1)

  let A0, B0, C0, D0 = ?? // CGPoints representing position in
                          // camera frame for camera in 0, 0, 0 facing Z+

  // then get transform from 0, 0, 0 to current position/rotation that sees
  // a0, b0, c0, d0 through the camera as qrCodeRectangle 
}
</code></pre>

<p>====Edit====</p>

<p>After trying number of things, I ended up going for camera pose estimation using openCV projection and perspective solver, <code>solvePnP</code> This gives me a rotation and translation that should represent the camera pose in the QR code referential. However when using those values and placing objects corresponding to the inverse transformation, where the QR code should be in the camera space, I get inaccurate shifted values, and I'm not able to get the rotation to work:</p>

<pre><code>// some flavor of pseudo code below
func renderer(_ sender: SCNSceneRenderer, updateAtTime time: TimeInterval) {
  guard let currentFrame = sceneView.session.currentFrame, let pov = sceneView.pointOfView else { return }
  let intrisics = currentFrame.camera.intrinsics
  let QRCornerCoordinatesInQRRef = [(-0.05, -0.05, 0), (0.05, -0.05, 0), (-0.05, 0.05, 0), (0.05, 0.05, 0)]

  // uses VNDetectBarcodesRequest to find a QR code and returns a bounding rectangle
  guard let qr = findQRCode(in: currentFrame) else { return }

  let imageSize = CGSize(
    width: CVPixelBufferGetWidth(currentFrame.capturedImage),
    height: CVPixelBufferGetHeight(currentFrame.capturedImage)
  )

  let observations = [
    qr.bottomLeft,
    qr.bottomRight,
    qr.topLeft,
    qr.topRight,
  ].map({ (imageSize.height * (1 - $0.y), imageSize.width * $0.x) })
  // image and SceneKit coordinated are not the same
  // replacing this by:
  // (imageSize.height * (1.35 - $0.y), imageSize.width * ($0.x - 0.2))
  // weirdly fixes an issue, see below

  let rotation, translation = openCV.solvePnP(QRCornerCoordinatesInQRRef, observations, intrisics)
  // calls openCV solvePnP and get the results

  let positionInCameraRef = -rotation.inverted * translation
  let node = SCNNode(geometry: someGeometry)
  pov.addChildNode(node)
  node.position = translation
  node.orientation = rotation.asQuaternion
}
</code></pre>

<p>Here is the output:</p>

<p><a href=""https://i.stack.imgur.com/nhGHA.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/nhGHA.jpg"" alt=""enter image description here""></a></p>

<p>where A, B, C, D are the QR code corners in the order they are passed to the program.</p>

<p>The predicted origin stays in place when the phone rotates, but it's shifted from where it should be. Surprisingly, if I shift the observations values, I'm able to correct this:</p>

<pre><code>  // (imageSize.height * (1 - $0.y), imageSize.width * $0.x)
  // replaced by:
  (imageSize.height * (1.35 - $0.y), imageSize.width * ($0.x - 0.2))
</code></pre>

<p><a href=""https://i.stack.imgur.com/tjBNW.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/tjBNW.jpg"" alt=""enter image description here""></a></p>

<p>and now the predicted origin stays robustly in place. However I don't understand where the shift values come from.</p>

<p>Finally, I've tried to get an orientation fixed relatively to the QR code referential:</p>

<pre><code>    var n = SCNNode(geometry: redGeometry)
    node.addChildNode(n)
    n.position = SCNVector3(0.1, 0, 0)
    n = SCNNode(geometry: blueGeometry)
    node.addChildNode(n)
    n.position = SCNVector3(0, 0.1, 0)
    n = SCNNode(geometry: greenGeometry)
    node.addChildNode(n)
    n.position = SCNVector3(0, 0, 0.1)
</code></pre>

<p>The orientation is fine when I look at the QR code straight, but then it shifts by something that seems to be related to the phone rotation:<a href=""https://i.stack.imgur.com/bHlWS.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/bHlWS.jpg"" alt=""enter image description here""></a></p>

<p>Outstanding questions I have are:</p>

<ul>
<li>How do I solve the rotation?</li>
<li>where do the position shift values come from?</li>
<li>What simple relationship do rotation, translation, QRCornerCoordinatesInQRRef, observations, intrisics verify? Is it O ~ K^-1 * (R_3x2 | T) Q ? Because if so that's off by a few order of magnitude.</li>
</ul>

<p>If that's helpful, here are a few numerical values:</p>

<pre><code>Intrisics matrix
Mat 3x3
1090.318, 0.000, 618.661
0.000, 1090.318, 359.616
0.000, 0.000, 1.000

imageSize
1280.0, 720.0
screenSize
414.0, 736.0
</code></pre>

<p>==== Edit2 ====</p>

<p>I've noticed that the rotation works fine when the phone stays horizontally parallel to the QR code (ie the rotation matrix is [[a, 0, b], [0, 1, 0], [c, 0, d]]), no matter what the actual QR code orientation is:</p>

<p><a href=""https://i.stack.imgur.com/ltqrY.jpg"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/ltqrY.jpg"" alt=""enter image description here""></a></p>

<p>Other rotation don't work.</p>
",iOS revert camera projection,0.0254833
19310788,7577,193,"<p>Why is it possible to call function in JavaScript like this, tested with node.js:</p>

<pre><code>~$ node
&gt; function hi() { console.log(""Hello, World!""); };
undefined
&gt; hi
[Function: hi]
&gt; hi()
Hello, World!
undefined
&gt; hi)( // WTF?
Hello, World!
undefined
&gt;
</code></pre>

<p>Why does the last call, <code>hi)(</code>, work? Is it bug in node.js, bug in V8 engine, officially undefined behaviour, or actually valid JavaScript for all interpreters?</p>
",Why does calling a function in the Node.js REPL with )( work?,0.02547182
27508991,3302,84,"<p>I read the C# Language Specification on the <em>Conditional logical operators</em> <code>||</code> and <code>&amp;&amp;</code>, also known as the short-circuiting logical operators. To me it seemed unclear if these existed for nullable booleans, i.e. the operand type <code>Nullable&lt;bool&gt;</code> (also written <code>bool?</code>), so I tried it with non-dynamic typing:</p>

<pre><code>bool a = true;
bool? b = null;
bool? xxxx = b || a;  // compile-time error, || can't be applied to these types
</code></pre>

<p>That seemed to settle the question (I could not understand the specification clearly, but assuming the implementation of the Visual C# compiler was correct, now I knew).</p>

<p>However, I wanted to try with <code>dynamic</code> binding as well. So I tried this instead:</p>

<pre><code>static class Program
{
  static dynamic A
  {
    get
    {
      Console.WriteLine(""'A' evaluated"");
      return true;
    }
  }
  static dynamic B
  {
    get
    {
      Console.WriteLine(""'B' evaluated"");
      return null;
    }
  }

  static void Main()
  {
    dynamic x = A | B;
    Console.WriteLine((object)x);
    dynamic y = A &amp; B;
    Console.WriteLine((object)y);

    dynamic xx = A || B;
    Console.WriteLine((object)xx);
    dynamic yy = A &amp;&amp; B;
    Console.WriteLine((object)yy);
  }
}
</code></pre>

<p>The surprising result is that this runs without exception.</p>

<p>Well, <code>x</code> and <code>y</code> are not surprising, their declarations lead to both properties being retrieved, and the resulting values are as expected, <code>x</code> is <code>true</code> and <code>y</code> is <code>null</code>.</p>

<p>But the evaluation for <code>xx</code> of <code>A || B</code> lead to no binding-time exception, and only the property <code>A</code> was read, not <code>B</code>. Why does this happen? As you can tell, we could change the <code>B</code> getter to return a crazy object, like <code>""Hello world""</code>, and <code>xx</code> would still evaluate to <code>true</code> without binding-problems...</p>

<p>Evaluating <code>A &amp;&amp; B</code> (for <code>yy</code>) also leads to no binding-time error. And here both properties are retrieved, of course. Why is this allowed by the run-time binder? If the returned object from <code>B</code> is changed to a ""bad"" object (like a <code>string</code>), a binding exception does occur.</p>

<p><strong><em>Is this correct behavior?</em></strong> (How can you infer that from the spec?)</p>

<p>If you try <code>B</code> as first operand, both <code>B || A</code> and <code>B &amp;&amp; A</code> give runtime binder exception (<code>B | A</code> and <code>B &amp; A</code> work fine as everything is normal with non-short-circuiting operators <code>|</code> and <code>&amp;</code>).</p>

<p>(Tried with C# compiler of Visual Studio 2013, and runtime version .NET 4.5.2.)</p>
",Do short-circuiting operators || and && exist for nullable booleans? The RuntimeBinder sometimes thinks so,0.02543913
7989090,5190,132,"<p>I've been updating my emacs config with the use of Rsense to allow for an autocomplete drop down box to appear whilst typing code.  This works well in most files except I've found it doesn't allow me to select an answer from the table when I'm editing some code in my ruby on rails project.</p>

<p>Here is my setup:
<a href=""https://github.com/map7/simple_emacs"">https://github.com/map7/simple_emacs</a></p>

<p>I'm using this under Ubuntu 10.04.</p>

<p>For simple ruby script files it works great. I can open up a new file and type.</p>

<pre class=""lang-rb prettyprint-override""><code>""test"".up...
</code></pre>

<p>Just as I type the 'p' character in up a list of options appear and I can go up and down the list with arrow keys and select one (eg: upcase) with the enter key.</p>

<p>What doesn't work is when I do the exact same test but within a rails project's base directory.</p>

<p><strong>Update:</strong></p>

<p>Found that the problem is with (require 'rails), so it's something in the emacs-rails plugin that the autocomplete doesn't like.</p>

<p><strong>Update:</strong> </p>

<p>It's within emacs-rails -> rails-project.el. If I comment this macro out then autocomplete works, otherwise it doesn't:</p>

<pre class=""lang-rb prettyprint-override""><code>(defmacro* rails-project:with-root ((root) &amp;body body)
  ""If you use `rails-project:root' or functions related on it
several times in a block of code, you can optimize your code by
using this macro. Also, blocks of code will be executed only if
rails-root exist.
 (rails-project:with-root (root)
    (foo root)
    (bar (rails-core:file \""some/path\"")))
 ""
 `(let ((,root (rails-project:root)))
    (when ,root
      (flet ((rails-project:root () ,root))
        ,@body))))
</code></pre>

<p>Can someone explain why this breaks autocomplete?</p>
",Emacs Ruby autocomplete almost working,0.02543353
18224779,3462,88,"<p>Consider the following C++ code:</p>

<pre><code>void* a = &amp;a;
</code></pre>

<p>Why doesn't the compiler complain for using an undeclared identifier?</p>

<p>Also, what does the compiler consider the variable <code>a</code> to be? Is it a pointer to a void object or is it a pointer to a <code>void*</code> pointer? </p>
",How is void *a = &a legal?,0.02541883
20346484,3583,91,"<p>Does anyone know how to test the following setup using Robolectric?</p>

<p>Fragment containing a ViewPager, data loaded with a CursorLoader.</p>

<p>With the code below, the CursorLoader is never pushed into the adapter for the view pager.
I get stuck at the <code>await()</code> call.</p>

<p><strong>EventsFragmentTest.java:</strong></p>

<pre><code>@RunWith(CustomRobolectricTestRunner.class)
public class EventsFragmentTest extends AbstractDbAndUiDriver
{
    // which element in the view pager we are testing
    private static final int           TEST_INDEX = 0;

    protected SherlockFragmentActivity mActivity;
    protected EventsFragment_          mFragment;

    @Override
    @Before
    public void setUp() throws Exception
    {
        // create activity to hold the fragment
        this.mActivity = CustomRobolectricTestRunner.getActivity();

        // create and start the fragment
        this.mFragment = new EventsFragment_();
    }

    @Test
    public void sanityTest()
    {
        // create an event
        final Event event = this.createEvent();

        // create mock cursor loader
        final Cursor cursor = this.createMockEventCursor(event);
        this.mFragment.setCursorLoader(mock(CursorLoader.class));
        when(this.mFragment.getCursorLoader().loadInBackground()).thenReturn(cursor);
        CustomRobolectricTestRunner.startFragment(this.mActivity, this.mFragment);

        await().atMost(5, SECONDS).until(this.isCursorLoaderLoaded(), equalTo(true));

        // check for data displayed
        final TextView title = this.getTextView(R.id.event_view_title);
        final TextView text = this.getTextView(R.id.event_view_text);

        // exists and visible is enough for now
        this.getImageView(R.id.event_view_image);

        assertThat(title.getText().toString(), equalTo(event.getTitle()));
        assertThat(text.getText().toString(), is(event.getText()));

        // clean up
        cursor.close();
    }

    @Override
    protected View getRootView()
    {
        return ((ViewPager) this.mFragment.getView().findViewById(R.id.events_pager)).getChildAt(TEST_INDEX);
    }

    private Callable&lt;Boolean&gt; isCursorLoaderLoaded()
    {
        return new Callable&lt;Boolean&gt;()
        {
            public Boolean call() throws Exception
            {
                return EventsFragmentTest.this.mFragment.isCursorLoaderLoaded(); // The condition that must be fulfilled
            }
        };
    }

    /**
     * Create an event
     * 
     * @return
     */
    protected Event createEvent()
    {
        // create a random event
        final Event event = new Event();
        event.setImage(null);
        event.setLink(""/some/link/"" + RandomUtils.getRandomString(5)); //$NON-NLS-1$
        event.setResourceUri(""/rest/uri/"" + RandomUtils.getRandomDouble()); //$NON-NLS-1$
        event.setText(""this is a test object "" + RandomUtils.getRandomString(5)); //$NON-NLS-1$
        return event;
    }

    protected Cursor createMockEventCursor(final Event event)
    {
        // Create a mock cursor.
        final Cursor cursor = new CursorWrapper(mock(MockCursor.class));

        when(cursor.getCount()).thenReturn(1);
        when(cursor.getString(cursor.getColumnIndexOrThrow(EventTable.COLUMN_TEXT))).thenReturn(event.getText());
        when(cursor.getString(cursor.getColumnIndexOrThrow(EventTable.COLUMN_TITLE))).thenReturn(event.getTitle());
        when(cursor.getString(cursor.getColumnIndexOrThrow(EventTable.COLUMN_IMAGE))).thenReturn(event.getImage());
        when(cursor.getString(cursor.getColumnIndexOrThrow(EventTable.COLUMN_LINK))).thenReturn(event.getLink());
        when(cursor.getString(cursor.getColumnIndexOrThrow(EventTable.COLUMN_RESOURCE_URI))).thenReturn(
                        event.getResourceUri());

        // return created event
        return cursor;
    }

}
</code></pre>

<p><strong>EventsFragment.java</strong></p>

<pre><code>@EFragment(resName = ""events_fragment"")
public class EventsFragment extends SherlockFragment implements LoaderCallbacks&lt;Cursor&gt;
{
    @ViewById(R.id.events_pager)
    protected ViewPager             mPager;

    @ViewById(R.id.events_indicator)
    protected CirclePageIndicator   mIndicator;

    @Pref
    protected ISharedPrefs_         mPreferences;

    protected EventsFragmentAdapter pageAdapter;

    private CursorLoader            mCursorLoader;

    /**
     * initialise the cursoradapter and the cursor loader manager.
     */
    @AfterViews
    void init()
    {
        final SherlockFragmentActivity activity = this.getSherlockActivity();

        this.pageAdapter = new EventsFragmentAdapter(activity.getSupportFragmentManager(), null);
        this.mPager.setAdapter(this.pageAdapter);
        this.mIndicator.setViewPager(this.mPager);
        this.getLoaderManager().initLoader(this.mPager.getId(), null, this);
    }

    /* (non-Javadoc)
     * @see android.support.v4.app.LoaderManager.LoaderCallbacks#onCreateLoader(int, android.os.Bundle)
     */
    @Override
    public Loader&lt;Cursor&gt; onCreateLoader(final int arg0, final Bundle arg1)
    {
        if (this.mCursorLoader == null)
        {
            // set sort to newest first
            final String sortOrder = BaseColumns._ID + "" DESC""; //$NON-NLS-1$

            this.mCursorLoader = new CursorLoader(this.getActivity(), EventContentProvider.CONTENT_URI,
                            EventTable.getProjection(), AbstractDbTable.getWhereCondition(null),
                            AbstractDbTable.getWhereArgs(this.mPreferences, null), sortOrder);
        }
        return this.mCursorLoader;
    }

    /* (non-Javadoc)
     * @see android.support.v4.app.LoaderManager.LoaderCallbacks#onLoadFinished(android.support.v4.content.Loader, java.lang.Object)
     */
    @Override
    public void onLoadFinished(final Loader&lt;Cursor&gt; arg0, final Cursor cursor)
    {
        this.pageAdapter.swapCursor(cursor);

    }

    /* (non-Javadoc)
     * @see android.support.v4.app.LoaderManager.LoaderCallbacks#onLoaderReset(android.support.v4.content.Loader)
     */
    @Override
    public void onLoaderReset(final Loader&lt;Cursor&gt; arg0)
    {
        this.pageAdapter.swapCursor(null);
    }

    /**
     * Required for testing only.
     * 
     * @param cursorLoader
     */
    public void setCursorLoader(final CursorLoader cursorLoader)
    {
        this.mCursorLoader = cursorLoader;
    }

    /**
     * Required for testing only.
     * 
     * @param cursorLoader
     */
    public CursorLoader getCursorLoader()
    {
        return this.mCursorLoader;
    }

    public boolean isCursorLoaderLoaded()
    {
        return (this.pageAdapter.getCursor() != null);
    }
}
</code></pre>
",Testing ViewPager (and CursorLoader) with Robolectric,0.02539771
27510798,3120,79,"<p>I have a parent/child structure in 3 levels. Let's say:<br/></p>

<blockquote>
  <p>Company -> Employee -> Availability</p>
</blockquote>

<p>Since Availability (and also Employee) is frequently updated here, I choose using parent/child structure against nested. And search function works fine (all documents in correct shards).</p>

<p>Now I want to sort those results. Sorting them by meta data from company (1st level) is easy. But I need to sort also by 3rd level (availability).</p>

<p>I want list of companies which are sorted by:</p>

<ul>
<li>Distance from location given ASC</li>
<li>Rating DESC</li>
<li>Soonest availability ASC</li>
</ul>

<p>For example:</p>

<p>Company A is 5 miles away, has rating 4 and soonest one of their employees is available in 20 hours
Company B is also 5 miles away, also has rating 4 but soonest one of their employee is available in 5 hours.</p>

<p>Therefore sort result needs to be B, A.</p>

<p>I would like to append special weight to each of this data, so I started writing aggregations which I could later use in my custom_score script. </p>

<p><strong><a href=""https://gist.github.com/PeteMinus/13617fe53973fed79f64"" rel=""noreferrer"">Full gist for creating index, importing data and searching</a></strong>
<br/> <br/>Now, I've managed to write a query which actually returns back result, but availability aggregation bucket is empty.
However, I'm also getting results back too structured, I would like to flatten them. </p>

<p>Currently I get back:<br/></p>

<blockquote>
  <p>Company IDS -> Employee IDS -> first availability</p>
</blockquote>

<p>I would like to have aggregation like:<br/></p>

<blockquote>
  <p><strong>Company IDS -> first availability</strong></p>
</blockquote>

<p>This way I'm able to do my <code>custom_score</code> script to calculate score and sort them properly.</p>

<p>More simplified question:<br/>
How can one sort/aggregate by multi level (grand)children and possibly flatten the result.</p>
",ElasticSearch multi level parent-child aggregation,0.02532051
26164135,10471,264,"<p>I want to study FRP in Haskell, but it's a bit difficult to decide on a library to use.
Many seem to be dead attempts, some seem to have been resurrected (such as recent activity on Yampa).</p>

<p>From what I read, it seems that there are two ""kinds"" of FRP: push-pull FRP (like in Reactive-banana) on one side and arrowized FRP (like in Yampa) on the other side. It seems that there also used to be some ""classic FRP"" at the time of Fran and FrTime, but I have not spotted any recent activity in these.</p>

<ul>
<li><p>Are these two (or three) really fundamentally different approaches of FRP?</p></li>
<li><p>Is one of them outdated theory whereas the other would be the ""stuff of the future""?</p></li>
<li><p>Or do they have to evolve in parallel, addressing different purposes?</p></li>
<li><p>Did I name the most prominent library of each category, or are there other options to consider (Sodium, Netwire, et al)?</p></li>
</ul>

<hr>

<p><sub>
I finally watched the <a href=""https://www.youtube.com/watch?v=Agu6jipKfYw"" rel=""noreferrer"">talk from Evan Czaplicki</a> recommended in the comments by J. Abrahamson. It is very interesting and did help clarify things up for me. I highly recommend it to anyone who found this question interesting.
</sub></p>
",How fundamentally different are push-pull and arrowized FRP?,0.02521249
38411552,5054,127,"<p>Following the question <a href=""https://stackoverflow.com/questions/38407760/extending-string-prototype-performance-shows-that-function-calls-are-10x-faster"">Extending String.prototype performance</a> I am really intrigued, because just adding <code>""use strict""</code> to a <code>String.prototype</code> method improved performance 10 times. The <a href=""https://stackoverflow.com/a/38410199/1968972"">explanation</a> by <a href=""https://stackoverflow.com/users/1048572/bergi"">bergi</a> is short and does not explain it to me. Why there is such a dramatic difference between two almost identical methods, that only differ in <code>""use strict""</code> at the top? Can you explain in more detail and with the theory behind this?</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>String.prototype.count = function(char) {
  var n = 0;
  for (var i = 0; i &lt; this.length; i++)
    if (this[i] == char) n++;
  return n;
};

String.prototype.count_strict = function(char) {
  ""use strict"";
  var n = 0;
  for (var i = 0; i &lt; this.length; i++)
    if (this[i] == char) n++;
  return n;
};
// Here is how I measued speed, using Node.js 6.1.0

var STR = '0110101110010110100111010011101010101111110001010110010101011101101010101010111111000';
var REP = 1e4;

console.time('proto');
for (var i = 0; i &lt; REP; i++) STR.count('1');
console.timeEnd('proto');

console.time('proto-strict');
for (var i = 0; i &lt; REP; i++) STR.count_strict('1');
console.timeEnd('proto-strict');</code></pre>
</div>
</div>
</p>

<p>Result:</p>

<pre><code>proto: 101 ms
proto-strict: 7.5 ms
</code></pre>
","Why ""use strict"" improves performance 10x in this example?",0.02512861
4810806,7134,179,"<p><strong>Question Part A</strong> ▉ (100 bountys, awarded)<br>
Main question was how to make this site, load faster. First we needed to read these waterfalls. Thanks all for your suggestions on the waterfall readout analysis. Evident from the various waterfall graphs shown here is the main bottleneck: the PHP-generated thumbnails. The protocol-less jquery loading from CDN advised by David got my bounty, albeit making my site only 3% faster overall, and while not answering the site's main bottleneck. Time for for clarification of my question, and, another bounty:</p>

<p><strong>Question Part B</strong> ▉ (100 bountys, awarded)<br>
The new focus was now to solve the problem that the 6 jpg images had, which are causing the most of the loading-delay. These 6 images are PHP-generated thumbnails, tiny and only 3~5 kb, but loading relatively <em>very</em> slowly. Notice the ""<em>time to first byte</em>"" on the various graphs. The problem remained unsolved, but a bounty went to James, who fixed the header error that RedBot <a href=""https://i.stack.imgur.com/FLWNX.png"" rel=""noreferrer"">underlined</a>: <em>""An If-Modified-Since conditional request returned the full content unchanged.""</em>.</p>

<p><strong>Question Part C</strong> ▉ (my last bounty: 250 points)<br>
Unfortunately, after even REdbot.org header error was fixed, the delay caused by the PHP-generated images remained untouched. What on earth are these tiny puny 3~5Kb thumbnails thinking? All that header information can send a rocket to moon and back. Any suggestions on this bottleneck is much appreciated and treated as possible answer, since I am stuck at this bottleneckish problem for already seven months now. My thanks in advance.</p>

<p>[Some background info on my site: CSS is at the top. JS at the bottom (Jquery,JQuery UI, bought menu awm/menu.js engines, tabs js engine, video swfobject.js) The black lines on the second image show whats initiating what to load. The angry robot is my pet ""ZAM"". He is harmless and often happier.]</p>

<hr>

<p><strong>Load Waterfall: Chronological</strong> | <a href=""http://webpagetest.org"" rel=""noreferrer"">http://webpagetest.org</a>
<img src=""https://i.stack.imgur.com/0LdLq.png"" alt=""enter image description here""></p>

<hr>

<p><strong>Parallel Domains Grouped</strong> | <a href=""http://webpagetest.org"" rel=""noreferrer"">http://webpagetest.org</a>
<img src=""https://i.stack.imgur.com/KqdKq.png"" alt=""enter image description here""></p>

<hr>

<p><strong>Site-Perf Waterfall</strong> | <a href=""http://site-perf.com"" rel=""noreferrer"">http://site-perf.com</a>
<img src=""https://i.stack.imgur.com/DuZzJ.png"" alt=""enter image description here""></p>

<hr>

<p><strong>Pingdom Tools Waterfall</strong>  | <a href=""http://tools.pingdom.com"" rel=""noreferrer"">http://tools.pingdom.com</a></p>

<p><img src=""https://i.stack.imgur.com/pTbCb.png"" alt=""enter image description here""></p>

<hr>

<p><strong>GTmetrix Waterfall</strong>  | <a href=""http://gtmetrix.com"" rel=""noreferrer"">http://gtmetrix.com</a></p>

<p><img src=""https://i.stack.imgur.com/DzIR3.png"" alt=""enter image description here""></p>

<hr>
","Cached, PHP generated Thumbnails load slowly",0.02509111
20720098,6499,163,"<p>I discovered this oddity:</p>

<pre><code>for (long l = 4946144450195624l; l &gt; 0; l &gt;&gt;= 5)
    System.out.print((char) (((l &amp; 31 | 64) % 95) + 32));
</code></pre>

<p>Output:</p>

<pre><code>hello world
</code></pre>

<p>How does this work?</p>
","How does this print ""hello world""?",0.02508078
19820297,11726,294,"<p>Why does changing the sum order returns a different result?</p>

<p><code>23.53 + 5.88 + 17.64</code> <strong>=</strong> <code>47.05</code></p>

<p><code>23.53 + 17.64 + 5.88</code> <strong>=</strong> <code>47.050000000000004</code></p>

<p>Both <a href=""http://en.wikipedia.org/wiki/Java_%28programming_language%29"">Java</a> and <a href=""http://en.wikipedia.org/wiki/JavaScript"">JavaScript</a> return the same results.</p>

<p>I understand that, due to the way floating point numbers are represented in binary, some rational numbers (<em>like 1/3 - 0.333333...</em>) cannot be represented precisely.</p>

<p>Why does simply changing the order of the elements affect the result?</p>
",Why does changing the sum order returns a different result?,0.02507249
11318175,4072,102,"<p>And if it does, is there an easy way to get the total time since it started?</p>
",Does a C# app track how long its been running?,0.02504912
9647269,3240,81,"<p>Microsoft has just announced that a software error in calculating dates (over leap year) <a href=""http://blogs.msdn.com/b/windowsazure/archive/2012/03/09/summary-of-windows-azure-service-disruption-on-feb-29th-2012.aspx"" rel=""noreferrer"">caused a major outage in Windows Azure</a> last week. </p>

<p>Was it really a simple error in judgement working around <code>DateTime.Now.AddYears(1)</code> on a leap year?  </p>

<p>What coding practices could have prevented this? </p>

<p><strong>EDIT</strong>
As dcstraw pointed out <code>DateTime.Now.AddYears(1)</code> on a leap year does in fact return the correct date in .NET.  So it's not a framework bug, but evidently a bug in Date calculations.</p>
",How can we develop coding practices designed to protect against leap year bugs?,0.025
10838675,3002,75,"<p>I've found that != and == are not the fastest ways for testing for zero or non-zero.</p>

<pre><code>bool nonZero1 = integer != 0;
xor eax, eax
test ecx, ecx
setne al

bool nonZero2 = integer &lt; 0 || integer &gt; 0;
test ecx, ecx
setne al

bool zero1 = integer == 0;
xor eax, eax
test ecx, ecx
sete al

bool zero2 = !(integer &lt; 0 || integer &gt; 0);
test ecx, ecx
sete al
</code></pre>

<p>Compiler: VC++ 11
Optimization flags: /O2 /GL /LTCG</p>

<p>This is the assembly output for x86-32. The second versions of both comparisons were ~12% faster on both x86-32 and x86-64. However, on x86-64 the instructions were identical (first versions looked exactly like the second versions), but the second versions were still faster.</p>

<ol>
<li>Why doesn't the compiler generate the faster version on x86-32?</li>
<li>Why are the second versions still faster on x86-64 when the assembly output is identical?</li>
</ol>

<p><strong>EDIT: I've added benchmarking code. ZERO: 1544ms, 1358ms NON_ZERO: 1544ms, 1358ms</strong>
<a href=""http://pastebin.com/m7ZSUrcP"" rel=""noreferrer"">http://pastebin.com/m7ZSUrcP</a>
or
<a href=""http://anonymouse.org/cgi-bin/anon-www.cgi/http://pastebin.com/m7ZSUrcP"" rel=""noreferrer"">http://anonymouse.org/cgi-bin/anon-www.cgi/http://pastebin.com/m7ZSUrcP</a></p>

<p>Note: It's probably inconvenient to locate these functions when compiled in a single source file, because main.asm goes quite big. I had zero1, zero2, nonZero1, nonZero2 in a separate source file.</p>

<p><strong>EDIT2: Could someone with both VC++11 and VC++2010 installed run the benchmarking code and post the timings? It might indeed be a bug in VC++11.</strong></p>
",int operators != and == when comparing to zero,0.02498334
2193953,109750,2735,"<p>I have a Flash project, and it has many source files. I have a fairly heavily-used class, call it Jenine. I recently (and, perhaps, callously) relocated Jenine from one namespace to another. I thought we were ready - I thought it was time. The new Jenine was better in every way - she had lost some code bloat, she had decoupled herself from a few vestigial class relationships, and she had finally come home to the namespace that she had always secretly known in her heart was the one she truly belonged to. She was among her own kind.</p>

<p>Unfortunately, Flash would have none of that. Perhaps it had formed an attachment. Perhaps it didn't <em>want</em> Jenine to be decoupled. Either way, it clung to the old, perfect version of Jenine in its memory. It refused to move on. It ignored her (function) calls. It tried to forget her new, public interfaces. Instead, every instance of Jenine that it constructed was always a copy of the old version, down to its classpath:</p>

<pre><code>var jenineInstance:Jenine = new Jenine();
trace( getQualifiedClassName(jenineInstance));
// Should print: com.newnamespace.subspace::Jenine
// Prints: com.oldnamespace.subspace::Jenine
// Ah, young love!
</code></pre>

<p>We fought. I'm not proud of some of the things I said or did. In the end, in a towering fit of rage, I deleted all references of Jenine completely. She was utterly, completely erased from the system. My cursor fell upon the ""Empty Trash"" menu option like the cold lid of a casket.</p>

<p>I don't think Flash ever recovered. To this day it still clings to the memory of Jenine. Her old, imperfect definitions still float through my project like abandoned ghosts. Whenever I force Flash to compile, it still lovingly inserts her into my movie, nestling her definition in amongst the other, living classes, like a small shrine. I wonder if they can see her.</p>

<p>Flash and I don't really talk anymore. I write my code, it compiles it. There's a new girl in town named Summer who looks almost identical to Jenine, as if someone had just copied her source-code wholesale into a new class, but Flash hasn't shown any interest. Most days it just mopes around and writes bad poetry in my comments when it thinks I'm not looking.</p>

<p>I hope no one else has had a similar experience, that this is just a singular, painful ripple in the horrifying dark lagoon that is the Flash code-base. Does anyone have any idea how to erase whatever cache the compiler is using?</p>
",Flash CS4 refuses to let go,0.02492027
11132868,7467,186,"<p>Consider the following piece of code:</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;unistd.h&gt;

int main(void)
{
    int i;
    for(i = 0; i &lt; 2; i++)
    {
        fork();
        printf(""."");
    }
    return 0;
}
</code></pre>

<p>This program outputs 8 dots. How can that be possible? Should not there be 6 dots instead?</p>
",fork() branches more than expected?,0.0249096
25715898,4340,108,"<p>I'm confused about what's the correct way to ignore the contents of a directory in git.</p>

<p>Assume I have the following directory structure:</p>

<pre><code>my_project  
     |--www  
         |--1.txt  
         |--2.txt
     |--.gitignore
</code></pre>

<p>What's the difference between putting this:</p>

<pre><code>www
</code></pre>

<p>And this?</p>

<pre><code>www/*
</code></pre>

<p>The reason I'm asking this question is: In git, if a directory is empty, git won't include such empty directory in repository. So I was trying the solution that is add an extra .gitkeep file under the directory so that it won't be empty. When I was trying that solution, if in the .gitignore file, I write like below:</p>

<pre><code>www
!*.gitkeep
</code></pre>

<p>It doesn't work(My intention is to ignore all contents under www but keep the directory). But if I try the following:</p>

<pre><code>www/* 
!*.gitkeep
</code></pre>

<p>Then it works! So I think it must has some differences between the two approaches.</p>
",What's the difference between Git ignoring directory and directory/*?,0.02488479
11593615,7757,193,"<p>This has got me stumped. I was trying to optimize some tests for Noda Time, where we have some type initializer checking. I thought I'd find out whether a type <em>has</em> a type initializer (static constructor or static variables with initializers) before loading everything into a new <code>AppDomain</code>. To my surprise, a small test of this threw <code>NullReferenceException</code> - despite there being no null values in <em>my</em> code. It <em>only</em> throws the exception when compiled with no debug information.</p>

<p>Here's a short but complete program to demonstrate the problem:</p>

<pre><code>using System;

class Test
{
    static Test() {}

    static void Main()
    {
        var cctor = typeof(Test).TypeInitializer;
        Console.WriteLine(""Got initializer? {0}"", cctor != null);
    }    
}
</code></pre>

<p>And a transcript of compilation and output:</p>

<pre class=""lang-none prettyprint-override""><code>c:\Users\Jon\Test&gt;csc Test.cs
Microsoft (R) Visual C# Compiler version 4.0.30319.17626
for Microsoft (R) .NET Framework 4.5
Copyright (C) Microsoft Corporation. All rights reserved.


c:\Users\Jon\Test&gt;test

Unhandled Exception: System.NullReferenceException: Object reference not set to
an instance of an object.
   at System.RuntimeType.GetConstructorImpl(BindingFlags bindingAttr, Binder bin
der, CallingConventions callConvention, Type[] types, ParameterModifier[] modifi
ers)
   at Test.Main()

c:\Users\Jon\Test&gt;csc /debug+ Test.cs
Microsoft (R) Visual C# Compiler version 4.0.30319.17626
for Microsoft (R) .NET Framework 4.5
Copyright (C) Microsoft Corporation. All rights reserved.


c:\Users\Jon\Test&gt;test
Got initializer? True
</code></pre>

<p>Now you'll notice I'm using .NET 4.5 (the release candidate) - which <em>may</em> be relevant here. It's somewhat tricky for me to test it with the various other original frameworks (in particular ""vanilla"" .NET 4) but if anyone else has easy access to machines with other frameworks, I'd be interested in the results.</p>

<p>Other details:</p>

<ul>
<li>I'm on an x64 machine, but this problem occurs with both x86 and x64 assemblies</li>
<li>It's the ""debug-ness"" of the <em>calling</em> code which makes a difference - even though in the test case above it's testing it on its own assembly, when I tried this against Noda Time I didn't have to recompile <code>NodaTime.dll</code> to see the differences - just <code>Test.cs</code> which referred to it.</li>
<li>Running the ""broken"" assembly on Mono 2.10.8 <em>doesn't</em> throw</li>
</ul>

<p>Any ideas? Framework bug?</p>

<p>EDIT: Curiouser and curiouser. If you take out the <code>Console.WriteLine</code> call:</p>

<pre><code>using System;

class Test
{
    static Test() {}

    static void Main()
    {
        var cctor = typeof(Test).TypeInitializer;
    }    
}
</code></pre>

<p>It now <em>only</em> fails when compiled with <code>csc /o- /debug-</code>. If you turn on optimizations, (<code>/o+</code>) it works. But if you include the <code>Console.WriteLine</code> call as per the original, both versions will fail.</p>
",Why would finding a type's initializer throw a NullReferenceException?,0.02488075
31398444,3538,88,"<p>I would like to know regarding following behavior of <code>instanceof</code> operator in Java.</p>

<pre><code>interface C {}

class B {}

public class A {
    public static void main(String args[]) {
        B obj = new B();
        System.out.println(obj instanceof A);      //Gives compiler error
        System.out.println(obj instanceof C);      //Gives false as output
    }
}
</code></pre>

<p>Why is it so? There is no relation between <code>interface C</code> and <code>class B</code>, but it gives false whereas in case of <code>obj instanceof A</code> it gives compiler error?</p>
",The 'instanceof' operator behaves differently for interfaces and classes,0.02487281
5275578,3740,93,"<p>The way <a href=""http://roxygen.org/"">Roxygen</a> seems to work is that the first line is the <code>\title</code>, everything else is in the <code>\details</code>, and then any <code>@foo</code> directives handle those things. But R documentation is richer than that. I can have <code>""\section{Llamas}{Are they ungulates?}""</code> in .Rd files.</p>

<p>But I can't get Roxygen to do anything other than wrap it all in \details. Am I missing something?</p>

<p>I have a hacky solution, which is to stick an unmatched <code>}</code> before my <code>\section</code>. This then ends the <code>\details</code> section. I then have to not put an ending <code>}</code> in, because roxygen sticks one in thinking its closing the <code>\details</code>. Eeeeeurrrrrrrrgh.</p>
",Arbitrary sections in roxygen docs,0.02486631
19108008,3383,84,"<p>Please explain what, exactly, happens when the following sections of code are executed:</p>

<pre><code>int a='\15';
System.out.println(a);
</code></pre>

<p>this prints out 13;</p>

<pre><code>int a='\25';
System.out.println(a);
</code></pre>

<p>this prints out 21;</p>

<pre><code>int a='\100';
System.out.println(a);
</code></pre>

<p>this prints out 64.</p>
","What are the Java semantics of an escaped number in a character literal, e.g. '\15' ?",0.02483003
19209650,5127,127,"<p>When preparing an <a href=""https://stackoverflow.com/help/mcve"">MCVE</a>/<a href=""http://sscce.org/"" rel=""noreferrer"">SSCCE</a> that involves images, it is useful to have direct access to images.  </p>

<p>The types of images that would cover most questions are - small images in multiple colors or shapes, animated GIFs with/without transparency, JPEGs that are 'pairs' of pictures &amp; can be used in image transitions, tile sets, sprite sheets..</p>

<p>Are there any small (under 30KB), on-site, license &amp; royalty free images we can hot-link to for these types of examples?</p>
",Example images for code and mark-up Q&As,0.02477082
40447195,6910,171,"<p>I am using an <code>int</code> type to store a value. By the semantics of the program, the value always varies in a very small range (0 - 36), and <code>int</code> (not a <code>char</code>) is used only because of the CPU efficiency.</p>

<p>It seems like many special arithmetical optimizations can be performed on such a small range of integers. Many function calls on those integers might be optimized into a small set of ""magical"" operations, and some functions may even be optimized into table look-ups.</p>

<p>So, is it possible to tell the compiler that this <code>int</code> is always in that small range, and is it possible for the compiler to do those optimizations?</p>
",Can I hint the optimizer by giving the range of an integer?,0.02474674
20353613,17682,437,"<p>In my class, I was playing around and found out that CSS works with made-up elements.</p>

<p>Example:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>imsocool {
    color:blue;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;imsocool&gt;HELLO&lt;/imsocool&gt;</code></pre>
</div>
</div>
</p>

<p>When my professor first saw me using this, he was a bit surprised that made-up elements worked and recommended I simply change all of my made up elements to paragraphs with ID's.</p>

<p>Why doesn't my professor want me to use made-up elements? They work effectively.</p>

<p>Also, why didn't he know that made-up elements exist and work with CSS. Are they uncommon?</p>
",Why does CSS work with fake elements?,0.0247144
10596467,4271,105,"<p>I'd like to add new bearer(s) to Android (rooted/custom build), to be a peer with Wifi and GPRS.</p>

<p>I have done some Android development and I am aware that (in Android 2.2)  there are constants for WIFI and GPRS.  Does this mean that I will need to be adding constants in all over the place, as well as providing the network stack?</p>

<p>The first bearer I want to add is USBNet (for Androids with USB host).</p>

<p>Another will be a 3G USB dongle as a second GPRS bearer.</p>

<p>I have started by downloading the source.</p>
",Adding a new network bearer to Android,0.02458441
11432508,5996,147,"<p>Why does the first and second Write work but not the last? Is there a way I can allow all 3 of them and detect if it was 1, (int)1 or i passed in? And really why is one allowed but the last? The second being allowed but not the last really blows my mind.</p>

<p><a href=""http://ideone.com/tQjCm"" rel=""noreferrer"">Demo to show compile error</a></p>

<pre><code>using System;
class Program
{
    public static void Write(short v) { }
    static void Main(string[] args)
    {
        Write(1);//ok
        Write((int)1);//ok
        int i=1;
        Write(i);//error!?
    }
}
</code></pre>
","Why can I pass 1 as a short, but not the int variable i?",0.02451634
6638291,3110,76,"<p>Outside of the argument of whether or not NULLs should ever be used: I am responsible for an existing database that uses NULL to mean ""missing or never entered"" data.  It is different from empty string, which means ""a user set this value, and they selected 'empty'.""</p>

<p>Another contractor on the project is firmly on the ""NULLs do not exist for me; I never use NULL and nobody else should, either"" side of the argument.  However, what confuses me is that since the contractor's team DOES acknowledge the difference between ""missing/never entered"" and ""intentionally empty or indicated by the user as unknown,"" they use a single character 'Z' throughout their code and stored procedures to represent ""missing/never entered"" with the same meaning as NULL throughout the rest of the database.</p>

<p>Although our shared customer has asked for this to be changed, and I have supported this request, the team cites this as ""standard practice"" among DBAs far more advanced than I; they are reluctant to change to use NULLs based on my ignorant request alone.  So, can anyone help me overcome my ignorance?  Is there any standard, or small group of individuals, or even a single loud voice among SQL experts which advocates the use of 'Z' in place of NULL?</p>

<h2>Update</h2>

<p>I have a response from the contractor to add.  Here's what he said when the customer asked for the special values to be removed to allow NULL in columns with no data:</p>

<blockquote>
  <p><em>Basically, I designed the database to avoid NULLs whenever possible.  Here is the rationale:</em></p>
  
  <p>• <em>A NULL in a string [VARCHAR] field is never necessary because an empty (zero-length) string furnishes exactly the same information.</em></p>
  
  <p>•  <em>A NULL in an integer field (e.g., an ID value) can be handled by using a value that would never occur in the data (e.g, -1 for an integer IDENTITY field).</em> </p>
  
  <p>•  <em>A NULL in a date field can easily cause complications in date calculations.  For example, in logic that computes date differences, such as the difference in days between a [RecoveryDate] and an [OnsetDate], the logic will blow up if one or both dates are NULL -- unless an explicit allowance is made for both dates being NULL.  That's extra work and extra handling.  If ""default"" or ""placeholder"" dates are used for [RecoveryDate] and [OnsetDate] (e.g., ""1/1/1900"") , mathematical calculations might show ""unusual"" values -- but date logic will not blow up.</em></p>
  
  <p><em>NULL handling has traditionally been an area where developers make mistakes in stored procedures.</em> </p>
  
  <p><em>In my 15 years as a DBA, I've found it best to avoid NULLs wherever possible.</em></p>
</blockquote>

<p>This seems to validate the mostly negative reaction to this question.  Instead of applying an accepted 6NF approach to designing out NULLs, special values are used to ""avoid NULLs wherever possible.""  I posted this question with an open mind, and I am glad I learned more about the ""NULLs are useful / NULLs are evil"" debate, but I am now quite comfortable labeling the 'special values' approach to be complete nonsense.</p>

<blockquote>
  <p>an empty (zero-length) string furnishes exactly the same information. </p>
</blockquote>

<p>No, it doesn't; in the existing database we are modifying, NULL means ""never entered"" and empty string means ""entered as empty"".</p>

<blockquote>
  <p>NULL handling has traditionally been an area where developers make mistakes in stored procedures.</p>
</blockquote>

<p>Yes, but those mistakes have been made thousands of times by thousands of developers, and the lessons and caveats for avoiding those mistakes are known and documented.  As has been mentioned here: whether you accept or reject NULLs, representation of missing values is a <em>solved problem</em>.  There is no need to invent a new solution just because developers continue make easy-to-overcome (and easy-to-identify) mistakes.</p>

<hr>

<p><em>As a footnote: I have been a DBE and developer for more than 20 years (which is certainly enough time for me to know the difference beetween a database engineer and a database administrator).  Throughout my career I have always been in the ""NULLs are useful"" camp, though I was aware that several very smart people disagreed.  I was extremely skeptical about the ""special values"" approach, but not well-versed enough in the academics of ""How To Avoid NULL the Right Way"" to make a firm stand.  I always love learning new things—and I still have lots to learn after 20 years.  Thanks to all who contributed to make this a useful discussion.</em></p>
",Standard use of 'Z' instead of NULL to represent missing data?,0.0244373
5027999,7915,193,"<p>Yesterday I was giving a talk about the new C# ""async"" feature, in particular delving into what the generated code looked like, and <code>the GetAwaiter()</code> / <code>BeginAwait()</code> / <code>EndAwait()</code> calls.</p>

<p>We looked in some detail at the state machine generated by the C# compiler, and there were two aspects we couldn't understand:</p>

<ul>
<li>Why the generated class contains a <code>Dispose()</code> method and a <code>$__disposing</code> variable, which never appear to be used (and the class doesn't implement <code>IDisposable</code>).</li>
<li>Why the internal <code>state</code> variable is set to 0 before any call to <code>EndAwait()</code>, when 0 normally appears to mean ""this is the initial entry point"".</li>
</ul>

<p>I suspect the first point could be answered by doing something more interesting within the async method, although if anyone has any further information I'd be glad to hear it. This question is more about the second point, however.</p>

<p>Here's a very simple piece of sample code:</p>

<pre><code>using System.Threading.Tasks;

class Test
{
    static async Task&lt;int&gt; Sum(Task&lt;int&gt; t1, Task&lt;int&gt; t2)
    {
        return await t1 + await t2;
    }
}
</code></pre>

<p>... and here's the code which gets generated for the <code>MoveNext()</code> method which implements the state machine. This is copied directly from Reflector - I haven't fixed up the unspeakable variable names:</p>

<pre><code>public void MoveNext()
{
    try
    {
        this.$__doFinallyBodies = true;
        switch (this.&lt;&gt;1__state)
        {
            case 1:
                break;

            case 2:
                goto Label_00DA;

            case -1:
                return;

            default:
                this.&lt;a1&gt;t__$await2 = this.t1.GetAwaiter&lt;int&gt;();
                this.&lt;&gt;1__state = 1;
                this.$__doFinallyBodies = false;
                if (this.&lt;a1&gt;t__$await2.BeginAwait(this.MoveNextDelegate))
                {
                    return;
                }
                this.$__doFinallyBodies = true;
                break;
        }
        this.&lt;&gt;1__state = 0;
        this.&lt;1&gt;t__$await1 = this.&lt;a1&gt;t__$await2.EndAwait();
        this.&lt;a2&gt;t__$await4 = this.t2.GetAwaiter&lt;int&gt;();
        this.&lt;&gt;1__state = 2;
        this.$__doFinallyBodies = false;
        if (this.&lt;a2&gt;t__$await4.BeginAwait(this.MoveNextDelegate))
        {
            return;
        }
        this.$__doFinallyBodies = true;
    Label_00DA:
        this.&lt;&gt;1__state = 0;
        this.&lt;2&gt;t__$await3 = this.&lt;a2&gt;t__$await4.EndAwait();
        this.&lt;&gt;1__state = -1;
        this.$builder.SetResult(this.&lt;1&gt;t__$await1 + this.&lt;2&gt;t__$await3);
    }
    catch (Exception exception)
    {
        this.&lt;&gt;1__state = -1;
        this.$builder.SetException(exception);
    }
}
</code></pre>

<p>It's long, but the important lines for this question are these:</p>

<pre><code>// End of awaiting t1
this.&lt;&gt;1__state = 0;
this.&lt;1&gt;t__$await1 = this.&lt;a1&gt;t__$await2.EndAwait();

// End of awaiting t2
this.&lt;&gt;1__state = 0;
this.&lt;2&gt;t__$await3 = this.&lt;a2&gt;t__$await4.EndAwait();
</code></pre>

<p>In both cases the state is changed again afterwards before it's next obviously observed... so why set it to 0 at all? If <code>MoveNext()</code> were called again at this point (either directly or via <code>Dispose</code>) it would effectively start the async method again, which would be wholly inappropriate as far as I can tell... if and <code>MoveNext()</code> <em>isn't</em> called, the change in state is irrelevant.</p>

<p>Is this simply a side-effect of the compiler reusing iterator block generation code for async, where it may have a more obvious explanation?</p>

<p><strong>Important disclaimer</strong></p>

<p>Obviously this is just a CTP compiler. I fully expect things to change before the final release - and possibly even before the next CTP release. This question is in no way trying to claim this is a flaw in the C# compiler or anything like that. I'm just trying to work out whether there's a subtle reason for this that I've missed :)</p>
","C# 5 async CTP: why is internal ""state"" set to 0 in generated code before EndAwait call?",0.02438408
10753306,3610,88,"<p>From the <a href=""http://api.jquery.com/ready/"">jQuery API docs site</a> for <code>ready</code> </p>

<blockquote>
  <p>All three of the following syntaxes are equivalent:</p>
  
  <ul>
  <li>$(document).ready(handler)</li>
  <li><strong>$().ready(handler) (this is not recommended)</strong></li>
  <li>$(handler)</li>
  </ul>
</blockquote>

<p>After doing homework - reading and playing with the <a href=""http://code.jquery.com/jquery-1.7.2.js"">source code</a>, I have no idea why </p>

<pre><code>$().ready(handler) 
</code></pre>

<p>is not recommended.  The first and third ways, are exactly the same, the third option calls the ready function on a cached jQuery object with <code>document</code>:</p>

<pre><code>rootjQuery = jQuery(document);
...
...

// HANDLE: $(function)
// Shortcut for document ready
} else if ( jQuery.isFunction( selector ) ) {
    return rootjQuery.ready( selector );
}
</code></pre>

<p>But the ready function has no interaction with the selector of the selected node elements, The <code>ready</code> source code:</p>

<pre><code>ready: function( fn ) {
    // Attach the listeners
    jQuery.bindReady();
        // Add the callback
    readyList.add( fn );
        return this;
},
</code></pre>

<p>As you can see, it justs add the callback to an internal queue( <code>readyList</code>) and doesn't change or use the elements in the set. This lets you call the <code>ready</code> function on every jQuery object.</p>

<p>Like:</p>

<ul>
<li><strong>regular</strong> selector: <code>$('a').ready(handler)</code> <a href=""http://jsfiddle.net/w5k5t/1/"">DEMO</a></li>
<li><strong>Nonsense</strong> selector: <code>$('fdhjhjkdafdsjkjriohfjdnfj').ready(handler)</code> <a href=""http://jsfiddle.net/w5k5t/2/"">DEMO</a></li>
<li><strong>Undefined</strong> selector:<code>$().ready(handler)</code> <a href=""http://jsfiddle.net/w5k5t/3/"">DEMO</a></li>
</ul>

<p>Finally... to my question: <strong>Why <code>$().ready(handler)</code> is not recommended?</strong></p>
","Why ""$().ready(handler)"" is not recommended?",0.02437673
51521158,7842,191,"<p>Inputting the command <code>0xbin()</code> returns False:</p>

<pre><code>&gt;&gt;&gt; 0xbin()
False
</code></pre>

<p>Why does that happen? This syntax should have no meaning whatsoever. Functions cannot start with 0, there are no ""i"" and ""n"" in hex, and the bin function must have some arguments.</p>
","In python, why does 0xbin() return False?",0.02435603
26776802,4319,105,"<p>I'm working on a 3.8-e4 hybrid (i.e we have the Luna dependencies, but we <b>do not</b> use the <em>Application.e4xmi</em>, yet). So we're basically running the compact layer.</p>

<p>With that being said, it would be nice to find an e4 programmatic way to stack these nasty views onto the editor folder.</p>

<hr>

<h2>1.) Problem</h2>

<p>I want to place a generic view folder in the editor area, so that each view which is opened at runtime will be opened there. </p>

<p><img src=""https://i.stack.imgur.com/zHcn8.png"" alt=""View in editor folder""></p>

<p><i>(pic stolen from <a href=""https://stackoverflow.com/questions/2758642/eclipse-rcp-stacking-a-view-with-the-editor-area"">this question</a>)</i></p>

<hr>

<h2>2.1) Possible fix no.1: Using plugin.xml</h2>

<p>Create a perspective extension, and add each possible view to that extension, with <b>relationship stack</b> over <b>relative org.eclipse.ui.editorss</b>. This is a bit inconvenient if you have too many views awating to be opened, and if the project scales quickly. I also noticed that wildcard view IDs do not work here.</p>

<p><img src=""https://i.stack.imgur.com/veJDE.png"" alt=""SS of the plugin.xml with perspective extensions""></p>

<p>If you find yourself the time to add each possible view to the perspective extension, that would work. Although, IF you open a view which is not added here (ie: opens in a different folder), then each subsequent opened view will be opened in the previous folder, and NOT in the editor area (inquire further explanation if you don't get it).</p>

<hr>

<h2>2.2) Possible fix no.2: Using code in the perspective factory</h2>

<p>In the <code>IPerspectiveFactory</code>, we do have access to the <code>IPageLayout</code>, which happens to be <code>org.eclipse.ui.internal.e4.compatibility.ModeledPageLayout</code> (e4 stuff). </p>

<p>Now, this <code>ModeledPageLayout</code> implementation is reasonable, but also no documentation and weird public APIs. This one gives the possibility to stack a view over any other relative</p>

<pre><code>modeledPageLayout.stackView(""newView0"", IPageLayout.ID_EDITOR_AREA);
</code></pre>

<p>This would be the programmatic version of <b>2.1</b>. Also, the same problem appears here. If a view is opened somewhere else, the code above becomes useless.</p>

<p>Interesting enough, the <code>stackView</code> API does not support wildcards (while others such as <code>addView</code> do).</p>

<hr>

<h2>2.3) Possible fix no.3: Workarounds yaaay!</h2>

<p>I have a lot of perspectives, and a lot of different folders in each one. Everything is precisely placed. </p>

<p>Since Eclipse offers the APIs to get all the view IDs from everywhere around the system, I want to do the following, per perspective: <b>each view ID which wasn't added to a specific folder will be appended to the editor area (ie editor folder, editor stack)</b>. </p>

<p>This would be my last resort, unless someone offers a more convenient and timesaving solution.</p>

<p>Remember, an e4 programmatic alternative is more flexible!</p>

<hr>

<h2>3.) Related questions</h2>

<ul>
<li><a href=""https://stackoverflow.com/questions/21382848/eclipse-rcp-open-view-in-editor-folder"">Eclipse RCP -- Open View in Editor folder</a></li>
<li><a href=""https://stackoverflow.com/questions/2758642/eclipse-rcp-stacking-a-view-with-the-editor-area"">Eclipse  RCP - Stacking a view with the editor area? </a></li>
<li><a href=""https://stackoverflow.com/questions/22921306/custom-eclipse-perspective-with-initially-invisble-view-stacked-to-editor-area"">Custom Eclipse perspective, with initially invisble view stacked to editor area</a></li>
<li><a href=""https://groups.google.com/forum/#!topic/vogella/_2yEZMg8epk"" rel=""nofollow noreferrer"">Google question, Lars answer</a></li>
</ul>

<p>These would be rendered deprecated for the e4 release.</p>

<hr>

<h2>4.) Related Bug on Eclipse's Bugzilla:</h2>

<p><a href=""https://bugs.eclipse.org/bugs/show_bug.cgi?id=450854"" rel=""nofollow noreferrer"">This recent bug opened by myself</a> has an attachment with a small SSCCE. The steps to reproduce this are described in <a href=""https://bugs.eclipse.org/bugs/show_bug.cgi?id=450854#c2"" rel=""nofollow noreferrer"">this comment</a>, so I'm not going to copy-paste them here.</p>
",Eclipse RCP - Open a View in the Editor Area (3.8/e4 hybrid),0.02431118
55590324,3456,84,"<p>How can two versions of the same function, differing only in one being inline and the other one not, return different values? Here is some code I wrote today and I am not sure how it works.</p>

<pre class=""lang-cpp prettyprint-override""><code>#include &lt;cmath&gt;
#include &lt;iostream&gt;

bool is_cube(double r)
{
    return floor(cbrt(r)) == cbrt(r);
}

bool inline is_cube_inline(double r)
{
    return floor(cbrt(r)) == cbrt(r);
}

int main()
{
    std::cout &lt;&lt; (floor(cbrt(27.0)) == cbrt(27.0)) &lt;&lt; std::endl;
    std::cout &lt;&lt; (is_cube(27.0)) &lt;&lt; std::endl;
    std::cout &lt;&lt; (is_cube_inline(27.0)) &lt;&lt; std::endl;
}

</code></pre>

<p>I would expect all outputs to be equal to <code>1</code>, but it actually outputs this (g++ 8.3.1, no flags):</p>

<pre><code>1
0
1
</code></pre>

<p>instead of</p>

<pre><code>1
1
1
</code></pre>

<p>Edit: clang++ 7.0.0 outputs this:</p>

<pre><code>0
0
0
</code></pre>

<p>and g++ -Ofast this:</p>

<pre><code>1
1
1
</code></pre>
",Inline version of a function returns different value than non-inline version,0.02430556
2252772,3381,82,"<p>I am in the precarious position of ""managing"" a team of developers at a small company. I say ""managing"" because although I assign work and provide feedback on their performance I have no recourse in actually disciplining an individual. </p>

<p>Some of my team I don't know what to do with, they are unable to work on their own, require massive amounts of hand holding and when left along generally wreak havoc on the project usually to a point of failure. When failure does occur I am left to salvage the project and push it (some times limping) across the finish line. </p>

<p>These developers not only lack skills with programming concepts, but generally ability to formulate a solution to a problem in code. Simple things like writing loops are tough for them let alone designing and implementing a solution to a problem.</p>

<p>We have tried pair programming, offering to pay for classes, buying books, allocating time during the work day to training and even taking whole days to train the team.  </p>

<p>The other senior developer and I do not know what to do, but our productivity is being throttled with having to deal with these individuals day to day. Management is forcing us to give them work and their major complaint is how things aren't getting done quickly enough.</p>

<p>None of our management team works directly with any of the developers other than myself and the other senior developer. Management is non-technical and believes every developer is created equally, and that we obviously need more people on these projects to get them done faster.</p>

<p>I am already preparing a document with sections from ""The Mythical Man Month"" and ""Code Complete"" to send to management to hopefully illustrate with statistics that what is really hindering us is having to drag the mediocre folks through the development cycle.</p>

<p>What other resources are out there? Books, articles, general advice anything would be helpful.</p>
",How to demonstrate to management that mediocre developers are hurting team,0.02425318
47871962,3179,77,"<p>The following code compiles in both Java 8 &amp; 9, but behaves differently.</p>

<pre class=""lang-java prettyprint-override""><code>class Simple {
    static String sample = ""\nEn un lugar\r\nde la Mancha\nde cuyo nombre\r\nno quiero acordarme"";

    public static void main(String args[]){
        String[] chunks = sample.split(""\\R\\R"");
        for (String chunk: chunks) {
            System.out.println(""Chunk : ""+chunk);
        }
    }
}
</code></pre>

<p>When I run it with Java 8 it returns:</p>

<pre class=""lang-none prettyprint-override""><code>Chunk : 
En un lugar
de la Mancha
de cuyo nombre
no quiero acordarme
</code></pre>

<p>But when I run it with Java 9 the output is different:</p>

<pre class=""lang-none prettyprint-override""><code>Chunk : 
En un lugar
Chunk : de la Mancha
de cuyo nombre
Chunk : no quiero acordarme
</code></pre>

<p>Why?</p>
",Why does \R behave differently in regular expressions between Java 8 and Java 9?,0.02422145
18958747,3186,77,"<p>So, some way or another (playing around), I found myself with a regex like <code>\d{1}{2}</code>.</p>

<p>Logically, to me, it should mean:</p>

<blockquote>
  <p>(A digit exactly once) exactly twice, i.e. a digit exactly twice.</p>
</blockquote>

<p>But it, in fact, appears to just mean ""a digit exactly once"" (thus ignoring the <code>{2}</code>).</p>

<pre><code>String regex = ""^\\d{1}{2}$""; // ^$ to make those not familiar with 'matches' happy
System.out.println(""1"".matches(regex)); // true
System.out.println(""12"".matches(regex)); // false
</code></pre>

<p>Similar results can be seen using <code>{n}{m,n}</code> or similar.</p>

<p>Why does this happen? Is it explicitly stated in regex / Java documentation somewhere or is it just a decision Java developers made on-the-fly or is it maybe a bug?</p>

<p>Or is it in fact not ignored and it actually means something else entirely?</p>

<p>Not that it matters much, but it's not across-the-board regex behaviour, <a href=""http://www.rubular.com/r/eefKxje4nf"">Rubular</a> does what I expect.</p>

<p>Note - the title is mainly for searchability for users who want to know how it works (not why).</p>
","How does {m}{n} (""exactly n times"" twice) work?",0.02416824
7884705,3976,96,"<p>This is a situation I encounter frequently as an inexperienced programmer and am wondering about particularly for an ambitious, speed-intensive project of mine I'm trying to optimize.  For the major C-like languages (C, objC, C++, Java, C#, etc) and their usual compilers, will these two functions run just as efficiently?  Is there any difference in the compiled code?</p>

<pre><code>void foo1(bool flag)
{
    if (flag)
    {
        //Do stuff
        return;
    }

    //Do different stuff
}

void foo2(bool flag)
{
    if (flag)
    {
        //Do stuff
    }
    else
    {
        //Do different stuff
    }
}
</code></pre>

<p>Basically, is there ever a direct efficiency bonus/penalty when <code>break</code>ing or <code>return</code>ing early?  How is the stackframe involved?  Are there optimized special cases?  Are there any factors (like inlining or the size of ""Do stuff"") that could affect this significantly?</p>

<p>I'm always a proponent of improved legibility over minor optimizations (I see foo1 a lot with parameter validation), but this comes up so frequently that I'd like to set aside all worry once and for all.  </p>

<p>And I'm aware of the pitfalls of premature optimization... ugh, those are some painful memories.</p>

<p>EDIT:  I accepted an answer, but EJP's answer explains pretty succinctly why the use of a <code>return</code> is practically negligible (in assembly, the <code>return</code> creates a 'branch' to the end of the function, which is extremely fast.  The branch alters the PC register and may also affect the cache and pipeline, which is pretty minuscule.)  For this case in particular, it literally makes no difference because both the <code>if/else</code> and the <code>return</code> create the same branch to the end of the function.</p>
",Efficiency of premature return in a function,0.02414487
33614455,3485,84,"<p>Consider this strange program:</p>

<pre><code>int main()
{
    int(*){} Is it C++14 or any other language?
}
</code></pre>

<p>(See a live demo <a href=""http://melpon.org/wandbox/permlink/YYiMrSh2AIrHxbWy"">here</a> &amp; <a href=""http://cpp.sh/46vs"">here</a>.)</p>

<p><strong>Even though the comment <code>//</code> is missing,</strong> the code compiles fine without any errors &amp; warnings even when I use <code>-pedantic-errors</code>options in g++ 6.0. This seems like a compiler bug to me. Is it really a bug in the compiler?</p>
",Why does this invalid-looking code compile successfully on g++ 6.0?,0.0241033
29681449,4815,116,"<p>As an interesting follow-up (not of big practical importance though) to my previous question:
<a href=""https://stackoverflow.com/questions/29675601/why-does-c-allow-us-to-surround-the-variable-name-in-parentheses-when-declarin"">Why does C++ allow us to surround the variable name in parentheses when declaring a variable?</a></p>

<p>I found out that combining the declaration in parentheses with <a href=""https://stackoverflow.com/questions/25549652/c-why-is-there-injected-class-name/25549691#25549691"">injected class name</a> feature may lead to surprising results regarding compiler behavior.</p>

<p>Take a look at the following program:</p>

<pre><code>#include &lt;iostream&gt;
struct B
{
};

struct C
{
  C (){ std::cout &lt;&lt; ""C"" &lt;&lt; '\n'; }
  C (B *) { std::cout &lt;&lt; ""C (B *)"" &lt;&lt; '\n';}
};

B *y = nullptr;
int main()
{
  C::C (y);
}
</code></pre>

<ol>
<li><p>Compiling with g++ 4.9.2 gives me the following compilation error:</p>

<pre><code>main.cpp:16:10: error: cannot call constructor 'C::C' directly [-fpermissive]
</code></pre></li>
<li><p>It compiles successfully with MSVC2013/2015 and prints <code>C (B *)</code></p></li>
<li><p>It compiles successfully with clang 3.5 and prints <code>C</code></p></li>
</ol>

<p>So obligatory question is which one is right? :)</p>

<p><em>(I strongly swayed towards clang version though and msvc way to stop declaring variable after just changing type with technically its typedef seems kind of weird)</em></p>
",Program being compiled differently in 3 major C++ compilers. Which one is right?,0.02409138
38005656,6947,167,"<p>I am researching CoffeeScript on the website <a href=""http://coffeescript.org/"" rel=""noreferrer"">http://coffeescript.org/</a>, and it has the text</p>

<blockquote>
  <p>The CoffeeScript compiler is itself written in CoffeeScript</p>
</blockquote>

<p>How can a compiler compile itself, or what does this statement mean?</p>
",How can a compiler compile itself?,0.02403915
29691513,3471,83,"<p>Someone explain to me the differences between the following two statements?</p>

<p>A <code>static final</code> variable initialized by a <code>static</code> code block:</p>

<pre><code>private static final String foo;
static { foo = ""foo""; }
</code></pre>

<p>A <code>static final</code> variable initialized by an assignment:</p>

<pre><code>private static final String foo = ""foo"";
</code></pre>
",Difference between static modifier and static block,0.02391242
10615461,3557,85,"<p>When I do <code>let! read = from.AsyncRead buf</code> in F#, it blocks and doesn't return until the TCP socket is dead. Why? And how do I fix it?</p>

<p>Its code:</p>

<pre class=""lang-ml prettyprint-override""><code>module StreamUtil

open System.IO

/// copy from 'from' stream to 'toStream'
let (|&gt;&gt;) (from : Stream) (toStream : Stream) =
  let buf = Array.zeroCreate&lt;byte&gt; 1024
  let rec doBlock () =
    async {
      let! read = from.AsyncRead buf
      if read &lt;= 0 then
        toStream.Flush()
        return ()
      else
        do! toStream.AsyncWrite(buf, 0, read)
        return! doBlock () }
  doBlock ()
</code></pre>

<p>It's being called from this code:</p>

<pre class=""lang-ml prettyprint-override""><code>use fs = new FileStream(targPath, FileMode.CreateNew, FileAccess.ReadWrite)
do! req.InputStream |&gt;&gt; fs
</code></pre>

<p>and requested over HTTP with this code from Windows Phone 7.1 emulator:</p>

<pre><code>public void Send()
{
    var b = new UriBuilder(_imageService.BaseUrl) {Path = ""/images""};

    var req = WebRequest.CreateHttp(b.Uri);
    req.ContentType = ""image/jpeg"";
    req.Method = ""POST"";
    var imgLen = SelectedImage.ImageStream.Length;
    req.Headers[HttpRequestHeader.ContentLength] = imgLen.ToString(CultureInfo.InvariantCulture);
    req.Accept = ""application/json"";
    req.BeginGetRequestStream(RequestReady, new ReqState(req, imgLen));
}

void RequestReady(IAsyncResult ar)
{
    var state = (ReqState)ar.AsyncState;
    var req = state.Request;

    var reqStream = req.EndGetRequestStream(ar);

    SmartDispatcher.BeginInvoke(() =&gt;
        {
            using (var sw = new StreamWriter(reqStream))
            using (var br = new BinaryReader(SelectedVoucher.ImageStream))
            {
                var readBytes = br.ReadBytes(state.ImgLen);

                // tried both 2
                sw.Write(readBytes);
                //sw.Write(Convert.ToBase64String(readBytes));
                sw.Flush();
                sw.Close();
            }
            req.BeginGetResponse(ResponseReady, req);
        });
}

// WHY IS IT YOU ARE NOT CALLED???
void ResponseReady(IAsyncResult ar)
{
    try
    {
        var request = (HttpWebRequest)ar.AsyncState;
        var response = request.EndGetResponse(ar);

        SmartDispatcher.BeginInvoke(() =&gt;
            {
                var rdr = new StreamReader(response.GetResponseStream());
                var msg = rdr.ReadToEnd();

                var imageLocation = response.Headers[""Location""];

                Debug.WriteLine(msg);
                Debug.WriteLine(imageLocation);
            });
    }
    catch (WebException ex)
    {
        Debug.WriteLine(ex.ToString());
    }
    catch (Exception ex)
    {
        Debug.WriteLine(ex.ToString());
    }
}
</code></pre>

<p>Unsuccessfully. The <code>ResponseReady</code> callback is never reached.</p>

<p>Meanwhile, this code works excellent:</p>

<pre class=""lang-ml prettyprint-override""><code>open System
open System.Net.Http // WebAPI nuget

let sync aw = Async.RunSynchronously aw

let postC&lt;'a&gt; (c : HttpClient) (r : Uri) (cont : HttpContent) =
  let response = sync &lt;| Async.AwaitTask( c.PostAsync(r, cont) )
  let struc:'a = sync &lt;| deserialize&lt;'a&gt; response
  response, struc

let withContent&lt;'a&gt; (fVerb : (HttpClient -&gt; Uri -&gt; HttpContent -&gt; _ * 'a))=
  let c = new HttpClient()
  fVerb c

[&lt;Test&gt;]
let ``POST /images 201 + Location header`` () =
  let post = withContent&lt;MyImage&gt; postC
  let bytes = IO.File.ReadAllBytes(""sample.jpg"")
  let hash = SHA1.Create().ComputeHash(bytes) |&gt; Convert.ToBase64String
  let pic = new ByteArrayContent(bytes)
  pic.Headers.Add(""Content-Type"", ""image/jpeg"")
  pic.Headers.Add(""X-SHA1-Hash"", hash)
  let resp, ri = (resource ""/images"", pic) ||&gt; post

  resp.StatusCode =? Code.Created
  ri.sha1 =? hash
  mustHaveHeaders resp
</code></pre>

<p>I couldn't get Fiddler2 working with WP7.</p>

<p><strong>EDIT: Welcome to a yak. I've moved onto greener pastures myself ;)</strong></p>
",Async POST fails on WP7 and F#,0.02389654
8067897,3602,86,"<p>The following code (taken <a href=""https://stackoverflow.com/questions/8067568/how-do-i-value-initialize-a-type-pointer-using-type-like-syntax/8067658#8067658"">from here</a>):</p>

<pre><code>int* ptr = int();
</code></pre>

<p>compiles in Visual C++ and value-initializes the pointer.</p>

<p>How is that possible? I mean <code>int()</code> yields an object of type <code>int</code> and I can't assign an <code>int</code> to a pointer.</p>

<p>How is the code above not illegal?</p>
","How is ""int* ptr = int()"" value initialization not illegal?",0.02387562
15813851,3941,94,"<p>Google displays a popup that asks if you want to set your home page as google.com. It's quite normal, when I say OK it sets it as google.com. After that however, I don't get the popup anymore. As far as I know, nobody should be able to retrieve the value of my homepage because it's a private info. But somehow Google is tracking it. I get the popup back when I set my homepage as a different site. I deleted the cookies but even then it is only displayed when I set homepage as another site.</p>

<p>I tested this behavior on IE8 &amp; IE9. The popup never shows up in Firefox and Chrome.</p>
",Checking user's homepage in Internet Explorer,0.02385181
34813675,3104,74,"<p>I am practicing for an exam, and found a sample problem that I don't understand. </p>

<p>For the following code, find what the output is: </p>

<pre><code>public class Test {

    private static int count = 0;

    public boolean equals(Test testje) {
        System.out.println(""count = "" + count);
        return false;
    }

    public static void main(String [] args) {
        Object t1 = new Test();
        Object t2 = new Test();
        Test t3 = new Test();
        Object o1 = new Object();

        ++count; t1.equals(t2);
        ++count; t1.equals(t3);
        ++count; t3.equals(o1);
        ++count; t3.equals(t3);
        ++count; t3.equals(t2);
    }
}
</code></pre>

<p>The output of this code is <code>count = 4</code>, but I don't understand why. Can anyone help me?</p>
",Java code related to equals method,0.02384021
15736282,12478,297,"<p>I came across the following program, which compiles without errors or even warnings:</p>

<pre><code>int main(){
  &lt;:]{%&gt;; // smile!
}
</code></pre>

<p><a href=""http://ideone.com/inXuVc"">Live example.</a></p>

<p>What does the program do, and what is that smiley-expression?</p>
","What is this smiley-with-beard expression: ""<:]{%>""?",0.02380189
461231,3996,95,"<p>For instance, take this piece of code:</p>

<pre><code>var person = new Person();
</code></pre>

<p>or for you Pythonistas:</p>

<pre><code>person = Person()
</code></pre>

<p>I'm told constantly how bad this is, but have yet to see an example of the immorality of these two lines of code.  To me, person is a Person and trying to give it another name is a waste of time.  I suppose in the days before syntax highlighting, this would have been a big deal.  But these days, it's pretty easy to tell a type name apart from a variable name.  Heck, it's even easy to see the difference here on SO.</p>

<p>Or is there something I'm missing?  If so, it would be helpful if you could provide an example of code that causes problems.</p>
",Am I immoral for using a variable name that differs from its type only by case?,0.02377377
31345230,5258,125,"<p>I am pulling and installing a package with dependencies, and a compilation fails, in this case not finding a file, <code>magic.h</code>.   How do I see what the compilation commands and flags were? The <code>-v</code> option does not help. (I do NOT want ideas about where to get magic.h from, this is just an example.)</p>

<pre class=""lang-bash prettyprint-override""><code>$ go get -u github.com/presbrey/magicmime
# github.com/presbrey/magicmime
../../../src/github.com/presbrey/magicmime/magicmime.go:20:11: fatal error:   'magic.h' file not found
#include &lt;magic.h&gt;
</code></pre>

<p>How can I find, for example, where it was looking for include files, what source <em>exactly</em> it was compiling? (In this case the source file I see in <code>$GO_PATH/src</code> has that <code>#include</code> commented out, and a <code>/usr/local/include/match.h</code> exists anyway.)</p>
","How can I see the internal compile commands which fail in a ""go get"" installation?",0.0237733
2147783,8137,193,"<p>I used a variable with a lot of data in it, say <code>String data</code>.
I wanted to use a small part of this string in the following way:</p>

<pre><code>this.smallpart = data.substring(12,18);
</code></pre>

<p>After some hours of debugging (with a memory visualizer) I found out that the objects field <code>smallpart</code> remembered all the data from <code>data</code>, although it only contained the substring.</p>

<p>When I changed the code into:</p>

<pre><code>this.smallpart = data.substring(12,18)+""""; 
</code></pre>

<p>..the problem was solved! Now my application uses very little memory now! </p>

<p>How is that possible? Can anyone explain this? I think this.smallpart kept referencing towards data, but why? </p>

<p><strong>UPDATE:</strong>
How can I clear the big String then? Will data = new String(data.substring(0,100)) do the thing?</p>
","Why does appending """" to a String save memory?",0.02371882
18159911,3208,76,"<p>I have a million integers in sorted order and I would like to find the longest subsequence where the difference between consecutive pairs is equal. For example </p>

<pre><code>1, 4, 5, 7, 8, 12
</code></pre>

<p>has a subsequence </p>

<pre><code>   4,       8, 12
</code></pre>

<p>My naive method is greedy and just checks how far you can extend a subsequence from each point. This takes <code>O(n²)</code> time per point it seems.</p>

<p>Is there a faster way to solve this problem?</p>

<p><strong>Update.</strong> I will test the code given in the answers as soon as possible (thank you). However it is clear already that using n^2 memory will not work.   So far there is no code that terminates with the input as <code>[random.randint(0,100000) for r in xrange(200000)]</code> .</p>

<p><strong>Timings.</strong>  I tested with the following input data on my 32 bit system.</p>

<pre><code>a= [random.randint(0,10000) for r in xrange(20000)] 
a.sort()
</code></pre>

<ul>
<li>The dynamic programming method of ZelluX uses 1.6G of RAM and takes 2 minutes and 14 seconds.  With pypy it takes only 9 seconds! However it crashes with a memory error on large inputs.</li>
<li>The O(nd) time method of Armin took 9 seconds with pypy but only 20MB of RAM. Of course this would be much worse if the range were much larger.  The low memory usage meant I could also test it with a= [random.randint(0,100000) for r in xrange(200000)] but it didn't finish in the few minutes I gave it with pypy.</li>
</ul>

<p>In order to be able to test the method of Kluev's I reran with </p>

<pre><code>a= [random.randint(0,40000) for r in xrange(28000)] 
a = list(set(a))
a.sort()
</code></pre>

<p>to make a list of length roughly <code>20000</code>.  All timings with pypy</p>

<ul>
<li>ZelluX, 9 seconds</li>
<li>Kluev, 20 seconds</li>
<li>Armin, 52 seconds</li>
</ul>

<p>It seems that if the ZelluX method could be made linear space it would be the clear winner.</p>
",Longest equally-spaced subsequence,0.02369077
40018398,3295,78,"<p>So i was playing with <code>list</code> objects and found little strange thing that if <code>list</code> is created with <code>list()</code> it uses more memory, than list comprehension? I'm using Python 3.5.2</p>

<pre><code>In [1]: import sys
In [2]: a = list(range(100))
In [3]: sys.getsizeof(a)
Out[3]: 1008
In [4]: b = [i for i in range(100)]
In [5]: sys.getsizeof(b)
Out[5]: 912
In [6]: type(a) == type(b)
Out[6]: True
In [7]: a == b
Out[7]: True
In [8]: sys.getsizeof(list(b))
Out[8]: 1008
</code></pre>

<p>From the <a href=""https://docs.python.org/3.5/library/stdtypes.html#list"">docs</a>:</p>

<blockquote>
  <p>Lists may be constructed in several ways:</p>
  
  <ul>
  <li>Using a pair of square brackets to denote the empty list: <code>[]</code></li>
  <li>Using square brackets, separating items with commas: <code>[a]</code>, <code>[a, b, c]</code></li>
  <li>Using a list comprehension: <code>[x for x in iterable]</code></li>
  <li>Using the type constructor: <code>list()</code> or <code>list(iterable)</code></li>
  </ul>
</blockquote>

<p>But it seems that using <code>list()</code> it uses more memory.</p>

<p>And as much <code>list</code> is bigger, the gap increases.</p>

<p><a href=""https://i.stack.imgur.com/VVHJL.png""><img src=""https://i.stack.imgur.com/VVHJL.png"" alt=""Difference in memory""></a></p>

<p>Why this happens?</p>

<p><strong>UPDATE #1</strong></p>

<p>Test with Python 3.6.0b2:</p>

<pre><code>Python 3.6.0b2 (default, Oct 11 2016, 11:52:53) 
[GCC 5.4.0 20160609] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.getsizeof(list(range(100)))
1008
&gt;&gt;&gt; sys.getsizeof([i for i in range(100)])
912
</code></pre>

<p><strong>UPDATE #2</strong></p>

<p>Test with Python 2.7.12:</p>

<pre><code>Python 2.7.12 (default, Jul  1 2016, 15:12:24) 
[GCC 5.4.0 20160609] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.getsizeof(list(xrange(100)))
1016
&gt;&gt;&gt; sys.getsizeof([i for i in xrange(100)])
920
</code></pre>
",list() uses slightly more memory than list comprehension,0.02367223
18086292,3382,80,"<p>I'm reading <em><a href=""https://rads.stackoverflow.com/amzn/click/com/0321563840"" rel=""noreferrer"" rel=""nofollow noreferrer"">The C++ Programming Language, 4th Edition</a></em> (by <a href=""http://en.wikipedia.org/wiki/Bjarne_Stroustrup"" rel=""noreferrer"">Bjarne Stroustrup</a>) about <a href=""/questions/tagged/argument-dependent-lookup"" class=""post-tag"" title=""show questions tagged &#39;argument-dependent-lookup&#39;"" rel=""tag"">argument-dependent-lookup</a>. Here is the quote (26.3.6, Overaggressive ADL):</p>

<blockquote>
  <p>Argument-dependent lookup (often referred to as ADL) is very useful to avoid verbosity (14.2.4). For example:</p>

<pre><code>#include &lt;iostream&gt;

int main()
{
    std::cout &lt;&lt; ""Hello, world"" &lt;&lt; endl; // OK because of ADL
}
</code></pre>
  
  <p>Without argument-dependent lookup, the <code>endl</code> manipulator would not be found. As it is, the compiler notices that the first argument to <code>&lt;&lt;</code> is an <code>ostream</code> defined in <code>std</code>. Therefore, it looks for <code>endl</code> in <code>std</code> and finds it (in <code>&lt;iostream&gt;</code>).</p>
</blockquote>

<p>And here's the <a href=""http://ideone.com/jyiZbs"" rel=""noreferrer"">result</a> produced by the compiler (C++11 mode):</p>

<pre><code>prog.cpp: In function ‘int main()’:
prog.cpp:4:36: error: ‘endl’ was not declared in this scope
 std::cout &lt;&lt; ""Hello, world"" &lt;&lt; endl;
                                ^
</code></pre>

<p>Either this is a bug in the compiler or in the book. What does the standard say?  </p>

<p><strong>Update:</strong></p>

<p>I need to clarify a bit. I know that the right answer is to use <code>std::endl</code>. The question was about the text in the book. As <strong>Lachlan Easton</strong> already said, it is not just a typo. The whole paragraph is (probably) wrong. I can accept this kind of error if the book is by an other (lesser known) author, but I was (and still am) in doubt because it was written by Bjarne.</p>
","Is Bjarne wrong about this example of ADL, or do I have a compiler bug?",0.02365464
16561122,4363,103,"<p>I've got a performance critical binary decision tree, and I'd like to focus this question on a single line of code. The code for the binary tree iterator is below with the results from running performance analysis against it.</p>

<pre><code>        public ScTreeNode GetNodeForState(int rootIndex, float[] inputs)
        {
0.2%        ScTreeNode node = RootNodes[rootIndex].TreeNode;

24.6%       while (node.BranchData != null)
            {
0.2%            BranchNodeData b = node.BranchData;
0.5%            node = b.Child2;
12.8%           if (inputs[b.SplitInputIndex] &lt;= b.SplitValue)
0.8%                node = b.Child1;
            }

0.4%        return node;
        }
</code></pre>

<p><strong>BranchData is a field, not a property.</strong> I did this to prevent the risk of it not being inlined.</p>

<p>The BranchNodeData class is as follows:</p>

<pre><code>public sealed class BranchNodeData
{
    /// &lt;summary&gt;
    /// The index of the data item in the input array on which we need to split
    /// &lt;/summary&gt;
    internal int SplitInputIndex = 0;

    /// &lt;summary&gt;
    /// The value that we should split on
    /// &lt;/summary&gt;
    internal float SplitValue = 0;

    /// &lt;summary&gt;
    /// The nodes children
    /// &lt;/summary&gt;
    internal ScTreeNode Child1;
    internal ScTreeNode Child2;
}
</code></pre>

<p>As you can see, the while loop / null check is a massive hit on performance. The tree is massive, so I would expect searching for a leaf to take a while, but I'd like to understand the disproportionate amount of time spent on that one line.</p>

<p>I've tried:</p>

<ul>
<li>Separating the Null check from the while - it's the Null check that's the hit.</li>
<li>Adding a boolean field to the object and checking against that, it made no difference. It doesn't matter what's being compared, it's the comparison that's the issue.</li>
</ul>

<p>Is this a branch prediction issue? If so, what can I do about it? If anything?</p>

<p>I won't pretend to understand the <a href=""http://en.wikipedia.org/wiki/Common_Intermediate_Language"" rel=""noreferrer"">CIL</a>, but I'll post it for anyone does so they can try to scrape some information from it.</p>

<pre><code>.method public hidebysig
instance class OptimalTreeSearch.ScTreeNode GetNodeForState (
    int32 rootIndex,
    float32[] inputs
) cil managed
{
    // Method begins at RVA 0x2dc8
    // Code size 67 (0x43)
    .maxstack 2
    .locals init (
        [0] class OptimalTreeSearch.ScTreeNode node,
        [1] class OptimalTreeSearch.BranchNodeData b
    )

    IL_0000: ldarg.0
    IL_0001: ldfld class [mscorlib]System.Collections.Generic.List`1&lt;class OptimalTreeSearch.ScRootNode&gt; OptimalTreeSearch.ScSearchTree::RootNodes
    IL_0006: ldarg.1
    IL_0007: callvirt instance !0 class [mscorlib]System.Collections.Generic.List`1&lt;class OptimalTreeSearch.ScRootNode&gt;::get_Item(int32)
    IL_000c: ldfld class OptimalTreeSearch.ScTreeNode OptimalTreeSearch.ScRootNode::TreeNode
    IL_0011: stloc.0
    IL_0012: br.s IL_0039
    // loop start (head: IL_0039)
        IL_0014: ldloc.0
        IL_0015: ldfld class OptimalTreeSearch.BranchNodeData OptimalTreeSearch.ScTreeNode::BranchData
        IL_001a: stloc.1
        IL_001b: ldloc.1
        IL_001c: ldfld class OptimalTreeSearch.ScTreeNode OptimalTreeSearch.BranchNodeData::Child2
        IL_0021: stloc.0
        IL_0022: ldarg.2
        IL_0023: ldloc.1
        IL_0024: ldfld int32 OptimalTreeSearch.BranchNodeData::SplitInputIndex
        IL_0029: ldelem.r4
        IL_002a: ldloc.1
        IL_002b: ldfld float32 OptimalTreeSearch.BranchNodeData::SplitValue
        IL_0030: bgt.un.s IL_0039

        IL_0032: ldloc.1
        IL_0033: ldfld class OptimalTreeSearch.ScTreeNode OptimalTreeSearch.BranchNodeData::Child1
        IL_0038: stloc.0

        IL_0039: ldloc.0
        IL_003a: ldfld class OptimalTreeSearch.BranchNodeData OptimalTreeSearch.ScTreeNode::BranchData
        IL_003f: brtrue.s IL_0014
    // end loop

    IL_0041: ldloc.0
    IL_0042: ret
} // end of method ScSearchTree::GetNodeForState
</code></pre>

<p><strong>Edit:</strong> I decided to do a branch prediction test, I added an identical if within the while, so we have</p>

<pre><code>while (node.BranchData != null)
</code></pre>

<p>and</p>

<pre><code>if (node.BranchData != null)
</code></pre>

<p>inside that. I then ran performance analysis against that, and it took six times longer to execute the first comparison as it did to execute the second comparison that always returned true. So it looks like it is indeed a branch prediction issue - and I'm guessing there's nothing I can do about it?!</p>

<p><strong>Another Edit</strong></p>

<p>The above result would also occur if node.BranchData had to be loaded from the RAM for the while check - it would then be cached for the if statement.</p>

<hr/>

<p>This is my third question on a similar topic. This time I'm focusing on a single line of code.
My other questions on this subject are:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/16539564/could-i-use-a-faster-data-structure-than-a-tree-for-this"">Could I use a faster data structure than a tree for this?</a></li>
<li><a href=""https://stackoverflow.com/questions/16416084/micro-optimisations-iterating-through-a-tree-in-c-sharp"">Micro optimisations iterating through a tree in C#</a></li>
</ul>
",Why does my application spend 24% of its life doing a null check?,0.02360761
27089196,3135,74,"<p>From page 291 of OCP Java SE 6 Programmer Practice Exams, question 25:</p>

<pre><code>public class Stone implements Runnable {
    static int id = 1;

    public void run() {
        id = 1 - id;
        if (id == 0) 
            pick(); 
        else 
            release();
    }

    private static synchronized void pick() {
        System.out.print(""P "");
        System.out.print(""Q "");
    }

    private synchronized void release() {
        System.out.print(""R "");
        System.out.print(""S "");
    }

    public static void main(String[] args) {
        Stone st = new Stone();
        new Thread(st).start();
        new Thread(st).start();
    }
}
</code></pre>

<p>One of the answers is:</p>

<blockquote>
  <p>The output could be <code>P Q P Q</code></p>
</blockquote>

<p>I marked this answer as correct. My reasoning:</p>

<ol>
<li>We are starting two threads. </li>
<li>First one enters <code>run()</code>.</li>
<li>According to <a href=""https://docs.oracle.com/javase/specs/jls/se8/html/jls-15.html#jls-15.26.1"">JLS 15.26.1</a>, it firstly evaluates <code>1 - id</code>. Result is <code>0</code>. It is stored on the thread's stack. We are just about to save that <code>0</code> to static <code>id</code>, but...</li>
<li>Boom, scheduler chooses the second thread to run.</li>
<li>So, the second thread enters <code>run()</code>. Static <code>id</code> is still <code>1</code>, so he executes method <code>pick()</code>. <code>P Q</code> is printed.</li>
<li>Scheduler chooses first thread to run. It takes <code>0</code> from its stack and saves to static <code>id</code>. So, the first thread also executes <code>pick()</code> and prints <code>P Q</code>.</li>
</ol>

<p>However, in the book it's written that this answer is incorrect:</p>

<blockquote>
  <p>It is incorrect because the line <code>id = 1 - id</code> swaps the value of <code>id</code> between <code>0</code> and <code>1</code>. There is no chance for the same method to be executed twice.</p>
</blockquote>

<p>I don't agree. I think there is some chance for the scenario I presented above. Such swap is not atomic. Am I wrong?</p>
",Is id = 1 - id atomic?,0.02360447
4822410,6573,155,"<p>I am writing a <code>JACC</code> provider.</p>

<p>Along the way, this means implementing a <a href=""http://download.oracle.com/javaee/6/api/javax/security/jacc/PolicyConfiguration.html"" rel=""noreferrer""><code>PolicyConfiguration</code></a>.</p>

<p>The <code>PolicyConfiguration</code> is responsible for accepting configuration information from the application server, such as which permissions accrue to which roles.  This is so that a <a href=""http://download.oracle.com/javase/6/docs/api/java/security/Policy.html"" rel=""noreferrer""><code>Policy</code></a> later on can make authorization decisions when handed <a href=""http://download.oracle.com/javase/6/docs/api/java/security/ProtectionDomain.html"" rel=""noreferrer"">information about the current user</a> and what he's trying to do.</p>

<p>However, it is not part of the <code>PolicyConfiguration</code>'s (atrocious) contract to maintain a mapping between roles and their permissions, and <code>Principals</code> that are assigned to those roles.</p>

<p>Typically--always, really--an application server houses this mapping.  For example, on Glassfish, you affect this mapping by supplying things like <code>sun-web.xml</code> and <code>sun-ejb-jar.xml</code> and so on with your Java EE modules.  (These vendor-specific files are responsible for saying, e.g., <code>superusers</code> is a group that is to be assigned the application role of <code>admins</code>.)</p>

<p>I would like to reuse the functionality these files supply, and I would like to do so for as wide an array of application servers as possible.</p>

<p>Here is--totally arbitrarily--IBM's take on the matter, which appears to confirm my suspicion that what <a href=""http://publib.boulder.ibm.com/infocenter/wasinfo/v6r0/index.jsp?topic=/com.ibm.websphere.express.doc/info/exp/ae/csec_jaccextensions.html"" rel=""noreferrer"">I want to do is essentially impossible</a>. (More ammunition for my case that this particular Java EE contract is not worth the paper it's printed on.)</p>

<p><strong>My question:</strong> how do I get at this principal-to-role-mapping information in--for starters--Glassfish and JBoss from within a <code>PolicyConfiguration</code>?  If there's a standard way to do it that I'm unaware of, I'm all ears.</p>
",How can a JACC provider use the Principal-to-role mapping facilities of the server it's deployed on?,0.02358132
38775392,3014,71,"<p>While trying to implement a C11 parser (for educational purposes), I found that in <a href=""http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf"" rel=""noreferrer"">C11 (p. 470)</a> but also in <a href=""http://cs.nyu.edu/courses/Spring13/CSCI-GA.2110-001/downloads/C99.pdf"" rel=""noreferrer"">C99 (p. 412)</a> (thanks Johannes!), the <em>direct declarator</em> is defined as:</p>

<pre><code>(6.7.6) direct-declarator:  
    direct-declarator [ type-qualifier-list? * ]
</code></pre>

<p>At first, I thought this was an error in the grammar (the type list shouldn't be optional). However, when I tried this out in my reference compiler (clang), I got an rather unexpected error:</p>

<pre><code>int array[*] = { 1, 2, 3 };
// error: star modifier used outside of function prototype
</code></pre>

<p>So apparently, (in clang) this is called the <em>star modifier</em>.</p>

<p>I quickly learned that they can only be used in function signatures:</p>

<pre><code>void foobar(int array[*])
</code></pre>

<p>However, they can only be used in the declaration. Trying to use it in a function definition results in an error as well:</p>

<pre><code>void foobar(int array[*]) {
    // variable length array must be bound in function definition
}
</code></pre>

<hr>

<p>So as far as I can tell, the intended behaviour is to use <code>[*]</code> in the function declaration and then use a fixed number in the function definition.</p>

<pre><code>// public header
void foobar(int array[*]);

// private implementation
void foobar(int array[5]) {

}
</code></pre>

<hr>

<p>However, I have never seen it and I don't quite understand the purpose of it either.</p>

<ol>
<li>What is its purpose, why was it added?</li>
<li>What's the difference with <code>int[]</code>?</li>
<li>What's the difference with <code>int *</code>?</li>
</ol>
","What does ""[*]"" (star modifier) mean in C?",0.02355674
44532077,3833,90,"<p>Given the following code:</p>

<pre><code>string someString = null;
switch (someString)
{
    case string s:
        Console.WriteLine(""string s"");
        break;
    case var o:
        Console.WriteLine(""var o"");
        break;
    default:
        Console.WriteLine(""default"");
        break;
}
</code></pre>

<p>Why is the switch statement matching on <code>case var o</code>?</p>

<p>It is my understanding that <code>case string s</code> does not match when <code>s == null</code> because (effectively) <code>(null as string) != null</code> evaluates to false. IntelliSense on VS Code tells me that <code>o</code> is a <code>string</code> as well. Any thoughts?</p>

<hr>

<p>Similiar to: <a href=""https://stackoverflow.com/questions/42950833/c-sharp-7-switch-case-with-null-checks"">C# 7 switch case with null checks</a></p>
",switch with var/null strange behavior,0.0234803
8792440,3238,76,"<p>The following code checks if <code>x</code> and <code>y</code> are distinct values (the variables <code>x</code>, <code>y</code>, <code>z</code> can only have values <code>a</code>, <code>b</code>, or <code>c</code>) and if so, sets <code>z</code> to the third character:</p>

<pre><code>if x == 'a' and y == 'b' or x == 'b' and y == 'a':
    z = 'c'
elif x == 'b' and y == 'c' or x == 'c' and y == 'b':
    z = 'a'
elif x == 'a' and y == 'c' or x == 'c' and y == 'a':
    z = 'b'
</code></pre>

<p>Is is possible to do this in a more, concise, readable and efficient way?</p>
",How can I find the missing value more concisely?,0.02347128
33800783,3549,83,"<p>Currently, I am reading the source code of <code>Protocol Buffer</code>, and I found one weird <code>enum</code> codes defined <a href=""https://github.com/google/protobuf/blob/master/src/google/protobuf/stubs/scoped_ptr.h#L72-L75"" rel=""noreferrer"">here</a></p>

<pre><code>  ~scoped_ptr() {
    enum { type_must_be_complete = sizeof(C) };
    delete ptr_;
  }

  void reset(C* p = NULL) {
    if (p != ptr_) {
      enum { type_must_be_complete = sizeof(C) };
      delete ptr_;
      ptr_ = p;
    }
  }
</code></pre>

<p>Why the <code>enum { type_must_be_complete = sizeof(C) };</code> is defined here? what is it used for?</p>
",Weird enum in destructor,0.02338687
5863128,3934,92,"<p>I have twice recently refactored code in order to change the order of parameters because there was too much code where hacks like <code>flip</code> or <code>\x -&gt; foo bar x 42</code> were happening.</p>

<p>When designing a function signature what principles will help me to make the best use of currying? </p>
",Ordering of parameters to make use of currying,0.02338587
13305020,4111,96,"<p>When a user makes some changes (cropping, red-eye removal, ...) to photos in the built-in <strong>Photos.app</strong> on iOS, the changes are not applied to the <code>fullResolutionImage</code> returned by the corresponding <code>ALAssetRepresentation</code>. </p>

<p>However, the changes are applied to the <code>thumbnail</code> and the <code>fullScreenImage</code> returned by the <code>ALAssetRepresentation</code>.
Furthermore, information about the applied changes can be found in the <code>ALAssetRepresentation</code>'s   metadata dictionary via the key <code>@""AdjustmentXMP""</code>.</p>

<p>I would like to apply these changes to the <code>fullResolutionImage</code> myself to preserve consistency. I've found out that on <strong>iOS6+</strong> <code>CIFilter</code>'s <code>filterArrayFromSerializedXMP:                              inputImageExtent:error:</code> can convert this XMP-metadata to an array of <code>CIFilter</code>'s:</p>

<pre><code>ALAssetRepresentation *rep; 
NSString *xmpString = rep.metadata[@""AdjustmentXMP""];
NSData *xmpData = [xmpString dataUsingEncoding:NSUTF8StringEncoding];

CIImage *image = [CIImage imageWithCGImage:rep.fullResolutionImage];

NSError *error = nil;
NSArray *filterArray = [CIFilter filterArrayFromSerializedXMP:xmpData 
                                             inputImageExtent:image.extent 
                                                        error:&amp;error];
if (error) {
     NSLog(@""Error during CIFilter creation: %@"", [error localizedDescription]);
}

CIContext *context = [CIContext contextWithOptions:nil];

for (CIFilter *filter in filterArray) {
     [filter setValue:image forKey:kCIInputImageKey];
     image = [filter outputImage];
}
</code></pre>

<p>However, this works only for some filters (cropping, auto-enhance) but not for others like red-eye removal. In these cases, the <code>CIFilter</code>s have no visible effect. Therefore, my questions:</p>

<ul>
<li>Is anyone aware of a way to create red-eye removal <code>CIFilter</code>? (In a way consistent with the Photos.app. The filter with the key <code>kCIImageAutoAdjustRedEye</code> is not enough. E.g., it does not take parameters for the position of the eyes.)</li>
<li>Is there a possibility to generate and apply these filters under iOS 5? </li>
</ul>
",Interpret XMP-Metadata in ALAssetRepresentation,0.02335198
4987415,5654,132,"<p>I recently had to type in a small C test program and, in the process, I made a spelling mistake in the main function by accidentally using <code>vooid</code> instead of <code>void</code>.</p>

<p>And yet it still worked.</p>

<p>Reducing it down to its smallest complete version, I ended up with:</p>

<pre><code>int main (vooid) {
    return 42;
}
</code></pre>

<p>This does <em>indeed</em> compile (<code>gcc -Wall -o myprog myprog.c</code>) and, when run, it returns 42.</p>

<p>How exactly is this valid code?</p>

<hr>

<p>Here's a transcript cut and pasted from my <code>bash</code> shell to show what I'm doing:</p>

<pre><code>pax$ cat qq.c
int main (vooid) {
    return 42;
}

pax$ rm qq ; gcc -Wall -o qq qq.c ; ./qq

pax$ echo $?
42
</code></pre>
","""int main (vooid)""? How does that work?",0.0233463
5186542,4593,107,"<p>First off, the barest bones of the project I wish to create is a wiki engine implemented as a single page web app. I plan on having a set of features available from the  get-go with plenty of feature additions down the road.</p>

<p><strong>Basic Features</strong></p>

<ul>
<li>page creation (creates both wiki article and discussion forum for that article)</li>
<li>markup and WYSIWYG ala <a href=""http://markitup.jaysalvat.com/examples/markdown/"">markitup</a></li>
<li>on-the-fly conversion between markup / html / WYSIWYG</li>
<li>a side bar to quick navigate</li>
<li>a top toolbar for choosing edit/view</li>
</ul>

<p><strong>Advanced Features</strong></p>

<ul>
<li>configurable side bar to navigate via different method</li>
<li>configurable toolbar (possibly add markup language of choice)</li>
<li>tags</li>
<li>editable todo's</li>
<li>drag and drop file uploads and image attachments</li>
</ul>

<p>The engine would originally consist of the most basic page creation, markup and WYSIWYG editing, and saving. I would eventually like to extend this basic engine with drag and drop image support, file uploads, live data graphs, and a sidebar for customizing views.</p>

<p>I have done a fairly extensive search for a decent project from which to base my project off, but other than TiddlyWiki there does not seem to be any good javascript based wiki engines. I also considered applying Jquery on top of existing wiki engines but I believe I would end up rewriting it eventually anyway (Plus its just more exciting to add the features I want as I go). Either way I have arrived at implementing this beast with a javascript library + framework. </p>

<p>I know that one cannot really compare some of these frameworks against each other as they are very much not apples to apples. I have tried to frame any comparison comments/questions against comparable pieces of the respective frameworks but I am open to being corrected.</p>

<p>So here we go:</p>

<p>Based on my own research and opinions I have narrowed the list down to the items below. I intentionally left out things such as SproutCore, corMVC, YUI, and others as I, in my limited capacity, thought the below items would be a better fit.</p>

<p><strong>My Options</strong></p>

<ul>
<li><a href=""http://jquery.com/"">jquery</a> + <a href=""http://jqueryui.com/"">jqueryUI</a> + <a href=""http://documentcloud.github.com/backbone/"">backbonejs</a></li>
<li><a href=""http://knockoutjs.com/"">knockoutjs</a></li>
<li><a href=""http://www.javascriptmvc.com/"">javascriptMVC</a></li>
<li><a href=""http://dojotoolkit.org/"">Dojo</a></li>
<li><a href=""http://www.sencha.com/"">ExtJS</a></li>
<li><a href=""http://cappuccino.org/"">Cappuccino</a></li>
</ul>

<hr>

<h2>jquery/UI + backbonejs</h2>

<p><em>Overall</em></p>

<blockquote>
  <p>From what I've read this combination is used and beloved by many and is very flexible and extensible. My major concern is that this combination is simply not the best jumping off point for developing the more desktop oriented UI interface. </p>
</blockquote>

<p><em>UI</em></p>

<blockquote>
  <p>While jQueryUI or jqueryTools might be competitive they certainly do not seem to be on-par with the UI capabilities of other frameworks. Specifically they seem to be heavy on the effects but lacking on decent layout slicing support.</p>
</blockquote>

<h2>javascriptMVC</h2>

<p><em>Overall</em></p>

<blockquote>
  <p>JavascriptMVC to me looks like it is essentially jquery + MVC(jqueryMX) extensions, along with a few other apps for documenting(documentJS), functional tests(funcUnit), and code and dependency management(stealJS). Beyond the benefits of the additional module, I think the functional debate really comes down to backbonejs vs. jqueryMX Am I correct on this and has anyone worked with or compared both?</p>
  
  <blockquote>
    <ul>
    <li>Features: jupiter's (maker of jMVC) overview of their <a href=""http://jupiterit.com/news/javascriptmvc-features"">features</a></li>
    <li>Link to <a href=""https://github.com/jupiterjs/jquerymx"">jqueryMX</a></li>
    </ul>
  </blockquote>
</blockquote>

<p><em>UI</em></p>

<blockquote>
  <p>JavascriptMVC adds the <a href=""https://github.com/jupiterjs/mxui"">MXUI</a> items on top of whatever is available for Jquery so I think at the very least it is a slight win in that category. </p>
</blockquote>

<h2>knockoutjs</h2>

<p><em>Overall</em></p>

<blockquote>
  <p>My thoughts and concerns on this on this are very similar to the jquery + backbone comments. They both seem to offer similar features but just from a different perspective. An oft cited downside is that knockoutjs couples business logic and presentation too tightly with the data-bind's and that this binding method can break down for complex UI interaction but I would love to hear why that is a non-issue.</p>
  
  <blockquote>
    <ul>
    <li><a href=""http://news.ycombinator.com/item?id=1810665"">Discussion</a> of backbone vs knockoutJS concepts</li>
    <li><a href=""http://blog.stevensanderson.com/2010/07/05/introducing-knockout-a-ui-library-for-javascript/"">Features</a> of knockoutjs</li>
    </ul>
  </blockquote>
</blockquote>

<p><em>UI</em></p>

<p>Blank at the moment</p>

<h2>Dojo &amp; ExtJS</h2>

<p><em>Overall</em></p>

<blockquote>
  <p>I am going to combine the discussion Dojo and ExtJS because I know the least about them and they seem to play in nearly the same space. Most of the information on stackoverflow about these two seems to be out-of-date. From what I have seen is that they are both large frameworks that are good for desktop caliber app implementation. Dojo had been chided for poor documentation but that seems to be no longer the case. ExtJS of course has the commercial license, but it is really reasonable for what you get and I wouldn't hold that against it too much. The widgets in ExtJS seem to be somewhat more professionally done than Dojo, but I could certainly be corrected there. I would be interested to hear from anyone who has experience in both.</p>
</blockquote>

<p><em>UI</em></p>

<blockquote>
  <p>Dojo has the <a href=""http://dojotoolkit.org/reference-guide/dijit/index.html"">dijit</a> UI library 
  ExtJS has UI features but they are not in Ext core. Here's the <a href=""http://dev.sencha.com/deploy/dev/docs/"">documentation</a> and here are their <a href=""http://www.sencha.com/products/extjs/examples/"">demos</a></p>
</blockquote>

<h2>Cappuccino</h2>

<p><em>Overall</em></p>

<blockquote>
  <p>And then there is Cappuccino. No CSS, no html, but also it could be tough to use existing javascript libraries. Objective-J doesn't seem to scary, especially considering that they tout being able to write plain javascript as well. The demos are impressive and seem to closely approach the UI needs for the wiki engine. The cocoa based API is a lot to take in for someone not familiar with it, but maybe it is worth it. I have heard the layout engine is not always easy to work with but a young and possibly disruptive tech like this will certainly have some shortcomings.</p>
</blockquote>

<p><em>UI</em></p>

<blockquote>
  <p>Blank at the moment</p>
</blockquote>

<p>I apologize for writing so much but hey, at least its not a x vs y vs z question hoping for tons of cheap answers. So what do you think? What should be the basis for my desktop like wiki engine, that will hopefully become more feature rich (read complex) over time?</p>
",Where am I wrong about my project and these Javascript Frameworks?,0.02329632
26989374,4637,108,"<p>I am investigating potential code-completion speedups while using clang's code-completion mechanism. The flow described below is what I found in <a href=""https://github.com/Andersbakken/rtags"" rel=""noreferrer"">rtags</a>, by Anders Bakken.</p>

<p>Translation units are parsed by a daemon monitoring files for changes. This is done by called <code>clang_parseTranslationUnit</code> and related functions(<code>reparse*</code>, <code>dispose*</code>). When the user requests a completion at a given line and column in a source file, the daemon passes the cached translation unit for the last saved version of the source file and the current source file to <code>clang_codeCompleteAt</code>. (<a href=""http://clang.llvm.org/doxygen/group__CINDEX__CODE__COMPLET.html"" rel=""noreferrer"">Clang CodeComplete docs</a>).</p>

<p>The flags passed to <code>clang_parseTranslationUnit</code>(from <a href=""https://github.com/Andersbakken/rtags/blob/master/src/CompletionThread.cpp"" rel=""noreferrer"">CompletionThread::process, line 271</a>) are <code>CXTranslationUnit_PrecompiledPreamble|CXTranslationUnit_CacheCompletionResults|CXTranslationUnit_SkipFunctionBodes</code>. The flags passed to <code>clang_codeCompleteAt</code>(from <a href=""https://github.com/Andersbakken/rtags/blob/master/src/CompletionThread.cpp"" rel=""noreferrer"">CompletionThread::process, line 305</a>) are <code>CXCodeComplete_IncludeMacros|CXCodeComplete_IncludeCodePatterns</code>.</p>

<p>The call to <code>clang_codeCompleteAt</code> is very slow - it takes around 3-5 seconds to obtain a completion even in the cases where the completion location is a legitimate member access code, a subset of the intended use case mentioned in the documentation of <a href=""http://clang.llvm.org/doxygen/group__CINDEX__CODE__COMPLET.html#ga50fedfa85d8d1517363952f2e10aa3bf"" rel=""noreferrer""><code>clang_codeCompleteAt</code></a>. This seems way too slow by IDE code-completion standards. Is there a way of speeding this up?</p>
",Faster code-completion with clang,0.02329092
28088958,3908,91,"<p>I have a requirement to plot <strong>run  history</strong> of a <strong>task</strong> in Highcharts.  It needs to show that run history of the tasks as a horizontal bar.  There are additional requirements which I've added as an update below. Recently I found out that <code>inverted</code> option is not supported in <a href=""http://api.highcharts.com/highstock#chart"" rel=""nofollow noreferrer"">StockChart</a> and that only <a href=""http://api.highcharts.com/highstock#navigator"" rel=""nofollow noreferrer"">navigator</a> &amp; <a href=""http://api.highcharts.com/highstock#rangeSelector"" rel=""nofollow noreferrer"">rangeSelector</a> are available in StockChart.  Therefore I am using those functions.</p>

<p>So in order to achieve the requirement I created something similar to <a href=""http://jsfiddle.net/abhisheksimion/bx2000cb/2/"" rel=""nofollow noreferrer"">this jsfiddle example</a> (found somewhere while browsing don't remember the source) and ended up with <a href=""http://embed.plnkr.co/lK9921/preview"" rel=""nofollow noreferrer"">this plunker link</a> with help from my previous <a href=""https://stackoverflow.com/questions/27983248/need-help-in-plotting-a-chart-using-highcharts-in-angularjs"">question</a>, thanks to <a href=""https://stackoverflow.com/users/1451635/pawe%C5%82-fus"">Pawel Fus</a></p>

<p><strong>Updating question to avoid confusion</strong></p>

<p>Additional requirements:</p>

<p>Show <strong>only those tasks</strong> which <strong>ran</strong> in a particular <strong>date and time range</strong>. In case there are too many runs, such as more than 10 run, then there needs to be a way to display only 10 tasks visibly with a y-axis that is scrollable to show other tasks.
<a href=""http://plnkr.co/edit/7GRgqk?p=preview"" rel=""nofollow noreferrer"">plunker link to the problem</a></p>

<p>Problem explanation of above plunker.</p>

<p>If you check the screenshot below from above plunker, the time range is from <code>12/12/2014 09:32:26</code> to <code>12/12/2014 10:32:26</code> and there are only 2 tasks that has run <code>m_ARRAYV_SALES_ZIG1_CALL2_VOD__C_OB</code> &amp; <code>m_ZIG2_HCP_MERGE_IB_CN</code>. However I can see another task in between <code>LILLY_C</code> which did not even ran in this date time range. (In actual data there are more than 10 tasks that clutters this chart which does not even fall under this date time range)</p>

<p>Also if you notice at the bottom most right corner time shifted from <code>09:38</code> to <code>19:20</code>. <code>19:20</code> is the end time for <code>m_ZIG2_HCP_MERGE_IB_CN</code> task.
<img src=""https://i.stack.imgur.com/hRMsK.png"" alt=""enter image description here"">
Below is my chart options</p>

<pre><code>    var chart_options = {
            chart: {
                renderTo: 'container',
                height: 600
            },
            title: {
            },
            credits: {
                enabled: false
            },
            xAxis: {
                type: 'datetime',
                gridLineWidth: 1,
                tickInterval: 1 * 3600 * 1000,
                dateTimeLabelFormats: {
                    month: '%b %e, %Y'
                }
            },
            yAxis: {                    
                tickInterval: 1,
                gridLineWidth: 1,
                labels: {
                    formatter: function() {
                        if (tasks[this.value]) {
                            return tasks[this.value].name;
                        }
                    }
                },
                startOnTick: false,
                endOnTick: false,
                title: {
                    text: 'Task'
                }
            },
            rangeSelector: {
                selected: 0,
                buttons: [ {
                    type: ""minute"",
                    count: 60,
                    text: ""1h""
                }, {
                    type: ""minute"",
                    count: 180,
                    text: ""3h""
                }, {
                    type: ""minute"",
                    count: 300,
                    text: ""5h""
                }],
                inputDateFormat: '%m/%d/%Y %H:%M:%S',
                inputEditDateFormat: '%m/%d/%Y %H:%M:%S',
                inputBoxWidth: 120
            },
            navigator: {
                enabled: false
            },
            legend: {
                enabled: false
            },
            tooltip: {
                shared: false,
                formatter: function() {
                    var str = '';
                    str += 'Task: ' + this.series.name + '&lt;br&gt;';
                    str += 'From: ' + Highcharts.dateFormat('%m/%d/%y %H:%M', this.point.from) + '&lt;br&gt;';
                    str += 'To: ' + Highcharts.dateFormat('%m/%d/%y %H:%M', this.point.to) + '&lt;br&gt;';
                    return str;
                }
            },
            plotOptions: {
                line: {
                    lineWidth: 10,
                    marker: {
                        enabled: true
                    },
                    dataLabels: {
                        enabled: true,
                        align: 'left',
                        formatter: function() {
                            return this.point.options &amp;&amp; this.point.options.label;
                        }
                    },
                    states:{
                        hover:{
                            lineWidth:10
                        }
                    }
                },
                series: {
                    cursor: 'pointer',
                    point: {
                        events: {
                            click: function () {
                                var query = '{ ""task_id"": ""'+this.task_id+'"",""start_time"": '+this.from+',""exclude_interval"": '+opExcludeMinutes+',""size"": 10 }';
                                $scope.taskName = this.series.name;
                                $scope.isTaskSelected = false;
                                $scope.operationalReportAgentTaskHistoryServiceRequest(query);
                            }
                        }
                    }
                }
            },
            series: seriesData
        };
</code></pre>
",How to create a column range chart in Highcharts using range and navigator functions?,0.02328557
29563832,3616,84,"<p>I just wrote some testing python code into <code>test.py</code>, and I'm launching it as follows:</p>

<pre><code>perl test.py
</code></pre>

<p>After a while I realized my mistake. I say ""after a while"", because the
Python code gets actually correctly executed, as if in Python interpreter!</p>

<p>Why is my Perl interpreting my Python? <code>test.py</code> looks like this:</p>

<pre><code>#!/usr/bin/python

...Python code here...
</code></pre>

<p>Interestingly, if I do the opposite (i.e. call <code>python something.pl</code>) I get a good deal of syntax errors.</p>
",Why don't I get any syntax errors when I execute my Python script with Perl?,0.02323009
21656766,3234,75,"<p>I wondered how many times can a JavaScript <code>while</code> statement (in Chrome's console) can increment a variable in a millisecond, so I quickly wrote this snippet directly into console:</p>

<pre><code>var run = true, i = 0;
setTimeout(function(){ run = false; }, 1);
while(run){ i++; }
</code></pre>

<p>The problem is that it runs forever.<br>
Why is this happening, and how can I solve it?</p>
",Why isn't setTimeout cancelling my loop?,0.02319109
10593686,3838,89,"<p>Let's imagine we have a struct for holding 3 doubles with some member functions:</p>

<pre><code>struct Vector {
  double x, y, z;
  // ...
  Vector &amp;negate() {
    x = -x; y = -y; z = -z;
    return *this;
  }
  Vector &amp;normalize() {
     double s = 1./sqrt(x*x+y*y+z*z);
     x *= s; y *= s; z *= s;
     return *this;
  }
  // ...
};
</code></pre>

<p>This is a little contrived for simplicity, but I'm sure you agree that similar code is out there. The methods allow you to conveniently chain, for example:</p>

<pre><code>Vector v = ...;
v.normalize().negate();
</code></pre>

<p>Or even:</p>

<pre><code>Vector v = Vector{1., 2., 3.}.normalize().negate();
</code></pre>

<p>Now if we provided begin() and end() functions, we could use our Vector in a new-style for loop, say to loop over the 3 coordinates x, y, and z (you can no doubt construct more ""useful"" examples by replacing Vector with e.g. String):</p>

<pre><code>Vector v = ...;
for (double x : v) { ... }
</code></pre>

<p>We can even do:</p>

<pre><code>Vector v = ...;
for (double x : v.normalize().negate()) { ... }
</code></pre>

<p>and also:</p>

<pre><code>for (double x : Vector{1., 2., 3.}) { ... }
</code></pre>

<p>However, the following (it seems to me) is broken:</p>

<pre><code>for (double x : Vector{1., 2., 3.}.normalize()) { ... }
</code></pre>

<p>While it seems like a logical combination of the previous two usages, I think this last usage creates a dangling reference while the previous two are completely fine.</p>

<ul>
<li>Is this correct and Widely appreciated?   </li>
<li>Which part of the above is the ""bad"" part, that should be avoided?   </li>
<li>Would the language be improved by changing the definition of the range-based for loop such that temporaries constructed in the for-expression exist for the duration of the loop?</li>
</ul>
",Is this a known pitfall of C++11 for loops?,0.02318916
20550930,9001,208,"<p><a href=""http://jsfiddle.net/goldrunt/jGL84/42/"">http://jsfiddle.net/goldrunt/jGL84/42/</a>
this is from line 84 in this JS fiddle. There are 3 different effects which can be applied to the balls by uncommenting lines 141-146. The 'bounce' effect works as it should, but the 'asplode' effect does nothing. Should I include the 'shrink' function inside the asplode function?</p>

<pre><code>// balls shrink and disappear if they touch
var shrink = function(p) {
    for (var i = 0; i &lt; 100; i++) {
        p.radius -= 1;
    }
    function asplode(p) {
        setInterval(shrink(p),100);
        balls.splice(p, 1);
    }
}
</code></pre>
",Why aren't my ball (objects) shrinking/disappearing?,0.02310854
36794202,4766,110,"<p>In a project, somebody pushed this line:</p>

<pre><code>double (*e)[n+1] = malloc((n+1) * sizeof(*e));
</code></pre>

<p>Which supposedly creates a two-dimensional array of (n+1)*(n+1) doubles.</p>

<p><em>Supposedly</em>, I say, because so far, nobody I asked could tell me what this does, exactly, nor where it originated from or why it should work (which allegedly, it does, but I'm not yet buying it).</p>

<p>Perhaps I'm missing something obvious, but I'd appreciate it if somebody could explain above line to me. Because personally, I'd feel much better if we'd use something we actually understand.</p>
",Freaky way of allocating two-dimensional array?,0.02308015
38143580,6110,141,"<p>A <code>script</code> element that got styled as <code>display:block</code> appears visible. Why is it possible and is there any real use case where it is desired?</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>td &gt; * {
  display: block;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;script type=""text/javascript""&gt;
        var test = 1;
      &lt;/script&gt;von 1
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;</code></pre>
</div>
</div>
</p>
",When should <script> tags be visible and why can they?,0.02307692
51526242,6418,148,"<p>I created two lists <code>l1</code> and <code>l2</code>, but each one with a different creation method:</p>

<pre><code>import sys

l1 = [None] * 10
l2 = [None for _ in range(10)]

print('Size of l1 =', sys.getsizeof(l1))
print('Size of l2 =', sys.getsizeof(l2))
</code></pre>

<p>But the output surprised me:</p>

<pre><code>Size of l1 = 144
Size of l2 = 192
</code></pre>

<p>The list created with a list comprehension is a bigger size in memory, but the two lists are identical in Python otherwise.</p>

<p>Why is that? Is this some CPython internal thing, or some other explanation?</p>
",Why do two identical lists have a different memory footprint?,0.02306014
18636561,3869,89,"<p>Nead clarification for following code:</p>

<pre><code>StringBuilder sample = new StringBuilder();
StringBuilder referToSample = sample;
referToSample.append(""B"");
System.out.println(sample);
</code></pre>

<p>This will print <code>B</code> so that proves <code>sample</code> and <code>referToSample</code> objects refer to the same memory reference.</p>

<pre><code>StringBuilder sample = new StringBuilder();
StringBuilder referToSample = sample;
sample.append(""A"");
referToSample.append(""B"");
System.out.println(referToSample);
</code></pre>

<p>This will print <code>AB</code> that also proves the same.</p>

<pre><code>StringBuilder sample = new StringBuilder();
StringBuilder referToSample = sample;
referToSample = null;
referToSample.append(""A"");
System.out.println(sample);
</code></pre>

<p>Obviously this will throw <code>NullPointerException</code> because I am trying to call <code>append</code> on a null reference.</p>

<pre><code>StringBuilder sample = new StringBuilder();
StringBuilder referToSample = sample;
referToSample = null;
sample.append(""A"");
System.out.println(sample);
</code></pre>

<p>So Here is my question, why is  the last code sample not throwing <code>NullPointerException</code> because what I see and understand from first two examples is if two objects referring to same object then if we change any value then it will also reflect to other because both are pointing to same memory reference. So why is that rule not applying here? If I assign <code>null</code> to referToSample then sample should also be null and it should throw a NullPointerException but it is not throwing one, why?</p>
",Why is this not throwing a NullPointerException?,0.02300336
30100725,12311,283,"<p>When comparing floats to integers, some pairs of values take much longer to be evaluated than other values of a similar magnitude.</p>

<p>For example:</p>

<pre><code>&gt;&gt;&gt; import timeit
&gt;&gt;&gt; timeit.timeit(""562949953420000.7 &lt; 562949953421000"") # run 1 million times
0.5387085462592742
</code></pre>

<p>But if the float or integer is made smaller or larger by a certain amount, the comparison runs much more quickly:</p>

<pre><code>&gt;&gt;&gt; timeit.timeit(""562949953420000.7 &lt; 562949953422000"") # integer increased by 1000
0.1481498428446173
&gt;&gt;&gt; timeit.timeit(""562949953423001.8 &lt; 562949953421000"") # float increased by 3001.1
0.1459577925548956
</code></pre>

<p>Changing the comparison operator (e.g. using <code>==</code> or <code>&gt;</code> instead) does not affect the times in any noticeable way. </p>

<p>This is not <em>solely</em> related to magnitude because picking larger or smaller values can result in faster comparisons, so I suspect it is down to some unfortunate way the bits line up. </p>

<p>Clearly, comparing these values is more than fast enough for most use cases. I am simply curious as to why Python seems to struggle more with some pairs of values than with others.</p>
",Why are some float < integer comparisons four times slower than others?,0.02298757
2969140,4051,93,"<p>I came upon the <a href=""http://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence"" rel=""noreferrer"">Curry-Howard Isomorphism</a> relatively late in my programming life, and perhaps this contributes to my being utterly fascinated by it. It implies that for every programming concept there exists a precise analogue in formal logic, and vice versa. Here's a ""basic"" list of such analogies, off the top of my head:</p>

<pre><code>program/definition        | proof
type/declaration          | proposition
inhabited type            | theorem/lemma
function                  | implication
function argument         | hypothesis/antecedent
function result           | conclusion/consequent
function application      | modus ponens
recursion                 | induction
identity function         | tautology
non-terminating function  | absurdity/contradiction
tuple                     | conjunction (and)
disjoint union            | disjunction (or)          -- corrected by Antal S-Z
parametric polymorphism   | universal quantification
</code></pre>

<p>So, to my question: <strong>what are some of the more interesting/obscure implications of this isomorphism?</strong> I'm no logician so I'm sure I've only scratched the surface with this list.</p>

<p>For example, here are some programming notions for which I'm unaware of pithy names in logic:</p>

<pre><code>currying                  | ""((a &amp; b) =&gt; c) iff (a =&gt; (b =&gt; c))""
scope                     | ""known theory + hypotheses""
</code></pre>

<p>And here are some logical concepts which I haven't quite pinned down in programming terms:</p>

<pre><code>primitive type?           | axiom
set of valid programs?    | theory
</code></pre>

<p>Edit:</p>

<p>Here are some more equivalences collected from the responses:</p>

<pre><code>function composition      | syllogism                -- from Apocalisp
continuation-passing      | double negation          -- from camccann
</code></pre>
",What are the most interesting equivalences arising from the Curry-Howard Isomorphism?,0.02295729
5595418,7319,168,"<p>I recently had a discussion with another developer who claimed to me that JOINs (SQL) are useless. This is technically true but he added that using joins is less efficient than making several requests and link tables in the code (C# or Java). </p>

<p>For him joins are for lazy people that don't care about performance. Is this true? Should we avoid using joins?</p>
",Joins are for lazy people?,0.02295396
55644201,4009,92,"<p>I have the following code:</p>

<pre><code>a = [0,1,2,3]

for a[-1] in a:
  print(a[-1])
</code></pre>

<p>The output is:</p>

<pre><code>0
1
2
2
</code></pre>

<p>I'm confused about why a list index can be used as an indexing variable in a for loop.</p>
",Why can I use a list index as an indexing variable in a for loop?,0.02294837
16994668,6984,160,"<p>Is there is a way to measure how sorted a list is?</p>

<p>I mean, it's not about knowing if a list is sorted or not (boolean), but something like a ratio of ""sortness"", something like the coefficient of correlation in statistics.</p>

<p>For example, </p>

<ul>
<li><p>If the items of a list are in ascending order, then its rate would be 1.0</p></li>
<li><p>If list is sorted descending, its rate would be -1.0</p></li>
<li><p>If list is almost sorted ascending, its rate would be 0.9 or some value close to 1.</p></li>
<li><p>If the list is not sorted at all (random), its rate would be close to 0</p></li>
</ul>

<p>I'm writting a small library in Scala for practice. I think a sorting rate would be useful, but I don't find any information about something like that. Maybe I don't know adequate terms for the concept.</p>
",Is there a way to measure how sorted a list is?,0.02290951
7368262,13199,302,"<p>For documenting classes with roxygen(2), specifying a title and description/details appears to be the same as for functions, methods, data, etc. However, slots and inheritance are their own sort of animal. What is the best practice -- current or planned -- for documenting S4 classes in roxygen2?</p>

<p>Due Diligence:</p>

<p>I found mention of an <code>@slot</code> tag in early descriptions of roxygen. 
<a href=""http://lists.r-forge.r-project.org/pipermail/roxygen-devel/2008-November/000009.html"" rel=""noreferrer"">A 2008 R-forge mailing list post</a> 
seems to indicate that this is dead, 
and there is no support for <code>@slot</code> in roxygen:</p>

<p>Is this true of roxygen2? The previously-mentioned post suggests a user should instead make their own itemized list with LaTeX markup. E.g. a new S4 class that extends the <code>""character""</code> class would be coded and documented like this:</p>

<pre><code>#' The title for my S4 class that extends \code{""character""} class.
#'
#' Some details about this class and my plans for it in the body.
#'
#' \describe{
#'    \item{myslot1}{A logical keeping track of something.}
#'
#'    \item{myslot2}{An integer specifying something else.}
#' 
#'    \item{myslot3}{A data.frame holding some data.}
#'  }
#' @name mynewclass-class
#' @rdname mynewclass-class
#' @exportClass mynewclass
setClass(""mynewclass"",
    representation(myslot1=""logical"",
        myslot2=""integer"",
        myslot3=""data.frame""),
    contains = ""character""
)
</code></pre>

<p>However, although this works, this <code>\describe</code> , <code>\item</code> approach for documenting the slots seems inconsistent with the rest of roxygen(2), in that there are no <code>@</code>-delimited tags and slots could go undocumented with no objection from <code>roxygenize()</code>. It also says nothing about a consistent way to document inheritance of the class being defined. I imagine dependency still generally works fine (if a particular slot requires a non-base class from another package) using the <code>@import</code> tag. </p>

<p>So, to summarize, what is the current best-practice for roxygen(2) slots?</p>

<p>There seem to be three options to consider at the moment:</p>

<blockquote>
  <ul>
  <li>A -- Itemized list (as example above).</li>
  <li>B -- <code>@slot</code> ... but with extra tags/implementation I missed. I was    unable to get @slot to work with roxygen / roxygen2 in versions where 
  it was included as a replacement for the itemized list in the example 
  above. Again, the example above does work with roxygen(2). </li>
  <li>C -- Some alternative tag for specifying slots, like <code>@param</code>, that    would accomplish the same thing.</li>
  </ul>
</blockquote>

<p>I'm borrowing/extending this question from a post I made to the <code>roxygen2</code> development page on <a href=""https://github.com/klutometis/roxygen/issues/34"" rel=""noreferrer"">github</a>.</p>
",How to properly document S4 class slots using Roxygen2?,0.02288052
17530187,3715,85,"<p>In an interview I was confronted with a question such as this:   </p>

<blockquote>
  <p>Your friend has given you a single source code file which prints the
  Fibonacci numbers on the console. Note that the main() block is
  empty and doesn't have any statements inside it. </p>
  
  <p>Explain how this is possible (hint: global instance!) </p>
</blockquote>

<p>I really want to know about this, how such a thing can be even possible!</p>
",How is it possible to declare nothing inside main() in C++ and yet have a working application after compilation?,0.02288022
24938333,3194,73,"<p>I recently came upon the following code:</p>

<pre><code>IntPredicate neg = x -&gt; x &lt;- x;
</code></pre>

<p>What is this, some sort of reverse double lambda?</p>
",What does the -> <- operator do?,0.02285535
14965238,4115,94,"<p>I'm trying to assert the equality of two <code>System.Drawing.Size</code> structures, and I'm getting a format exception instead of the expected assert failure.</p>

<pre><code>[TestMethod]
public void AssertStructs()
{
    var struct1 = new Size(0, 0);
    var struct2 = new Size(1, 1);

    //This throws a format exception, ""System.FormatException: Input string was not in a correct format.""
    Assert.AreEqual(struct1, struct2, ""Failed. Expected {0}, actually it is {1}"", struct1, struct2); 

    //This assert fails properly, ""Failed. Expected {Width=0, Height=0}, actually it is {Width=1, Height=1}"".
    Assert.AreEqual(struct1, struct2, ""Failed. Expected "" + struct1 + "", actually it is "" + struct2); 
}
</code></pre>

<p>Is this intended behavior? Am I doing something wrong here?</p>
",Why does this assert throw a format exception when comparing structures?,0.02284326
44767080,3415,78,"<p>I'm currently in the process of writing a tree enumerator where I've come across the following problem:</p>

<p>I'm looking at masked bitsets, i.e. bitsets where the set bits are a subset of a mask, i.e. <code>0000101</code> with mask <code>1010101</code>. What I want to accomplish is increment the bitset, but only with respect to the masked bits. In this example, the result would be <code>0010000</code>. To make it a bit clearer, extract only the masked bits, i.e. <code>0011</code>, increment them to <code>0100</code> and distribute them to the mask bits again, giving <code>0010000</code>.</p>

<p>Does anybody see an efficient way to do this, short of implementing the operation by hand using a combination of bitscans and prefix masks?</p>
",Incrementing 'masked' bitsets,0.02284041
31187452,3065,70,"<p>Why this code prints <code>AAC</code> instead of expected <code>A$`C</code>?</p>

<pre><code>console.log('ABC'.replace('B', '$`'));
</code></pre>

<p>==></p>

<pre><code>AAC
</code></pre>

<p>And how to make it give the expected result?</p>
","Why 'ABC'.replace('B', '$`') gives AAC",0.0228385
6785651,3504,80,"<p>I am working on this driver that connects the hard disk over the network. There is a bug that if I enable two or more hard disks on the computer, only the first one gets the partitions looked over and identified. The result is, if I have 1 partition on hda and 1 partitions on hdb, as soon as I connect hda there is a partition that can be mounted. So hda1 gets a blkid xyz123 as soon as it mounts. But when I go ahead and mount hdb1 it also comes up with the same blkid and in fact, the driver is reading it from hda, not hdb. </p>

<p>So I think I found the place where the driver is messing up. Below is a debug output including a dump_stack which I put at the first spot where it seems to be accessing the wrong device. </p>

<p>Here is the code section:</p>

<pre><code>/*basically, this is just the request_queue processor. In the log output that
  follows, the second device, (hdb) has just been connected, right after hda
  was connected and hda1 was mounted to the system. */

void nblk_request_proc(struct request_queue *q)
{
struct request *req;
ndas_error_t err = NDAS_OK;

dump_stack();

while((req = NBLK_NEXT_REQUEST(q)) != NULL)
{
    dbgl_blk(8,""processing queue request from slot %d"",SLOT_R(req));

    if (test_bit(NDAS_FLAG_QUEUE_SUSPENDED, &amp;(NDAS_GET_SLOT_DEV(SLOT_R(req))-&gt;queue_flags)))  {
        printk (""ndas: Queue is suspended\n"");
        /* Queue is suspended */
#if ( LINUX_VERSION_CODE &gt;= KERNEL_VERSION(2,6,31) )
        blk_start_request(req);
#else
        blkdev_dequeue_request(req);
#endif
</code></pre>

<p>Here is a log output. I have added some comments to help understand what is happening and where the bad call seems to come up. </p>

<pre><code>  /* Just below here you can see ""slot"" mentioned many times. This is the 
     identification for the network case in which the hd is connected to the 
     network. So you will see slot 2 in this log because the first device has 
     already been connected and mounted. */

  kernel: [231644.155503] BL|4|slot_enable|/driver/block/ctrldev.c:281|adding disk: slot=2, first_minor=16, capacity=976769072|nd/dpcd1,64:15:44.38,3828:10
  kernel: [231644.155588] BL|3|ndop_open|/driver/block/ops.c:233|ing bdev=f6823400|nd/dpcd1,64:15:44.38,3720:10
  kernel: [231644.155598] BL|2|ndop_open|/driver/block/ops.c:247|slot =0x2|nd/dpcd1,64:15:44.38,3720:10
  kernel: [231644.155606] BL|2|ndop_open|/driver/block/ops.c:248|dev_t=0x3c00010|nd/dpcd1,64:15:44.38,3720:10
  kernel: [231644.155615] ND|3|ndas_query_slot|netdisk/nddev.c:791|slot=2 sdev=d33e2080|nd/dpcd1,64:15:44.38,3696:10
  kernel: [231644.155624] ND|3|ndas_query_slot|netdisk/nddev.c:817|ed|nd/dpcd1,64:15:44.38,3696:10
  kernel: [231644.155631] BL|3|ndop_open|/driver/block/ops.c:326|mode=1|nd/dpcd1,64:15:44.38,3720:10
  kernel: [231644.155640] BL|3|ndop_open|/driver/block/ops.c:365|ed open|nd/dpcd1,64:15:44.38,3724:10
  kernel: [231644.155653] BL|8|ndop_revalidate_disk|/driver/block/ops.c:2334|gendisk=c6afd800={major=60,first_minor=16,minors=0x10,disk_name=ndas-44700486-0,private_data=00000002,capacity=%lld}|nd/dpcd1,64:15:44.38,3660:10
  kernel: [231644.155668] BL|8|ndop_revalidate_disk|/driver/block/ops.c:2346|ed|nd/dpcd1,64:15:44.38,3652:10

  /* So at this point the hard disk is added (gendisk=c6...) and the identifications
     all match the network device. The driver is now about to begin scanning the 
     hard drive for existing partitions. the little 'ed', at the end of the previous
     line indicates that revalidate_disk has finished it's job. 

     Also, I think the request queue is indicated by the output dpcd1 near the very
     end of the line. 

     Now below we have entered the function that is pasted above. In the function
     you can see that the slot can be determined by the queue. And the log output
     after the stack dump shows it is from slot 1. (The first network drive that was
     already mounted.) */

        kernel: [231644.155677]  ndas-44700486-0:Pid: 467, comm: nd/dpcd1 Tainted: P           2.6.32-5-686 #1
  kernel: [231644.155711] Call Trace:
  kernel: [231644.155723]  [&lt;fc5a7685&gt;] ? nblk_request_proc+0x9/0x10c [ndas_block]
  kernel: [231644.155732]  [&lt;c11298db&gt;] ? __generic_unplug_device+0x23/0x25
  kernel: [231644.155737]  [&lt;c1129afb&gt;] ? generic_unplug_device+0x1e/0x2e
  kernel: [231644.155743]  [&lt;c1123090&gt;] ? blk_unplug+0x2e/0x31
  kernel: [231644.155750]  [&lt;c10cceec&gt;] ? block_sync_page+0x33/0x34
  kernel: [231644.155756]  [&lt;c108770c&gt;] ? sync_page+0x35/0x3d
  kernel: [231644.155763]  [&lt;c126d568&gt;] ? __wait_on_bit_lock+0x31/0x6a
  kernel: [231644.155768]  [&lt;c10876d7&gt;] ? sync_page+0x0/0x3d
  kernel: [231644.155773]  [&lt;c10876aa&gt;] ? __lock_page+0x76/0x7e
  kernel: [231644.155780]  [&lt;c1043f1f&gt;] ? wake_bit_function+0x0/0x3c
  kernel: [231644.155785]  [&lt;c1087b76&gt;] ? do_read_cache_page+0xdf/0xf8
  kernel: [231644.155791]  [&lt;c10d21b9&gt;] ? blkdev_readpage+0x0/0xc
  kernel: [231644.155796]  [&lt;c1087bbc&gt;] ? read_cache_page_async+0x14/0x18
  kernel: [231644.155801]  [&lt;c1087bc9&gt;] ? read_cache_page+0x9/0xf
  kernel: [231644.155808]  [&lt;c10ed6fc&gt;] ? read_dev_sector+0x26/0x60
  kernel: [231644.155813]  [&lt;c10ee368&gt;] ? adfspart_check_ICS+0x20/0x14c
  kernel: [231644.155819]  [&lt;c10ee138&gt;] ? rescan_partitions+0x17e/0x378
  kernel: [231644.155825]  [&lt;c10ee348&gt;] ? adfspart_check_ICS+0x0/0x14c
  kernel: [231644.155830]  [&lt;c10d26a3&gt;] ? __blkdev_get+0x225/0x2c7
  kernel: [231644.155836]  [&lt;c10ed7e6&gt;] ? register_disk+0xb0/0xfd
  kernel: [231644.155843]  [&lt;c112e33b&gt;] ? add_disk+0x9a/0xe8
  kernel: [231644.155848]  [&lt;c112dafd&gt;] ? exact_match+0x0/0x4
  kernel: [231644.155853]  [&lt;c112deae&gt;] ? exact_lock+0x0/0xd
  kernel: [231644.155861]  [&lt;fc5a8b80&gt;] ? slot_enable+0x405/0x4a5 [ndas_block]
  kernel: [231644.155868]  [&lt;fc5a8c63&gt;] ? ndcmd_enabled_handler+0x43/0x9e [ndas_block]
  kernel: [231644.155874]  [&lt;fc5a8c20&gt;] ? ndcmd_enabled_handler+0x0/0x9e [ndas_block]
  kernel: [231644.155891]  [&lt;fc54b22b&gt;] ? notify_func+0x38/0x4b [ndas_core]
  kernel: [231644.155906]  [&lt;fc561cba&gt;] ? _dpc_cancel+0x17c/0x626 [ndas_core]
  kernel: [231644.155919]  [&lt;fc562005&gt;] ? _dpc_cancel+0x4c7/0x626 [ndas_core]
  kernel: [231644.155933]  [&lt;fc561cba&gt;] ? _dpc_cancel+0x17c/0x626 [ndas_core]
  kernel: [231644.155941]  [&lt;c1003d47&gt;] ? kernel_thread_helper+0x7/0x10

  /* here are the output of the driver debugs. They show that this operation is
     being performed on the first devices request queue. */

  kernel: [231644.155948] BL|8|nblk_request_proc|/driver/block/block26.c:494|processing queue request from slot 1|nd/dpcd1,64:15:44.38,3408:10
  kernel: [231644.155959] BL|8|nblk_handle_io|/driver/block/block26.c:374|struct ndas_slot sd = NDAS GET SLOT DEV(slot 1)
  kernel: [231644.155966] |nd/dpcd1,64:15:44.38,3328:10
  kernel: [231644.155970] BL|8|nblk_handle_io|/driver/block/block26.c:458|case READA call ndas_read(slot=1, ndas_req)|nd/dpcd1,64:15:44.38,3328:10
  kernel: [231644.155979] ND|8|ndas_read|netdisk/nddev.c:824|read io: slot=1, cmd=0, req=x00|nd/dpcd1,64:15:44.38,3320:10
</code></pre>

<p>I hope this is enough background information. Maybe an obvious question at this moment is ""When and where are the request_queues assigned?"" </p>

<p>Well that is handled a little bit before the add_disk function. adding disk, is the first line on the log output. </p>

<pre><code>slot-&gt;disk = NULL;
spin_lock_init(&amp;slot-&gt;lock);
slot-&gt;queue = blk_init_queue(
    nblk_request_proc, 
    &amp;slot-&gt;lock
);
</code></pre>

<p>As far as I know, this is the standard operation. So back to my original question. Can I find the request queue somewhere and make sure it is incremented or unique for each new device or does the Linux kernel only use one queue for each Major number? I want to discover why this driver is loading the same queue on two different block storages, and determine if that is causing the duplicate blkid during the initial registration process.</p>

<p>Thanks for looking at this situation for me. </p>
",How can I identify the request queue for a linux block device,0.02283105
6256847,23444,535,"<p><strong>Note: this appears to have been fixed in <a href=""https://github.com/dotnet/roslyn"" rel=""noreferrer"">Roslyn</a></strong></p>

<p>This question arose when writing my answer to <a href=""https://stackoverflow.com/questions/6238074"">this one</a>, which talks about the associativity of the <a href=""http://msdn.microsoft.com/en-us/library/ms173224.aspx"" rel=""noreferrer"">null-coalescing operator</a>.</p>

<p>Just as a reminder, the idea of the null-coalescing operator is that an expression of the form</p>

<pre><code>x ?? y
</code></pre>

<p>first evaluates <code>x</code>, then:</p>

<ul>
<li>If the value of <code>x</code> is null, <code>y</code> is evaluated and that is the end result of the expression</li>
<li>If the value of <code>x</code> is non-null, <code>y</code> is <em>not</em> evaluated, and the value of <code>x</code> is the end result of the expression, after a conversion to the compile-time type of <code>y</code> if necessary</li>
</ul>

<p>Now <em>usually</em> there's no need for a conversion, or it's just from a nullable type to a non-nullable one - usually the types are the same, or just from (say) <code>int?</code> to <code>int</code>. However, you <em>can</em> create your own implicit conversion operators, and those are used where necessary.</p>

<p>For the simple case of <code>x ?? y</code>, I haven't seen any odd behaviour. However, with <code>(x ?? y) ?? z</code> I see some confusing behaviour.</p>

<p>Here's a short but complete test program - the results are in the comments:</p>

<pre><code>using System;

public struct A
{
    public static implicit operator B(A input)
    {
        Console.WriteLine(""A to B"");
        return new B();
    }

    public static implicit operator C(A input)
    {
        Console.WriteLine(""A to C"");
        return new C();
    }
}

public struct B
{
    public static implicit operator C(B input)
    {
        Console.WriteLine(""B to C"");
        return new C();
    }
}

public struct C {}

class Test
{
    static void Main()
    {
        A? x = new A();
        B? y = new B();
        C? z = new C();
        C zNotNull = new C();

        Console.WriteLine(""First case"");
        // This prints
        // A to B
        // A to B
        // B to C
        C? first = (x ?? y) ?? z;

        Console.WriteLine(""Second case"");
        // This prints
        // A to B
        // B to C
        var tmp = x ?? y;
        C? second = tmp ?? z;

        Console.WriteLine(""Third case"");
        // This prints
        // A to B
        // B to C
        C? third = (x ?? y) ?? zNotNull;
    }
}
</code></pre>

<p>So we have three custom value types, <code>A</code>, <code>B</code> and <code>C</code>, with conversions from A to B, A to C, and B to C.</p>

<p>I can understand both the second case and the third case... but <em>why</em> is there an extra A to B conversion in the first case? In particular, I'd <em>really</em> have expected the first case and second case to be the same thing - it's just extracting an expression into a local variable, after all.</p>

<p>Any takers on what's going on? I'm extremely hesistant to cry ""bug"" when it comes to the C# compiler, but I'm stumped as to what's going on...</p>

<p>EDIT: Okay, here's a nastier example of what's going on, thanks to configurator's answer, which gives me further reason to think it's a bug. EDIT: The sample doesn't even need two null-coalescing operators now...</p>

<pre><code>using System;

public struct A
{
    public static implicit operator int(A input)
    {
        Console.WriteLine(""A to int"");
        return 10;
    }
}

class Test
{
    static A? Foo()
    {
        Console.WriteLine(""Foo() called"");
        return new A();
    }

    static void Main()
    {
        int? y = 10;

        int? result = Foo() ?? y;
    }
}
</code></pre>

<p>The output of this is:</p>

<pre><code>Foo() called
Foo() called
A to int
</code></pre>

<p>The fact that <code>Foo()</code> gets called twice here is hugely surprising to me - I can't see any reason for the expression to be <em>evaluated</em> twice.</p>
",Curious null-coalescing operator custom implicit conversion behaviour,0.02282034
58441514,4140,94,"<p>It's been cited by many users as the reason for switching to Pytorch, but I've yet to find a justification / explanation for sacrificing the most important practical quality, speed, for eager execution.</p>

<p>Below is code benchmarking performance, TF1 vs. TF2 - with TF1 running anywhere from <strong>47% to 276% faster</strong>. </p>

<p>My question is: <em>what is it, at the graph or hardware level, that yields such a significant slowdown?</em></p>

<hr>

<p>Looking for a detailed answer - am already familiar with broad concepts. <a href=""https://github.com/tensorflow/tensorflow/issues/33487"" rel=""noreferrer"">Relevant Git</a></p>

<p><strong>Specs</strong>: CUDA 10.0.130, cuDNN 7.4.2, Python 3.7.4, Windows 10, GTX 1070</p>

<hr>

<p><strong>Benchmark results</strong>:</p>

<p><img src=""https://i.stack.imgur.com/ayBCS.png"" width=""530""></p>

<hr>

<p><strong>UPDATE</strong>: Disabling Eager Execution per below code does <em>not</em> help. The behavior, however, is inconsistent: sometimes running in graph mode helps considerably, other times it runs <em>slower</em> relative to Eager.</p>

<p>As TF devs don't appear around anywhere, I'll be investigating this matter myself - can follow progress in the linked Github issue.</p>

<p><strong>UPDATE 2</strong>: tons of experimental results to share, along explanations; should be done today.</p>

<hr>

<p><strong>Benchmark code</strong>:</p>

<pre class=""lang-py prettyprint-override""><code># use tensorflow.keras... to benchmark tf.keras; used GPU for all above benchmarks
from keras.layers import Input, Dense, LSTM, Bidirectional, Conv1D
from keras.layers import Flatten, Dropout
from keras.models import Model
from keras.optimizers import Adam
import keras.backend as K
import numpy as np
from time import time

batch_shape = (32, 400, 16)
X, y = make_data(batch_shape)

model_small = make_small_model(batch_shape)
model_small.train_on_batch(X, y)  # skip first iteration which builds graph
timeit(model_small.train_on_batch, 200, X, y)

K.clear_session()  # in my testing, kernel was restarted instead

model_medium = make_medium_model(batch_shape)
model_medium.train_on_batch(X, y)  # skip first iteration which builds graph
timeit(model_medium.train_on_batch, 10, X, y)
</code></pre>

<hr>

<p><strong>Functions used</strong>:</p>

<pre class=""lang-py prettyprint-override""><code>def timeit(func, iterations, *args):
    t0 = time()
    for _ in range(iterations):
        func(*args)
    print(""Time/iter: %.4f sec"" % ((time() - t0) / iterations))

def make_small_model(batch_shape):
    ipt   = Input(batch_shape=batch_shape)
    x     = Conv1D(128, 400, strides=4, padding='same')(ipt)
    x     = Flatten()(x)
    x     = Dropout(0.5)(x)
    x     = Dense(64, activation='relu')(x)
    out   = Dense(1,  activation='sigmoid')(x)
    model = Model(ipt, out)
    model.compile(Adam(lr=1e-4), 'binary_crossentropy')
    return model

def make_medium_model(batch_shape):
    ipt   = Input(batch_shape=batch_shape)
    x     = Bidirectional(LSTM(512, activation='relu', return_sequences=True))(ipt)
    x     = LSTM(512, activation='relu', return_sequences=True)(x)
    x     = Conv1D(128, 400, strides=4, padding='same')(x)
    x     = Flatten()(x)
    x     = Dense(256, activation='relu')(x)
    x     = Dropout(0.5)(x)
    x     = Dense(128, activation='relu')(x)
    x     = Dense(64,  activation='relu')(x)
    out   = Dense(1,   activation='sigmoid')(x)
    model = Model(ipt, out)
    model.compile(Adam(lr=1e-4), 'binary_crossentropy')
    return model

def make_data(batch_shape):
    return np.random.randn(*batch_shape), np.random.randint(0, 2, (batch_shape[0], 1))
</code></pre>
",Why is TensorFlow 2 much slower than TensorFlow 1?,0.02270531
52451998,7457,169,"<p>I tried to create an image file, like this:</p>

<pre><code>uint8_t raw_r[pixel_width][pixel_height];
uint8_t raw_g[pixel_width][pixel_height];
uint8_t raw_b[pixel_width][pixel_height];
uint8_t blue(uint32_t x, uint32_t y)
{
    return (rand()%2)? (x+y)%rand() : ((x*y%1024)%rand())%2 ? (x-y)%rand() : rand();
}
uint8_t green(uint32_t x, uint32_t y)
{
    return (rand()%2)? (x-y)%rand() : ((x*y%1024)%rand())%2 ? (x+y)%rand() : rand();
}
uint8_t red(uint32_t x, uint32_t y)
{
    return (rand()%2)? (y-x)%rand() : ((x*y%1024)%rand())%2 ? (x+y)%rand() : rand();
}

for (y=0; y&lt;pixel_height; ++y)
{
    for (x=0; x&lt;pixel_width; ++x)
    {
        raw_b[x][y]=blue(x, y);
        raw_g[x][y]=green(x, y);
        raw_r[x][y]=red(x, y);
    }
}
</code></pre>

<p>I expected to get something random (white noise). However, the output is interesting:</p>

<p><a href=""https://i.stack.imgur.com/fLHGD.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/fLHGD.gif"" alt=""""></a></p>

<p>Do you know the reason why?</p>

<hr>

<h1>Edit</h1>

<p>Now, it is clear that it has nothing to do with <code>rand()</code>.</p>

<p>Also try this code:</p>

<pre><code>for (x=0; x&lt;pixel_width; ++x)
    for (y=0; y&lt;pixel_height; ++y)
    {
        r[x][y] = (x+y);
        g[x][y] = (y-x);
        /* b[x][y] = rand()%2? x : y; */
    }
</code></pre>

<p><a href=""https://i.stack.imgur.com/hLKRO.gif"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/hLKRO.gif"" alt=""""></a></p>
",Why do I get this particular color pattern when using rand()?,0.02266327
26295216,5163,117,"<p>I recently came across a strange deoptimization (or rather missed optimization opportunity).</p>

<p>Consider this function for efficient unpacking of arrays of 3-bit integers to 8-bit integers. It unpacks 16 ints in each loop iteration:</p>

<pre><code>void unpack3bit(uint8_t* target, char* source, int size) {
   while(size &gt; 0){
      uint64_t t = *reinterpret_cast&lt;uint64_t*&gt;(source);
      target[0] = t &amp; 0x7;
      target[1] = (t &gt;&gt; 3) &amp; 0x7;
      target[2] = (t &gt;&gt; 6) &amp; 0x7;
      target[3] = (t &gt;&gt; 9) &amp; 0x7;
      target[4] = (t &gt;&gt; 12) &amp; 0x7;
      target[5] = (t &gt;&gt; 15) &amp; 0x7;
      target[6] = (t &gt;&gt; 18) &amp; 0x7;
      target[7] = (t &gt;&gt; 21) &amp; 0x7;
      target[8] = (t &gt;&gt; 24) &amp; 0x7;
      target[9] = (t &gt;&gt; 27) &amp; 0x7;
      target[10] = (t &gt;&gt; 30) &amp; 0x7;
      target[11] = (t &gt;&gt; 33) &amp; 0x7;
      target[12] = (t &gt;&gt; 36) &amp; 0x7;
      target[13] = (t &gt;&gt; 39) &amp; 0x7;
      target[14] = (t &gt;&gt; 42) &amp; 0x7;
      target[15] = (t &gt;&gt; 45) &amp; 0x7;
      source+=6;
      size-=6;
      target+=16;
   }
}
</code></pre>

<p>Here is the generated assembly for parts of the code:</p>

<pre><code> ...
 367:   48 89 c1                mov    rcx,rax
 36a:   48 c1 e9 09             shr    rcx,0x9
 36e:   83 e1 07                and    ecx,0x7
 371:   48 89 4f 18             mov    QWORD PTR [rdi+0x18],rcx
 375:   48 89 c1                mov    rcx,rax
 378:   48 c1 e9 0c             shr    rcx,0xc
 37c:   83 e1 07                and    ecx,0x7
 37f:   48 89 4f 20             mov    QWORD PTR [rdi+0x20],rcx
 383:   48 89 c1                mov    rcx,rax
 386:   48 c1 e9 0f             shr    rcx,0xf
 38a:   83 e1 07                and    ecx,0x7
 38d:   48 89 4f 28             mov    QWORD PTR [rdi+0x28],rcx
 391:   48 89 c1                mov    rcx,rax
 394:   48 c1 e9 12             shr    rcx,0x12
 398:   83 e1 07                and    ecx,0x7
 39b:   48 89 4f 30             mov    QWORD PTR [rdi+0x30],rcx
 ...
</code></pre>

<p>It looks quite efficent. Simply a <code>shift right</code> followed by an <code>and</code>, and then a <code>store</code> to the <code>target</code> buffer. But now, look what happens when I change the function to a method in a struct:</p>

<pre><code>struct T{
   uint8_t* target;
   char* source;
   void unpack3bit( int size);
};

void T::unpack3bit(int size) {
        while(size &gt; 0){
           uint64_t t = *reinterpret_cast&lt;uint64_t*&gt;(source);
           target[0] = t &amp; 0x7;
           target[1] = (t &gt;&gt; 3) &amp; 0x7;
           target[2] = (t &gt;&gt; 6) &amp; 0x7;
           target[3] = (t &gt;&gt; 9) &amp; 0x7;
           target[4] = (t &gt;&gt; 12) &amp; 0x7;
           target[5] = (t &gt;&gt; 15) &amp; 0x7;
           target[6] = (t &gt;&gt; 18) &amp; 0x7;
           target[7] = (t &gt;&gt; 21) &amp; 0x7;
           target[8] = (t &gt;&gt; 24) &amp; 0x7;
           target[9] = (t &gt;&gt; 27) &amp; 0x7;
           target[10] = (t &gt;&gt; 30) &amp; 0x7;
           target[11] = (t &gt;&gt; 33) &amp; 0x7;
           target[12] = (t &gt;&gt; 36) &amp; 0x7;
           target[13] = (t &gt;&gt; 39) &amp; 0x7;
           target[14] = (t &gt;&gt; 42) &amp; 0x7;
           target[15] = (t &gt;&gt; 45) &amp; 0x7;
           source+=6;
           size-=6;
           target+=16;
        }
}
</code></pre>

<p>I thought the generated assembly should be quite the same, but it isn't. Here is a part of it:</p>

<pre><code>...
 2b3:   48 c1 e9 15             shr    rcx,0x15
 2b7:   83 e1 07                and    ecx,0x7
 2ba:   88 4a 07                mov    BYTE PTR [rdx+0x7],cl
 2bd:   48 89 c1                mov    rcx,rax
 2c0:   48 8b 17                mov    rdx,QWORD PTR [rdi] // Load, BAD!
 2c3:   48 c1 e9 18             shr    rcx,0x18
 2c7:   83 e1 07                and    ecx,0x7
 2ca:   88 4a 08                mov    BYTE PTR [rdx+0x8],cl
 2cd:   48 89 c1                mov    rcx,rax
 2d0:   48 8b 17                mov    rdx,QWORD PTR [rdi] // Load, BAD!
 2d3:   48 c1 e9 1b             shr    rcx,0x1b
 2d7:   83 e1 07                and    ecx,0x7
 2da:   88 4a 09                mov    BYTE PTR [rdx+0x9],cl
 2dd:   48 89 c1                mov    rcx,rax
 2e0:   48 8b 17                mov    rdx,QWORD PTR [rdi] // Load, BAD!
 2e3:   48 c1 e9 1e             shr    rcx,0x1e
 2e7:   83 e1 07                and    ecx,0x7
 2ea:   88 4a 0a                mov    BYTE PTR [rdx+0xa],cl
 2ed:   48 89 c1                mov    rcx,rax
 2f0:   48 8b 17                mov    rdx,QWORD PTR [rdi] // Load, BAD!
 ...
</code></pre>

<p>As you see, we introduced an additional redundant <code>load</code> from memory before each shift (<code>mov    rdx,QWORD PTR [rdi]</code>). It seems like the <code>target</code> pointer (which is now a member instead of a local variable) has to be always reloaded before storing into it. <em>This slows down the code considerably (around 15% in my measurements).</em></p>

<p>First I thought maybe the C++ memory model enforces that a member pointer may not be stored in a register but has to be reloaded, but this seemed like an awkward choice, as it would make a lot of viable optimizations impossible. So I was very surprised that the compiler did not store <code>target</code> in a register here.</p>

<p>I tried caching the member pointer myself into a local variable:</p>

<pre><code>void T::unpack3bit(int size) {
    while(size &gt; 0){
       uint64_t t = *reinterpret_cast&lt;uint64_t*&gt;(source);
       uint8_t* target = this-&gt;target; // &lt;&lt; ptr cached in local variable
       target[0] = t &amp; 0x7;
       target[1] = (t &gt;&gt; 3) &amp; 0x7;
       target[2] = (t &gt;&gt; 6) &amp; 0x7;
       target[3] = (t &gt;&gt; 9) &amp; 0x7;
       target[4] = (t &gt;&gt; 12) &amp; 0x7;
       target[5] = (t &gt;&gt; 15) &amp; 0x7;
       target[6] = (t &gt;&gt; 18) &amp; 0x7;
       target[7] = (t &gt;&gt; 21) &amp; 0x7;
       target[8] = (t &gt;&gt; 24) &amp; 0x7;
       target[9] = (t &gt;&gt; 27) &amp; 0x7;
       target[10] = (t &gt;&gt; 30) &amp; 0x7;
       target[11] = (t &gt;&gt; 33) &amp; 0x7;
       target[12] = (t &gt;&gt; 36) &amp; 0x7;
       target[13] = (t &gt;&gt; 39) &amp; 0x7;
       target[14] = (t &gt;&gt; 42) &amp; 0x7;
       target[15] = (t &gt;&gt; 45) &amp; 0x7;
       source+=6;
       size-=6;
       this-&gt;target+=16;
    }
}
</code></pre>

<p>This code also yields the ""good"" assembler without additional stores. So my guess is: The compiler is not allowed to hoist the load of a member pointer of a struct, so such a ""hot pointer"" should always be stored in a local variable. </p>

<ul>
<li><strong>So, why is the compiler unable to optimize out these loads?</strong></li>
<li><strong>Is it the C++ memory model that forbids this? Or is it simply a shortcoming of my compiler?</strong></li>
<li><strong>Is my guess correct or what is the exact reason why the optimization can't be performed?</strong></li>
</ul>

<p>The compiler in use was <code>g++ 4.8.2-19ubuntu1</code> with <code>-O3</code> optimization. I also tried <code>clang++ 3.4-1ubuntu3</code> with similar results: Clang is even able to vectorize the method with the local <code>target</code> pointer. However, using the <code>this-&gt;target</code> pointer yields the same result: An extra load of the pointer before each store.</p>

<p>I checked the assembler of some similar methods and the result is the same: It seems that a member of <code>this</code> always has to be reloaded before a store, even if such a load could simply be hoisted outside the loop. I will have to rewrite a lot of code to get rid of these additional stores, mainly by caching the pointer myself into a local variable that is declared above the hot code. <strong>But I always thought fiddling with such details as caching a pointer in a local variable would surely qualify for premature optimization in these days where compilers have gotten so clever. But it seems I am wrong here</strong>. Caching a member pointer in a hot loop seems to be a necessary manual optimization technique.</p>
",Using this pointer causes strange deoptimization in hot loop,0.02266124
33272994,5523,125,"<p>Why does Clang optimize away the loop in this code</p>

<pre><code>#include &lt;time.h&gt;
#include &lt;stdio.h&gt;

static size_t const N = 1 &lt;&lt; 27;
static double arr[N] = { /* initialize to zero */ };

int main()
{
    clock_t const start = clock();
    for (int i = 0; i &lt; N; ++i) { arr[i] *= 1.0; }
    printf(""%u ms\n"", (unsigned)(clock() - start) * 1000 / CLOCKS_PER_SEC);
}
</code></pre>

<p>but not the loop in this code?</p>

<pre><code>#include &lt;time.h&gt;
#include &lt;stdio.h&gt;

static size_t const N = 1 &lt;&lt; 27;
static double arr[N] = { /* initialize to zero */ };

int main()
{
    clock_t const start = clock();
    for (int i = 0; i &lt; N; ++i) { arr[i] += 0.0; }
    printf(""%u ms\n"", (unsigned)(clock() - start) * 1000 / CLOCKS_PER_SEC);
}
</code></pre>

<p>(Tagging as both C and C++ because I would like to know if the answer is different for each.)</p>
",Why does Clang optimize away x * 1.0 but NOT x + 0.0?,0.02263263
9477970,4022,91,"<p>I'm developing a language dictionary app. I save the favourite word into Preference. The Favourite content in the XML file looks like the following:</p>

<pre class=""lang-xml prettyprint-override""><code>&lt;?xml version='1.0' encoding='utf-8' standalone='yes' ?&gt;
  &lt;map&gt;
    &lt;string name=""history""&gt;
      dict_name::160170::hi,dict_name::157140::he-man,dict_name::184774::jet,dict_name::34527::black
    &lt;/string&gt;
    &lt;string name=""waitingTime""&gt;
      0
    &lt;/string&gt;
    &lt;boolean name=""saveFavourite"" value=""true"" /&gt;
    &lt;string name=""defaultDictionary""&gt;
      dict_name
    &lt;/string&gt;
    &lt;string name=""favourite""&gt;
      dict_name::149271::go,dict_name::25481::back,dict_name::184774::jet
    &lt;/string&gt;
    &lt;boolean name=""saveHistory"" value=""true"" /&gt;
  &lt;/map&gt;
</code></pre>

<p>I use the following code to load the Favourite content into the webview:</p>

<pre class=""lang-java prettyprint-override""><code>public class User extends Activity {
    private static final String FAVOURITE_TAG = ""[MyDict - FavouriteView] "";
    private static final String CONTENT_TAG = null;

    private ListView mLSTFavourite = null;
    private ArrayList&lt;String&gt; lstDict = null;
    private ArrayList&lt;Integer&gt; lstId = null;
    private ArrayList&lt;String&gt; mWordFavourite = null;
    private ArrayAdapter&lt;String&gt; aptList = null;
    private SharedPreferences prefs;

    @Override
    public void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.favourite);
        prefs = PreferenceManager.getDefaultSharedPreferences(getApplicationContext());

        if (prefs.getBoolean(""saveFavourite"", true)) {
            String strFavourite = prefs.getString(""favourite"", """");
            Log.i(FAVOURITE_TAG, ""Favourite loaded"");
            if (strFavourite != null &amp;&amp; !strFavourite.equals("""")) {
                mWordFavourite = new ArrayList&lt;String&gt;(Arrays.asList(strFavourite.split("","")));
            } else {
                mWordFavourite = new ArrayList&lt;String&gt;();
            }
        } else {
            mWordFavourite = new ArrayList&lt;String&gt;();
        }

        Log.d(FAVOURITE_TAG, ""mWordFavourite = "" + mWordFavourite.size());
        mLSTFavourite = (ListView) findViewById(R.id.lstFavourite);

        ImageButton btnClear = (ImageButton) findViewById(R.id.btnClear);
        ImageButton btnBackToContent = (ImageButton) findViewById(R.id.btnBackToContent);

        if (lstDict == null) {
            lstDict = new ArrayList&lt;String&gt;();
            lstId = new ArrayList&lt;Integer&gt;();
            aptList = new ArrayAdapter&lt;String&gt;(getApplicationContext(), R.layout.customlist);
        }
        lstDict.clear();
        lstId.clear();
        aptList.clear();

        if (mWordFavourite != null &amp;&amp; mWordFavourite.size() &gt; 0) {
            try {
                for (int i = 0; i &lt; mWordFavourite.size(); i++) {
                    Log.i(FAVOURITE_TAG, ""item = "" + mWordFavourite.get(i));
                    String arrPart[] = mWordFavourite.get(i).split(""::"");
                    if (arrPart.length == 3) {
                        Log.i(CONTENT_TAG, ""loaded content "" + arrPart.length + "", wordId = "" + arrPart[1]);
                        // Log.i(CONTENT_TAG, ""loaded 0"");
                        lstDict.add(i, arrPart[0]);
                        // Log.i(CONTENT_TAG, ""loaded 1"");
                        lstId.add(i, Integer.parseInt(arrPart[1]));
                        // Log.i(CONTENT_TAG, ""loaded 2"");
                        aptList.add(arrPart[2]);
                    } else {
                        Log.i(FAVOURITE_TAG, ""Wrong entry: "" + mWordFavourite.get(i));
                    }
                }
            } catch (Exception ex) {
                Log.i(FAVOURITE_TAG, ""Wrong entry found!"");
            }
        }
        // Log.i(CONTENT_TAG,""Adapter size = "" + aptList.getCount());
        // assign result return
        mLSTFavourite.setAdapter(aptList);
        mLSTFavourite.setOnItemClickListener(new AdapterView.OnItemClickListener() {
                    public void onItemClick(AdapterView&lt;?&gt; arg0, View v, int arg2, long arg3) {
                        // mEDWord.setText(mAdapter.getItem(arg2));
                        Intent i = new Intent();
                        i.putExtra(""dict"", lstDict.get(arg2));
                        i.putExtra(""wordId"", lstId.get(arg2));
                        setResult(RESULT_OK, i);
                        finish();
                    }
                });
        btnClear.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                // TODO Auto-generated method stub
                mWordFavourite.clear();
                aptList.clear();
                mLSTFavourite.setAdapter(aptList);
                SharedPreferences.Editor editor = prefs.edit();
                editor.putString(""favourite"", """");
                editor.commit();
                setResult(RESULT_OK);
                finish();
            }
        });

        btnBackToContent.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                setResult(RESULT_CANCELED);
                finish();
            }
        });
    }
}
</code></pre>

<p>The Favourite content is successfully loaded. The favourite words are listed in the webview. But the problem is that it only shows the definition of the latest word added to the Favourite regardless of what word is chosen. For example:</p>

<pre><code>word1
word2
word3
</code></pre>

<p>Despite word1 and/or word2 is selected for meaning, the definition of the last word, which is word3, is always shown. My purpose is to display the definition of <code>word1</code> when <code>word1</code> is selected, and the definition of <code>word2</code> when <code>word2</code> is selected, and so on and so forth. I save my dictionary data in SQLite database.</p>

<p>Can anybody there help to solve this problem.</p>
",Favourite content is not shown correctly on webview,0.02262556
2217524,8314,188,"<p>There is something I have never understood. How can a great big PC game like GTA IV use 50% of my CPU and run at 60fps while a DX demo of a rotating Teapot @ 60fps uses a whopping 30% ? </p>
",How are 3D games so efficient?,0.02261246
643032,7280,164,"<p>At Disney World, they use a system called <a href=""http://en.wikipedia.org/wiki/FASTPASS"" rel=""noreferrer"">Fastpass</a> to create a second, shorter line for popular rides.  The idea is that you can wait in the standard line, often with a wait longer than an hour, or you can get a FastPass which allows you to come back during a specified time block (usually a couple hours later) and only wait for 10 minutes or less.  You can only be ""waiting"" for one ride at a time with a FastPass.</p>

<p>I have been trying to figure out the queue theory behind this concept, but the only explanation I have found is that it is designed to get people out of the lines and doing things that will bring in additional revenue (shopping, eating, etc).  </p>

<p>Is this why FastPass was implemented, or is there a real visitor efficiency problem that it solving?  Are there software applications that have applied similar logic?  Are there software applications that <em>should</em> apply similar logic?</p>

<p>Part of the problem I see with implementing something similar in software is that it is based on users choosing their queue.  Do to the faster wait cycles in software, I think a good application of this theory would require the application to be smart enough to know what queues to place people in based on their needs without requiring end-user choice.</p>
",Is Disney's FastPass Valid and/or Useful Queue Theory,0.02252747
16950394,3063,69,"<p>Why can't you use a trailing comma with <code>*args</code> in Python?  In other words, this works</p>

<pre><code>&gt;&gt;&gt; f(1, 2, b=4,)
</code></pre>

<p>But this does not</p>

<pre><code>&gt;&gt;&gt; f(*(1, 2), b=4,)
  File ""&lt;stdin&gt;"", line 1
    f(*(1, 2), b=4,)
                   ^
SyntaxError: invalid syntax
</code></pre>

<p>This is the case with both Python 2 and Python 3.</p>
",Why is a trailing comma a SyntaxError in an argument list that uses *args syntax?,0.02252693
55807322,7865,177,"<p>Is there a way in Go to list <em>all</em> the standard/built-in packages (i.e., the packages which come installed with a GoLang installation)?</p>

<p>I have a list of packages and I want to figure out which packages are standard.</p>
",Can I list all standard Go packages?,0.02250477
9568074,6267,141,"<p>I'm trying to use http caching. In my controller I'm setting a response as follows: </p>

<pre><code>$response-&gt;setPublic();
$response-&gt;setMaxAge(120);
$response-&gt;setSharedMaxAge(120);
$response-&gt;setLastModified($lastModifiedAt);
</code></pre>

<p><strong>dev mode</strong></p>

<p>In dev environment first response is a 200 with following headers:</p>

<pre><code>cache-control:max-age=120, public, s-maxage=120
last-modified:Wed, 29 Feb 2012 19:00:00 GMT
</code></pre>

<p>For next 2 minutes every response is a 304 with following headers:</p>

<pre><code>cache-control:max-age=120, public, s-maxage=120
</code></pre>

<p>This is basically what I expect it to be.</p>

<p><strong>prod mode</strong></p>

<p>In prod mode response headers are different. Note that in app.php I wrap the kernel in AppCache.</p>

<p>First response is a 200 with following headers:</p>

<pre><code>cache-control:must-revalidate, no-cache, private
last-modified:Thu, 01 Mar 2012 11:17:35 GMT
</code></pre>

<p>So it's a private no-cache response.</p>

<p>Every next request is pretty much what I'd expect it to be; a 304 with following headers:</p>

<pre><code>cache-control:max-age=120, public, s-maxage=120
</code></pre>

<p><strong>Should I worry about it? Is it an expected behaviour?</strong> </p>

<p><strong>What will happen if I put Varnish or Akamai server in front of it?</strong></p>

<p>I did a bit of debugging and I figured that response is private because of last-modified header. HttpCache kernel <a href=""https://github.com/symfony/symfony/blob/master/src/Symfony/Component/HttpKernel/HttpCache/HttpCache.php#L210"">uses EsiResponseCacheStrategy</a> to update the cached response (<a href=""https://github.com/symfony/symfony/blob/master/src/Symfony/Component/HttpKernel/HttpCache/HttpCache.php#L171"">HttpCache::handle()</a> method). </p>

<pre><code>if (HttpKernelInterface::MASTER_REQUEST === $type) {
    $this-&gt;esiCacheStrategy-&gt;update($response);
}
</code></pre>

<p>EsiResponseCacheStrategy <a href=""https://github.com/symfony/symfony/blob/master/src/Symfony/Component/HttpKernel/HttpCache/EsiResponseCacheStrategy.php#L42"">turns a response into non cacheable</a> if it uses either Last-Response or ETag (<a href=""https://github.com/symfony/symfony/blob/master/src/Symfony/Component/HttpKernel/HttpCache/EsiResponseCacheStrategy.php#L40"">EsiResponseCacheStrategy::add()</a> method):</p>

<pre><code>if ($response-&gt;isValidateable()) {
    $this-&gt;cacheable = false;
} else {
    // ... 
}
</code></pre>

<p><a href=""https://github.com/symfony/symfony/blob/master/src/Symfony/Component/HttpFoundation/Response.php#L407"">Response::isValidateable()</a> returns true if Last-Response or ETag header is present.</p>

<p>It results in <a href=""https://github.com/symfony/symfony/blob/master/src/Symfony/Component/HttpKernel/HttpCache/EsiResponseCacheStrategy.php#L62"">overwriting the Cache-Control header</a> (<a href=""https://github.com/symfony/symfony/blob/master/src/Symfony/Component/HttpKernel/HttpCache/EsiResponseCacheStrategy.php#L55"">EsiResponseCacheStrategy::update()</a> method):</p>

<pre><code>if (!$this-&gt;cacheable) {
    $response-&gt;headers-&gt;set('Cache-Control', 'no-cache, must-revalidate');

    return;
}
</code></pre>

<p>I asked this question on Symfony2 user group but I didn't get an answer so far: <a href=""https://groups.google.com/d/topic/symfony2/6lpln11POq8/discussion"">https://groups.google.com/d/topic/symfony2/6lpln11POq8/discussion</a></p>

<p><strong>Update.</strong></p>

<p>Since I no longer have access to the original code I tried to <a href=""https://github.com/jakzal/symfony-standard/blob/cache/src/Acme/DemoBundle/Controller/DemoController.php#L62"">reproduce the scenario with the latest Symfony standard edition</a>.</p>

<p>Response headers are more consistent now, but still seem to be wrong. </p>

<p>As soon as I set a <code>Last-Modified</code> header on the response, the first response made by a browser has a: </p>

<pre><code>Cache-Control:must-revalidate, no-cache, private
</code></pre>

<p>Second response has an expected:</p>

<pre><code>Cache-Control:max-age=120, public, s-maxage=120
</code></pre>

<p>If I avoid sending <code>If-Modified-Since</code> header, every request returns <code>must-revalidate, no-cache, private</code>.</p>

<p>It doesn't matter if the request was made in <code>prod</code> or <code>dev</code> environment anymore.</p>
",Is it fine if first response is private with AppCache (Symfony2)?,0.0224988
25549652,6321,142,"<p>Recently, I saw a strange C++ feature: <em>injected class name</em>.</p>

<pre><code>class X { };
X x1;
class X::X x2; // class X::X is equal to X
class X::X::X x3; // ...and so on...
</code></pre>

<p>But I cannot figure out why this feature is necessary. Is there any practice that requires this feature?</p>

<p>And I heard this feature didn't exist in old C++. Then, when was it introduced? C++03? C++11?</p>
",Why is there an injected class name?,0.0224648